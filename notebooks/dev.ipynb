{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b27fdfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path \n",
    "import os\n",
    "import datetime as dt\n",
    "import requests\n",
    "import json\n",
    "from intuitlib.client import AuthClient\n",
    "import urllib.parse\n",
    "from time import perf_counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a0cc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Job:\n",
    "    def __init__(self):\n",
    "        base_dir = Path(\"c:/Users/ZheRao/OneDrive - Monette Farms/Monette Farms Team Site - Innovation Projects/Production/Database\")\n",
    "        self.base_dir = base_dir\n",
    "        self.today = dt.date.today()\n",
    "        month_format = \"\".join([\"0\",str(self.today.month)]) if self.today.month < 10 else str(self.today.month)\n",
    "        self.us_companies = [\"MFUSA\", \"MFAZ\", \"MSUSA\", \"MPUSA\"]\n",
    "        self.company_names = self.us_companies + [\"MSL\", \"NexGen\", \"MFBC\", \"MPL\", \"MFL\"]\n",
    "        self.raw_path = {\n",
    "            \"QBO\": {\n",
    "                \"Raw\": base_dir/\"Bronze\"/\"QBO\"/\"Raw\"/f\"{self.today.year}_{self.today.month}\",\n",
    "                \"GL\": base_dir/\"Bronze\"/\"QBO\"/\"GeneralLedger\",\n",
    "                \"PL\": base_dir/\"Bronze\"/\"QBO\"/\"ProfitAndLoss\",\n",
    "                \"Time\":base_dir/\"Bronze\"/\"QBOTime\"\n",
    "            },\n",
    "            \"Delivery\": {\"Traction\":base_dir/\"Bronze\"/\"Traction\", \"HP\":base_dir/\"Bronze\"/\"HarvestProfit\"},\n",
    "            \"Auth\": {\"QBO\":base_dir/\"Bronze\"/\"Authentication\"/\"QBO\", \"QBOTime\": base_dir/\"Bronze\"/\"Authentication\"/\"QBOTime\"},\n",
    "            \"Log\": base_dir/\"Load_History\"/f\"{self.today.year}\"/month_format\n",
    "        }\n",
    "        self.silver_path = {\n",
    "            \"QBO\": {\n",
    "                \"Dimension_time\": base_dir/\"Silver\"/\"QBO\"/\"Dimension\"/f\"{self.today.year}_{self.today.month}\",\n",
    "                \"Dimension\": base_dir/\"Silver\"/\"QBO\"/\"Dimension\",\n",
    "                \"Raw\": base_dir/\"Silver\"/\"QBO\"/\"Fact\"/\"Raw\",\n",
    "                \"PL\": base_dir/\"Silver\"/\"QBO\"/\"Fact\"/\"ProfitAndLoss\",\n",
    "                \"GL\": base_dir/\"Silver\"/\"QBO\"/\"Fact\"/\"GeneralLedger\",\n",
    "                \"Time\": base_dir/\"Silver\"/\"QBOTime\"\n",
    "            },\n",
    "            \"Delivery\": {\"Traction\":base_dir/\"Silver\"/\"Traction\", \"HP\":base_dir/\"Silver\"/\"HarvestProfit\"}\n",
    "        }\n",
    "        \n",
    "    \n",
    "    def get_fx(self):\n",
    "        key  = os.getenv(\"ALPHAVANTAGE_KEY\")\n",
    "        url  = (\"https://www.alphavantage.co/query?\"\n",
    "                \"function=CURRENCY_EXCHANGE_RATE\"\n",
    "                \"&from_currency=USD&to_currency=CAD\"\n",
    "                f\"&apikey={key}\")\n",
    "        rate = float(requests.get(url, timeout=10).json()\n",
    "                    [\"Realtime Currency Exchange Rate\"][\"5. Exchange Rate\"])\n",
    "        self.fx = rate\n",
    "    \n",
    "    def create_log(self, path: Path) -> None:\n",
    "        self.check_file(path)\n",
    "        day_format = \"\".join([\"0\",str(self.today.day)]) if self.today.day < 10 else str(self.today.day)\n",
    "        self.log = open(path/(day_format+\"_Log.txt\"), \"a\")\n",
    "\n",
    "    \n",
    "    def close_log(self):\n",
    "        self.log.close()\n",
    "\n",
    "    def check_file(self, path: Path) -> None:\n",
    "        if not Path.exists(path):\n",
    "            os.makedirs(path)\n",
    "    \n",
    "    def formulate_date(self, df:pd.DataFrame, date_cols:list[str], drop_time:bool=True) -> pd.DataFrame:\n",
    "        \"\"\" \n",
    "            format the date columns into datetime format\n",
    "        \"\"\"\n",
    "        assert len(set(date_cols) - set(df.columns)) == 0, \"Not all columns passed are inside dataframe passed\"\n",
    "        for col in date_cols:\n",
    "            df[col] = pd.to_datetime(df[col], utc=True)\n",
    "            if drop_time: df[col] = df[col].dt.date\n",
    "        return df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ee67c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Projects(Job):\n",
    "    \"\"\" \n",
    "        for project specific data transformations\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.gold_path = {\n",
    "            \"weekly_banking\": self.base_dir / \"Gold\" / \"FinanceProject\" / \"WeeklyBanking\",\n",
    "            \"inventory\": self.base_dir / \"Gold\" / \"InventoryProject\",\n",
    "            \"payroll\": self.base_dir / \"Gold\" / \"HRProject\" /\"PayrollProject\",\n",
    "            \"finance_operational\": self.base_dir / \"Gold\" / \"FinanceOperationalProject\",\n",
    "            \"budget\": self.base_dir / \"Gold\" / \"BudgetProject\",\n",
    "            \"QBOTime\": self.base_dir / \"Gold\" / \"HRProject\" / \"QBOTimeProject\"\n",
    "        }\n",
    "        self.silver_acc = pd.read_csv(self.silver_path[\"QBO\"][\"Dimension_time\"]/\"Account.csv\")\n",
    "        self.commodities = {\n",
    "            \"Produce\": [\"Strawberry\", \"Watermelon\", \"Cantaloupe\", \"Market Garden\", \"Broccoli\", \"Pumpkin\", \"Sweet Corn\", \"Cauliflower\", \"Squash\", \"Honeydew Melon\", \"Potato\", \"Carrot\", \"Cabbage\",\n",
    "                        \"Lettuce\", \"Brussel Sprouts\", \"Prairie Pathways\", \"Beet\", \"Corn Maze\"],\n",
    "            \"Grain\": [\"Blackeye Pea\", \"Winter Wheat\", \"Durum\", \"Cotton\", \"Chickpea\", \"Barley\", \"Green Lentil\", \"Red Lentil\", \"Canola\", \n",
    "                        \"Wheat\",\"Field Pea\", \"Corn\", \"Oat\", \"Soybean\", \"Bean\"],\n",
    "            \"Cattle\": [\"Weaned Calves\", \"Cull Bull\", \"Cull Cow\", \"Bred Heifer\", \"Purebred Yealing Bull\", \"Purebred Heifer\", \n",
    "                        \"Purebred Cow\", \"Purebred Bull\", \"Cow\", \"Bull\", \"Steer\", \"Heifer\", \"Yearling\", \"Calf\"]\n",
    "        }\n",
    "        self.locations = {\n",
    "            \"Produce\": [\"BritishColumbia (produce)\", \"Outlook\", \"Arizona (produce)\"],\n",
    "            \"Cattle\": [\"Airdrie\", \"Eddystone (cattle)\", \"Ashcroft\", \"Home Ranch\", \"Diamond S\", \"Wolf Ranch\", \"Fraser River Ranch\", \"Moon Ranch\", \"Waldeck\", \"Calderbank\"],\n",
    "            \"Grain\": [\"Eddystone (grain)\", \"Arizona (grain)\", \"Colorado\", \"Swift Current\", \"Regina\", \"Raymore\", \"Prince Albert\", \"The Pas\",\n",
    "                      \"Kamsack\", \"Hafford\", \"Yorkton\", \"Fly Creek\", \"Camp 4\", \"Havre\", \"Billings\"],\n",
    "            \"Seed\": [\"NexGen\", \"Seeds\", \"Seeds USA\"],\n",
    "            \"Others\": [\"Eddystone (corporate)\", \"Arizona (corporate)\", \"Legacy\", \"BritishColumbia (corporate)\", \"-Corporate\"]\n",
    "        }\n",
    "        self.bc_ranches = [\"Ashcroft\", \"Fraser River Ranch\", \"Moon Ranch\", \"Wolf Ranch\", \"Home\", \"Diamond S\", \"BritishColumbia (corporate)\",\"Home Ranch\"]\n",
    "        self.pl_exist = False # determines whether _financial_operational has run and gold_pl is stored in self, if not, any subsequent downstream projects will run _financial_operational first\n",
    "\n",
    "    def _pillar_classification(self, entry: pd.Series) -> str:\n",
    "        \"\"\" \n",
    "            this function classifies pillar of a transaction based on location\n",
    "        \"\"\"\n",
    "        location = entry[\"Location\"]\n",
    "        if not isinstance(location, str):\n",
    "            return \"Missing\"\n",
    "        if \"produce\" in location:\n",
    "            return \"Produce\"\n",
    "        elif \"grain\" in location:\n",
    "            return \"Grain\"\n",
    "        elif \"cattle\" in location:\n",
    "            return \"Cattle\"\n",
    "        elif \"corporate\" in location:\n",
    "            return \"Unclassified\"\n",
    "        match location.lower():\n",
    "            case \"hafford\"|\"kamsack\"|\"prince albert\"|\"raymore\"|\"regina\"|\"swift current\"|\"the pas\"|\"camp 4\"|\"fly creek\"|\"havre\"|\"yorkton\"|\"colorado\":\n",
    "                return \"Grain\"\n",
    "            case \"outlook\"|\"seeds usa\":\n",
    "                return \"Produce\"\n",
    "            case \"ashcroft\"|\"diamond s\"|\"fraser river ranch\"|\"home ranch\"|\"moon ranch\"|\"wolf ranch\"|\"waldeck\"|\"calderbank\"|\"airdrie\":\n",
    "                return \"Cattle\"\n",
    "            case \"seeds\"|\"nexgen\":\n",
    "                return \"Seed\"\n",
    "            case _:\n",
    "                return \"Unclassified\"\n",
    "    \n",
    "    def _identify_product(self, entry: pd.Series, for_budget:bool=False) -> str:\n",
    "        \"\"\" \n",
    "            this function identifies commodity from account names, except for seed, \n",
    "                if this function is called from budget project, it combines MG & CSA and take CM into consideration, and name forage differently\n",
    "        \"\"\"\n",
    "        if entry[\"AccPillar\"] == \"Seed\":\n",
    "            return \"SeedProduct\"\n",
    "        accname = entry[\"AccountName\"].lower()\n",
    "        if \"float\" in accname:\n",
    "            return \"Others\"\n",
    "        for x in self.commodities[\"Produce\"] + self.commodities[\"Grain\"] + self.commodities[\"Cattle\"]:\n",
    "            if x.lower() in accname:\n",
    "                if for_budget:\n",
    "                    match x:\n",
    "                        case \"Market Garden\"|\"CSA\":\n",
    "                            return \"Market Garden / CSA\"\n",
    "                        case \"Corn Maze\":\n",
    "                            return \"Prairie Pathways\"\n",
    "                    return x \n",
    "        if \"straw\" in accname or \"forage\" in accname or \"hay bale\" in accname:\n",
    "            if for_budget: \n",
    "                return \"Hay/Silage\" \n",
    "            else: \n",
    "                return \"Forage\"\n",
    "        return \"Others\"\n",
    "    \n",
    "    def _weekly_banking(self) -> None:\n",
    "        \"\"\" \n",
    "            weekly banking project: match latest GL bank transactions with raw activities - extract accounts for those activities\n",
    "                assumptions: a raw entry (e.g., invoice) can have multiple lines - multiple associated accounts, only considering the first one \n",
    "        \"\"\"\n",
    "        print(\"\\nStarting Weekly Banking Project Transformation\\n\")\n",
    "        # determine minal date to keep for GL\n",
    "        if self.today.month > 6:\n",
    "            year = self.today.year \n",
    "            month = self.today.month - 6 \n",
    "        else:\n",
    "            year = self.today.year - 1\n",
    "            month = self.today.month + 12 - 6\n",
    "        # load and prepare data\n",
    "        ## account\n",
    "        account = self.silver_acc.copy(deep=True)\n",
    "        ## change some accounts to Transfer category\n",
    "        acc_list = [\"MFL264\", \"MSL250\"]\n",
    "        account.loc[account[\"AccID\"].isin(acc_list), \"Profitem\"] = \"Asset\"\n",
    "        account.loc[account[\"AccID\"].isin(acc_list), \"Category\"] = \"Transfer\"\n",
    "        account_bank = account[account[\"AccountType\"]==\"Bank\"]\n",
    "        ## LinkedTxn for invoice and bill\n",
    "        invoice_linked = pd.read_csv(self.silver_path[\"QBO\"][\"Raw\"] / \"LinkedTxn\"/ \"LinkedTxn_Mapping_Invoice.csv\")\n",
    "        bill_linked = pd.read_csv(self.silver_path[\"QBO\"][\"Raw\"] / \"LinkedTxn\"/ \"LinkedTxn_Mapping_Bill.csv\")\n",
    "        mapping = pd.concat([invoice_linked, bill_linked])\n",
    "        mapping = mapping.drop(columns=[\"Corp\"])\n",
    "        # define customized function for processing other raw table\n",
    "        def _process_facts(df_type:str) -> pd.DataFrame:\n",
    "            \"\"\" \n",
    "                function for processing raw tables for mapping table - TransactionID_partial to AccID\n",
    "            \"\"\"\n",
    "            df = pd.read_csv(self.silver_path[\"QBO\"][\"Raw\"]/(df_type+\".csv\"), usecols = [\"TransactionID\", \"AccID\"])\n",
    "            df[\"TransactionID\"] = df[\"TransactionID\"].apply(lambda x: x.split(\"-\")[1])\n",
    "            df = df.drop_duplicates()\n",
    "            df = df.rename(columns={\"TransactionID\":\"TxnId\"})\n",
    "            return df\n",
    "        ## purchase table for expense transactions\n",
    "        purchase = _process_facts(\"Purchase\")\n",
    "        purchase[\"TxnType\"] = \"Expense\"\n",
    "        mapping = pd.concat([mapping,purchase])\n",
    "        ## journal entries - exclude most entries related to bank\n",
    "        journal = _process_facts(\"JournalEntry\")\n",
    "        journal[\"TxnType\"] = \"Journal Entry\"\n",
    "        # for journal entries, exclude most of entires where the activity account ID is a bank ID\n",
    "        exclude_list = list(account_bank.AccID.unique())\n",
    "        # mylist = [\"MFL51\", \"MFBC470\", \"MFBC471\", \"MFL28\", \"MFL27\", \"MFL1150040024\"]\n",
    "        mylist = [\"MFBC470\", \"MFBC471\"] # should include these accounts\n",
    "        for acc in mylist:\n",
    "            exclude_list.remove(acc)\n",
    "        journal = journal[~journal[\"AccID\"].isin(exclude_list)]\n",
    "        mapping = pd.concat([mapping,journal])\n",
    "        ## deposit\n",
    "        deposit = _process_facts(\"Deposit\")\n",
    "        deposit[\"TxnType\"] = \"Deposit\"\n",
    "        mapping = pd.concat([mapping,deposit])\n",
    "        ## salesreceipts\n",
    "        sales = _process_facts(\"SalesReceipt\")\n",
    "        sales[\"TxnType\"] = \"Sales Receipt\"\n",
    "        mapping = pd.concat([mapping,sales])\n",
    "        # process mapping table - dedup\n",
    "        mapping = mapping.drop_duplicates(subset=[\"TxnId\"],keep=\"first\")\n",
    "        ## load GL transacitons\n",
    "        cols = [\"TransactionType\",\"TransactionID_partial\",\"AccID\",\"AccNum\",\"AccName\", \"TransactionDate\", \"Amount\", \"SplitAcc\", \"SplitAccID\", \"Memo\", \"Corp\", \"Balance\"]\n",
    "        transactions = pd.read_csv(self.silver_path[\"QBO\"][\"GL\"]/\"GeneralLedger.csv\",dtype={\"TransactionID_partial\":str}, usecols=cols)\n",
    "        transactions = transactions[transactions[\"AccID\"].isin(account_bank.AccID.unique())]\n",
    "        transactions[\"TransactionDate\"] = pd.to_datetime(transactions[\"TransactionDate\"])\n",
    "        transactions = transactions[transactions[\"TransactionDate\"]>=dt.datetime(year, month, 1)]\n",
    "        transactions = transactions.rename(columns={\"TransactionType\":\"TxnType\",\"TransactionID_partial\":\"TxnId\",\n",
    "                                                    \"AccID\":\"BankAccID\",\"AccNum\":\"BankAccNum\",\"AccName\":\"BankAccName\",\n",
    "                                                    \"TransactionDate\":\"BankActivityDate\",\"Amount\":\"BankAmount\"})\n",
    "        # merge to get CurrencyID for bank_acc\n",
    "        transactions = pd.merge(transactions, account_bank.loc[:,[\"AccID\",\"CurrencyID\"]], left_on=[\"BankAccID\"], right_on=[\"AccID\"], how=\"left\")\n",
    "        transactions = transactions.drop(columns=[\"AccID\"])\n",
    "        # separating transfers - don't merge with mapping table\n",
    "        transfers = transactions[transactions[\"TxnType\"] == \"Transfer\"].copy(deep=True)\n",
    "        transactions = transactions[transactions[\"TxnType\"]!=\"Transfer\"]\n",
    "        transactions = transactions.drop(columns=[\"SplitAcc\", \"SplitAccID\"])\n",
    "        transactions[\"BankActivityDate\"] = pd.to_datetime(transactions[\"BankActivityDate\"])\n",
    "        transactions[\"TxnType\"] = transactions[\"TxnType\"].replace({\"Cheque Expense\":\"Expense\", \"Check\": \"Expense\"})\n",
    "        # merge with mapping table\n",
    "        transactions_mapped = pd.merge(transactions,mapping,on=[\"TxnId\",\"TxnType\"],how=\"left\")\n",
    "        non_match = transactions_mapped[transactions_mapped[\"AccID\"].isna()]\n",
    "        print(\"None Match Transaction Types\")\n",
    "        print(non_match.TxnType.value_counts())\n",
    "        print(f\"Non matches - {len(non_match)}\")\n",
    "        # function to determine transfer type\n",
    "        def _determine_transfer_type(entry:str) -> str:\n",
    "            \"\"\" \n",
    "                determine whether the transfer is for visa, bank, or other transfer\n",
    "            \"\"\"\n",
    "            if \"visa\" in entry.lower():\n",
    "                return \"Visa Payment\"\n",
    "            elif \"due\" in entry.lower():\n",
    "                return \"Bank Transfer\"\n",
    "            else:\n",
    "                return \"Other Transfer\"\n",
    "        # allocate transfer type \n",
    "        transfers[\"TransferType\"] = transfers[\"SplitAcc\"].apply(lambda x: _determine_transfer_type(x))\n",
    "        transfers = transfers.rename(columns={\"SplitAccID\":\"AccID\"})\n",
    "        transfers = transfers.drop(columns=[\"SplitAcc\"])\n",
    "        transactions_mapped = pd.concat([transactions_mapped,transfers], ignore_index=True)\n",
    "        # clean up the dataframe\n",
    "        transactions_mapped = transactions_mapped.rename(columns={\"CurrencyID\":\"BankCurrencyID\"})\n",
    "        transactions_mapped = pd.merge(transactions_mapped, account.loc[:,[\"AccID\",\"AccName\",\"AccNum\",\"Category\",\"Profitem\",\"CurrencyID\"]], on=\"AccID\", how=\"left\")\n",
    "        transactions_mapped.loc[transactions_mapped[\"TransferType\"]==\"Bank Transfer\",\"Category\"] = \"Bank Transfer\"\n",
    "        transactions_mapped.loc[((transactions_mapped[\"BankAccNum\"].str.startswith(\"MSL\"))&(transactions_mapped[\"AccNum\"]==\"MSL120001\")), \"Category\"] = \"Seed Processing Revenue\"\n",
    "        transactions_mapped = transactions_mapped.rename(columns={\"AccNum\":\"ActivityAccNum\", \"AccName\":\"ActivityAccName\"})\n",
    "        # csv from sharepoint is unstable, and produced unpredictable readings from Power BI\n",
    "        self.check_file(self.gold_path[\"weekly_banking\"])\n",
    "        transactions_mapped.to_excel(self.gold_path[\"weekly_banking\"]/\"BankingActivity.xlsx\", sheet_name=\"transactions\", index=False)\n",
    "\n",
    "    def _finance_operational(self) -> None:\n",
    "        \"\"\" \n",
    "            transform PL data into operational-ready\n",
    "                1. reclassify accounts\n",
    "                2. standardize location, classify pillar\n",
    "                3. revising signs\n",
    "        \"\"\"\n",
    "        print(\"\\nStarting Finance Operational Project Transformation\\n\")\n",
    "        # load data from silver space\n",
    "        data = pd.read_csv(self.silver_path[\"QBO\"][\"PL\"]/\"ProfitAndLoss.csv\")\n",
    "        assert data.loc[0,\"FXRate\"] == data.FXRate.mean(), \"different FXRate detected\"\n",
    "        self.fx = data.loc[0,\"FXRate\"]\n",
    "        data[\"TransactionDate\"] = pd.to_datetime(data[\"TransactionDate\"])\n",
    "        data[\"FiscalYear\"] = data.TransactionDate.apply(lambda x: x.year + 1 if x.month >= 11 else x.year)\n",
    "        # clean location\n",
    "        data = data.rename(columns={\"Location\":\"LocationRaw\"})\n",
    "        data[\"Location\"] = data[\"LocationRaw\"]\n",
    "        ## add location for seed operation\n",
    "        data.loc[data[\"Corp\"]==\"MSL\",\"Location\"] = \"Seeds\"\n",
    "        data.loc[data[\"Corp\"]==\"NexGen\",\"Location\"] = \"NexGen\"\n",
    "        data.loc[data[\"Corp\"]==\"MSUSA\",\"Location\"] = \"Arizona (produce)\" # count Seeds USA as AZ Produce\n",
    "        ## clean location\n",
    "        clean_location = {\"Airdrie - Grain\":\"Airdrie\", \"Airdrie - Cattle\":\"Airdrie\", \"Airdrie - General\":\"Airdrie\", \"Airdrie\":\"Airdrie\", \n",
    "                        \"Eddystone - Grain\": \"Eddystone (grain)\", \"Eddystone - Cattle\": \"Eddystone (cattle)\", \"Eddystone - General\":\"Eddystone (corporate)\",\n",
    "                        \"Outlook (JV)\":\"Outlook\", \"AZ Produce\":\"Arizona (produce)\", \"Corporate\":\"Arizona (corporate)\", \"BC Produce\":\"BritishColumbia (produce)\",\n",
    "                        \"Grain\":\"Arizona (grain)\", \"Cache/Fischer/Loon - DNU\":\"Legacy\", \"Ashcroft (CC, Fischer, Loon)\":\"Ashcroft\", \n",
    "                        \"Outlook (Capital)\":\"Outlook\", \"Colorado (MF)\":\"Colorado\", \"Colorado (JV)\":\"Colorado\", \"Cattle - General\":\"BritishColumbia (corporate)\",\n",
    "                        \"Home (70 M, LF/W, 105 M)\":\"Home Ranch\", \"Diamond S (BR)\":\"Diamond S\", \"North Farm (deleted)\":\"Legacy\"}\n",
    "        data[\"Location\"] = data[\"Location\"].replace(clean_location)\n",
    "        locations = self.locations[\"Produce\"] + self.locations[\"Grain\"] + self.locations[\"Cattle\"] + self.locations[\"Others\"] + self.locations[\"Seed\"]\n",
    "        unaccounted_location = list(set(data[\"Location\"].unique()) - set(locations))\n",
    "        print(f\"location unaccounted for - {unaccounted_location}\")\n",
    "        # classify pillar\n",
    "        data[\"Pillar\"] = data.apply(lambda x: self._pillar_classification(x),axis=1)\n",
    "        # reorganize corp\n",
    "        ## MPUSA missing location = Arizona (produce)\n",
    "        data.loc[((data[\"Corp\"] == \"MPUSA\")&(data[\"Location\"].isna())), \"Location\"] = \"Arizona (produce)\"\n",
    "        data.loc[((data[\"Corp\"] == \"MPUSA\")&(data[\"Location\"] == \"Arizona (produce)\")), \"Pillar\"] = \"Produce\"\n",
    "        ## AZ Produce --> MPUSA\n",
    "        data.loc[data[\"Location\"] == \"Arizona (produce)\", \"Corp\"] = \"MPUSA\"\n",
    "        ## move everything for AZ in 2025 to produce\n",
    "        data.loc[((data[\"FiscalYear\"] >= 2025) & (data[\"Location\"].str.contains(\"Arizona\",case=False))),\"Pillar\"] = \"Produce\"\n",
    "        data.loc[((data[\"FiscalYear\"] >= 2025) & (data[\"Location\"].str.contains(\"Arizona\",case=False))),\"Location\"] = \"Arizona (produce)\"\n",
    "        ## BC Produce --> MPL\n",
    "        data.loc[data[\"Location\"] == \"BritishColumbia (produce)\", \"Corp\"] = \"MPL\"\n",
    "        ## Outlook --> MPL\n",
    "        data.loc[data[\"Location\"]==\"Outlook\", \"Corp\"] = \"MPL\"\n",
    "        # Reclassify accounts for Operational Purpose\n",
    "        ## read & process operational classification\n",
    "        acc_operation = pd.read_csv(self.silver_path[\"QBO\"][\"Dimension\"]/\"Accounts Classification - Operation.csv\", dtype={\"Pillar\": str, \"IsGenric\": str}, keep_default_na=False)\n",
    "        acc_operation = acc_operation.rename(columns={\"Pillar\":\"AccPillar\", \"OperationProfiType\":\"OperationProfType\"})\n",
    "        acc_operation[\"AccNum\"] = acc_operation[\"AccountName\"].apply(lambda x: x.split(\" \")[0])\n",
    "        acc_operation[\"IsIntercompany\"] = acc_operation[\"AccountName\"].apply(lambda x: \"Yes\" if \"intercompany\" in x.lower() else \"No\")\n",
    "        ## classify commodity\n",
    "        acc_operation[\"Commodity\"] = acc_operation.apply(lambda x: self._identify_product(x), axis=1)\n",
    "        self.operation_acc = acc_operation\n",
    "        acc_operation.to_csv(self.gold_path[\"finance_operational\"]/\"accounts_classified_operation.csv\", index=False)\n",
    "        ## read accounts table and apply new classification\n",
    "        accounts = self.silver_acc\n",
    "        accounts1 = accounts[accounts[\"AccNum\"].isna()].copy(deep=True)\n",
    "        accounts = accounts[accounts[\"AccNum\"].notna()]\n",
    "        accounts = pd.merge(accounts, acc_operation.loc[:,[\"AccNum\",\"OperationProfType\",\"OperationCategory\",\"OperationSubCategory\",\"AccPillar\",\"Commodity\",\"IsGeneric\",\"IsIntercompany\"]],\n",
    "                            on = \"AccNum\", how = \"left\")\n",
    "        accounts = pd.concat([accounts,accounts1],ignore_index=True)\n",
    "        # Revising Signs according to Operational Classification\n",
    "        print(\"Revising Signs ...\")\n",
    "        expense_accounts = accounts[(accounts[\"OperationCategory\"] == \"Expense\") | (accounts[\"OperationCategory\"] ==\"Inventory Consumption\")]\n",
    "        data[\"AmountDisplay\"] = data.apply(lambda x: -x[\"AmountCAD\"] if x[\"AccID\"] in expense_accounts.AccID.unique() else x[\"AmountCAD\"], axis=1)\n",
    "        self.gold_pl = data\n",
    "        self.gold_acc = accounts\n",
    "        # save files\n",
    "        print(\"Saving ...\")\n",
    "        self.check_file(self.gold_path[\"finance_operational\"])\n",
    "        data.to_csv(self.gold_path[\"finance_operational\"]/\"PL.csv\", index=False)\n",
    "        accounts.to_excel(self.gold_path[\"finance_operational\"]/\"Account_table.xlsx\", sheet_name = \"Account\", index=False)\n",
    "        data.to_excel(self.gold_path[\"finance_operational\"]/\"PL.xlsx\", sheet_name=\"Transactions\", index=False)\n",
    "        self.pl_exist = True\n",
    "\n",
    "    def _process_pp(self, data:pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\" \n",
    "            This function takes original dataframe, apply the payperiod number classification based on transactions date, process payperiod columns, and return the new dataframe\n",
    "        \"\"\"\n",
    "        # load payperiods\n",
    "        payperiods = pd.read_csv(self.gold_path[\"payroll\"]/\"Payperiods.csv\")\n",
    "        payperiods[\"START\"] = pd.to_datetime(payperiods[\"START\"])\n",
    "        payperiods[\"END\"] = pd.to_datetime(payperiods[\"END\"])\n",
    "        payperiods = payperiods.loc[:,[\"PP\",\"START\",\"END\",\"Cycle\",\"FiscalYear\"]]\n",
    "        def _determine_pp(entry:pd.Series, date_col:str = \"TransactionDate\") -> str:\n",
    "            \"\"\" \n",
    "                This function determined which payperiod a transaction should be classified into, \n",
    "                    starting from most recent payperiod, the algorithm uses period start date + drift to determine which payperiod a transaction should fall into\n",
    "                Assumptions:\n",
    "                    1. for outlook and az, each payperiod is shifted by 5 + 7 days forward\n",
    "                    2. for other location, each payperiod is shifted by 5 days forward\n",
    "            \"\"\"\n",
    "            date = entry[date_col] \n",
    "            if isinstance(entry[\"Location\"],str):\n",
    "                location = entry[\"Location\"].lower()\n",
    "            else:\n",
    "                location = \"None\"\n",
    "            if \"outlook\" in location or \"az\" in location or \"arizona\" in location:\n",
    "                date_diff = dt.timedelta(days=5+7)\n",
    "            else:\n",
    "                date_diff = dt.timedelta(days=5)\n",
    "            year = date.year \n",
    "            month = date.month\n",
    "            # push back the most recent payperiod dates for older transactions to save compute\n",
    "            if month >= 11:\n",
    "                payperiods_subset = payperiods[payperiods[\"END\"] <= dt.datetime(year+1,2,1)] \n",
    "            else:  \n",
    "                payperiods_subset = payperiods[payperiods[\"END\"] <= dt.datetime(year,month+2,1)]\n",
    "            for i in range(len(payperiods_subset)-1,-1,-1):\n",
    "                if date > (payperiods_subset.loc[i,\"END\"]+date_diff):\n",
    "                    return \"Exceed Max PayPeriod\"\n",
    "                if date >= (payperiods_subset.loc[i,\"START\"]+date_diff):\n",
    "                    return str(payperiods_subset.loc[i,\"PP\"]) + \"-\" + str(payperiods_subset.loc[i,\"Cycle\"]) + \"-\" + str(payperiods_subset.loc[i,\"FiscalYear\"])\n",
    "            return \"Earlier than Min PayPeriod\"\n",
    "        print(\"Allocating PPNum for transactions ...\")\n",
    "        date_col = \"TransactionDate\" if \"TransactionDate\" in data.columns else \"date\"\n",
    "        data[\"PPNum\"] = data.apply(lambda x: _determine_pp(x,date_col),axis=1)\n",
    "        data = data[data[\"PPNum\"] != \"Earlier than Min PayPeriod\"].copy(deep=True).reset_index(drop=True) # eliminate earlier than min payperiod in the csv, note dates are shifted in the csv\n",
    "        data[\"Cycle\"] = data[\"PPNum\"].apply(lambda x: x.split(\"-\")[1])\n",
    "        data[\"FiscalYear\"] = data[\"PPNum\"].apply(lambda x: int(x.split(\"-\")[2]))\n",
    "        data[\"PPNum\"] = data[\"PPNum\"].apply(lambda x: x.split(\"-\")[0])\n",
    "        data[\"PPName\"] = data[\"PPNum\"].apply(lambda x: \"PP0\" + x if int(x) < 10 else \"PP\" + x)\n",
    "        data[\"PPName\"] = data[\"Cycle\"].str.slice(2,) + \"-\" + data[\"PPName\"]\n",
    "        return data\n",
    "\n",
    "    def _process_units(self) -> None:\n",
    "        \"\"\" \n",
    "            this function read and process Unit files that contains unit numbers for each location\n",
    "        \"\"\"\n",
    "        acres = pd.read_csv(self.gold_path[\"payroll\"]/\"Unit.csv\",dtype={\"Location\":str, \"Unit\":float})\n",
    "        acres[\"Location\"] = acres[\"Location\"].str.strip()\n",
    "        doc_rename = {\"Airdrie Grain\": \"Airdrie (grain)\", \"Aridrie Cattle (head days 365)\":\"Airdrie\", \"Arizona All\":\"Arizona (produce)\",\n",
    "                    \"BC Cattle (head days 365)\":\"BritishColumbia (cattle)\", \"BC Produce\":\"BritishColumbia (produce)\", \n",
    "                    \"Box Elder\":\"Havre\", \"Eddystone Cattle (head days 365)\":\"Eddystone (cattle)\", \"Eddystone Grain\":\"Eddystone (grain)\",\n",
    "                    \"Monette Seeds CDN (avg met. ton)\":\"Seeds\", \"Monette Seeds USA\":\"Seeds USA\", \"NexGen (avg met. ton)\":\"NexGen\",\n",
    "                    \"Waldeck (head days 365)\":\"Waldeck\", \"Calderbank  (head days 365)\":\"Calderbank\"}\n",
    "        acres[\"Location\"] = acres[\"Location\"].replace(doc_rename)\n",
    "        acres[\"Pillar\"] = acres.apply(lambda x: self._pillar_classification(x),axis=1)\n",
    "        acres.to_csv(self.gold_path[\"payroll\"]/\"Unit_PowerBI.csv\",index=False)\n",
    "\n",
    "    def _payroll_project(self) -> None: \n",
    "        \"\"\" \n",
    "            will run _finance_operational() first\n",
    "            output: details + cost per unit (units per location input sheet) + average cost per unit for FY\n",
    "        \"\"\"\n",
    "        if not self.pl_exist:\n",
    "            self._finance_operational()\n",
    "        print(\"\\nStarting Payroll Project Transformation\\n\")\n",
    "\n",
    "        # load and filter accounts for wages and contract labor\n",
    "        account = self.silver_acc[(self.silver_acc[\"Category\"].isin([\"Wages and benefits - direct\",\"Wages and benefits - overhead\"]) | (self.silver_acc[\"AccNum\"].isin([\"MFAZ595001\",\"MFBC536030\"])))] \n",
    "        # load only with transaction date later than 2021-12-20, and without \"Accrual\" in the memo\n",
    "        data = self.gold_pl.copy(deep=True)\n",
    "        data = data[data[\"AccID\"].isin(account.AccID.unique())]\n",
    "        data[\"TransactionDate\"] = pd.to_datetime(data[\"TransactionDate\"])\n",
    "        data = data[data[\"TransactionDate\"]>=dt.datetime(2021,12,20)].reset_index(drop=True)\n",
    "        data = data[~data[\"Memo\"].str.contains(\"Accrual\",case=False,na=False)]\n",
    "        # allocating payperiods\n",
    "        data = self._process_pp(data=data)\n",
    "        # standardizing location\n",
    "        # data.loc[data[\"Location\"]==\"Airdrie (corporate)\", \"Pillar\"] = \"Cattle\"                # deprecated\n",
    "        # data.loc[data[\"Location\"]==\"Airdrie (corporate)\", \"Location\"] = \"Airdrie (cattle)\"    # deprecated\n",
    "        data.loc[data[\"Location\"]==\"Eddystone (corporate)\", \"Pillar\"] = \"Unclassified\"\n",
    "        data.loc[data[\"Location\"]==\"Eddystone (corporate)\", \"Location\"] = \"Unassigned\"\n",
    "        data.loc[data[\"Location\"]==\"Legacy\", \"Location\"] = \"Unassigned\"\n",
    "        data.loc[(data[\"Location\"].str.contains(\"corporate\",case=False,na=False)&(data[\"Location\"]!=\"BritishColumbia (corporate)\")),\"Location\"] = \"Corporate\"\n",
    "        ## move BC ranches into BC Cattle\n",
    "        data.loc[(data[\"Location\"].isin(self.bc_ranches)), \"Location\"] = \"BritishColumbia (cattle)\"\n",
    "        data.loc[data[\"Location\"] == \"BritishColumbia (cattle)\", \"Pillar\"] = \"Cattle\"\n",
    "        # summarizing data\n",
    "        ## by Location per PP\n",
    "        data_summarized = pd.DataFrame(data.groupby([\"Location\",\"PPName\",\"Pillar\",\"FiscalYear\",\"Cycle\",\"PPNum\"]).agg({\"AmountDisplay\":\"sum\"}).reset_index(drop=False))\n",
    "        assert len(data_summarized) == len(data.groupby([\"Location\",\"PPName\"]).agg({\"AmountDisplay\":\"sum\"}).reset_index(drop=False)), \"Duplicated value detected for per Location per PP calculation\"\n",
    "        ## join acres data for CostPerUnit compute\n",
    "        print(\"Summarizing ...\")\n",
    "        acres = pd.read_csv(self.gold_path[\"payroll\"]/\"Unit_PowerBI.csv\",dtype={\"Location\":str, \"Unit\":float})\n",
    "        acres = acres.loc[:,[\"Location\", \"Unit\"]]\n",
    "        print(f\"Unaccounted location for Acres Doc: {set(acres.Location.unique()) - set(data_summarized.Location.unique())}\")\n",
    "        data_summarized = pd.merge(data_summarized, acres, on=\"Location\", how=\"left\")\n",
    "        data_summarized[\"CostPerUnit\"] = data_summarized[\"AmountDisplay\"] / data_summarized[\"Unit\"] * 26\n",
    "        data_summarized[\"Count\"] = 1\n",
    "        ## by Location\n",
    "        data_summarized2 = data_summarized.groupby(by=[\"Location\",\"FiscalYear\",\"Pillar\"]).agg({\"CostPerUnit\":\"mean\", \"Count\":\"sum\"}).reset_index(drop=False)\n",
    "        data_summarized2 = data_summarized2.rename(columns={\"CostPerUnit\":\"Avg CostPerUnit\"})\n",
    "        assert len(data_summarized2) == len(data_summarized.groupby(by=[\"Location\",\"FiscalYear\"]).agg({\"CostPerUnit\":\"mean\"})), \"Duplicated value detected for per Location calculation\"\n",
    "        ## by pillar\n",
    "        data_summarized3 = data_summarized2.groupby(by=[\"FiscalYear\",\"Pillar\"]).agg({\"Avg CostPerUnit\":\"mean\", \"Count\":\"sum\"}).reset_index(drop=False)\n",
    "        assert len(data_summarized3) == len(data_summarized.groupby(by=[\"Pillar\",\"FiscalYear\"]).agg({\"CostPerUnit\":\"mean\"})), \"Duplicated value detected for per Pillar calculation\"\n",
    "        # saving\n",
    "        print(\"Saving ...\")\n",
    "        self.check_file(self.gold_path[\"payroll\"])\n",
    "        data.to_excel(self.gold_path[\"payroll\"]/\"Payroll.xlsx\", sheet_name=\"Payroll\", index=False)\n",
    "        data_summarized.to_excel(self.gold_path[\"payroll\"]/\"PayrollSummarized.xlsx\", sheet_name=\"PayrollSummarized\", index=False)\n",
    "        data_summarized2.to_excel(self.gold_path[\"payroll\"]/\"PayrollSummarized2.xlsx\", sheet_name=\"PayrollSummarized2\", index=False)\n",
    "        data_summarized3.to_excel(self.gold_path[\"payroll\"]/\"PayrollSummarized3.xlsx\", sheet_name=\"PayrollSummarized3\", index=False)\n",
    "\n",
    "    def _QBOTime_project(self) -> None:\n",
    "        \"\"\" \n",
    "            apply PP allocation to QBO Time data, clean locaiton, and join relevant info into one table\n",
    "        \"\"\"\n",
    "        print(\"\\nStarting QBO Time Project Transformation\\n\")\n",
    "        # read files\n",
    "        timesheets = pd.read_csv(self.silver_path[\"QBO\"][\"Time\"]/\"timesheets.csv\")\n",
    "        jobcode = pd.read_csv(self.silver_path[\"QBO\"][\"Time\"]/\"jobcodes.csv\")\n",
    "        users = pd.read_csv(self.silver_path[\"QBO\"][\"Time\"]/\"users.csv\")\n",
    "        group = pd.read_csv(self.silver_path[\"QBO\"][\"Time\"]/\"group.csv\")\n",
    "        print(f\"Read {len(timesheets)} timesheet records, {len(jobcode)} jobcodes, {len(users)} users, {len(group)} groups\")\n",
    "        timesheets_len, users_len = len(timesheets), len(users)\n",
    "        # clean up location in group table\n",
    "        ## Arizona - all produce\n",
    "        group.loc[((group[\"corp_short\"]==\"A\")&(group[\"location_name\"]==\"Monette Farms AZ\")), \"Location\"] = \"Arizona (produce)\"\n",
    "        group.loc[((group[\"corp_short\"]==\"A\")&(group[\"location_name\"]==\"Monette Produce USA\")), \"Location\"] = \"Arizona (produce)\"\n",
    "        group.loc[((group[\"corp_short\"]==\"A\")&(group[\"location_name\"]==\"Monette Seeds USA\")), \"Location\"] = \"Arizona (produce)\"\n",
    "        ## BC\n",
    "        group.loc[((group[\"corp_short\"]==\"BC\")&(group[\"location_name\"]==\"Ashcroft Ranch\")), \"Location\"] = \"Ashcroft\"\n",
    "        group.loc[((group[\"corp_short\"]==\"BC\")&(group[\"location_name\"]==\"Cache/Fischer/Loon\")), \"Location\"] = \"Unassigned\"\n",
    "        group.loc[((group[\"corp_short\"]==\"BC\")&(group[\"location_name\"]==\"Diamond S Ranch\")), \"Location\"] = \"Diamond S\"\n",
    "        group.loc[((group[\"corp_short\"]==\"BC\")&(group[\"location_name\"]==\"Fraser River Ranch\")), \"Location\"] = \"Fraser River Ranch\"\n",
    "        group.loc[((group[\"corp_short\"]==\"BC\")&(group[\"location_name\"]==\"Home Ranch (70 Mile, LF/W, BR)\")), \"Location\"] = \"Home Ranch\"\n",
    "        group.loc[((group[\"corp_short\"]==\"BC\")&(group[\"location_name\"]==\"Moon Ranch\")), \"Location\"] = \"Moon Ranch\"\n",
    "        group.loc[((group[\"corp_short\"]==\"BC\")&(group[\"location_name\"]==\"Produce\")), \"Location\"] = \"BritishColumbia (produce)\"\n",
    "        group.loc[((group[\"corp_short\"]==\"BC\")&(group[\"location_name\"]==\"Wolf Ranch\")), \"Location\"] = \"Wolf Ranch\"\n",
    "        group.loc[((group[\"corp_short\"]==\"BC\")&(group[\"location_name\"]==\"SAWP\")), \"Location\"] = \"Unassigned\"\n",
    "        ## Outlook\n",
    "        group.loc[((group[\"corp_short\"]==\"O\")), \"Location\"] = \"Outlook\"\n",
    "        ## others\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"Airdrie\")), \"Location\"] = \"Airdrie\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"BC\")), \"Location\"] = \"Unassigned\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"Calderbank\")), \"Location\"] = \"Calderbank\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"Eddystone\")), \"Location\"] = \"Eddystone (unspecified)\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"Hafford\")), \"Location\"] = \"Hafford\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"Kamsack\")), \"Location\"] = \"Kamsack\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"MFUSA Billings\")), \"Location\"] = \"Billings\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"MFUSA Box Elder\")), \"Location\"] = \"Havre\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"Nexgen Seeds\")), \"Location\"] = \"NexGen\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"Prince Albert\")), \"Location\"] = \"Prince Albert\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"Raymore\")), \"Location\"] = \"Raymore\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"Regina\")), \"Location\"] = \"Regina\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"Russel Approvals\")), \"Location\"] = \"Unassigned\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"Seeds\")), \"Location\"] = \"Seeds\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"Swift Current\")), \"Location\"] = \"Swift Current\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"The Pas\")), \"Location\"] = \"The Pas\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"Waldeck\")), \"Location\"] = \"Waldeck\"\n",
    "        unclassified = group[group[\"Location\"].isna()].location_name.unique()\n",
    "        if len(unclassified) > 0: print(f\"\\nUnclassified location - {unclassified}\\n\")\n",
    "        # create another location column for general location where bc ranches are merged into one\n",
    "        group = group.rename(columns={\"Location\": \"Location (detail)\"})\n",
    "        group[\"Location\"] = group[\"Location (detail)\"]\n",
    "        group.loc[(group[\"Location (detail)\"].isin(self.bc_ranches)), \"Location\"] = \"BritishColumbia (cattle)\"\n",
    "        # merge tables into one table\n",
    "        ## merge location into users\n",
    "        users = pd.merge(users, group.loc[:,[\"group_id\", \"location_name\", \"Location\", \"Location (detail)\"]].drop_duplicates(), on=\"group_id\", how=\"left\")\n",
    "        ## merge users into timesheets\n",
    "        timesheets = pd.merge(timesheets,users.loc[:,[\"user_id\", \"group_id\", \"username\", \"full_name\", \"location_name\",\"Location\",\"Location (detail)\"]], on=\"user_id\", how=\"left\")\n",
    "        ## merge job into timesheets\n",
    "        timesheets = pd.merge(timesheets, jobcode.loc[:,[\"jobcode_id\",\"job_name\",\"type\"]].rename(columns={\"type\":\"job_type\"}), on=\"jobcode_id\", how=\"left\")\n",
    "        assert (len(users) == users_len) and (len(timesheets) == timesheets_len), f\"duplicated records found, timesheets - {timesheets_len} vs {len(timesheets)}; users - {users_len} vs {len(users)}\"\n",
    "        # classify payperiods\n",
    "        timesheets[\"date\"] = pd.to_datetime(timesheets[\"date\"])\n",
    "        timesheets = self._process_pp(data=timesheets)\n",
    "        # summarizing data\n",
    "        ## by Location per PP \n",
    "        summarized = timesheets.groupby([\"Location\",\"PPName\",\"FiscalYear\",\"Cycle\",\"PPNum\"]).agg({\"duration\":\"sum\"}).reset_index(drop=False)\n",
    "        assert len(summarized) == len(timesheets.groupby([\"Location\",\"PPName\"]).agg({\"duration\":\"sum\"})), \"duplicated value detected for timsheet per Location per PP summarization\"\n",
    "        ## read units file\n",
    "        acres = pd.read_csv(self.gold_path[\"payroll\"]/\"Unit_PowerBI.csv\",dtype={\"Location\":str, \"Unit\":float})\n",
    "        acres = acres.loc[:,[\"Location\", \"Unit\"]]\n",
    "        addition = pd.DataFrame(data={\"Location\":[\"Billings\"], \"Unit\":[acres[acres[\"Location\"].isin(['Fly Creek', 'Camp 4'])].Unit.sum()]})\n",
    "        acres = pd.concat([acres,addition],ignore_index=True)\n",
    "        print(f\"Unaccounted location for Acres Doc: {set(acres.Location.unique()) - set(summarized.Location.unique())}\")\n",
    "        print(f\"Unaccounted location for timesheets: {set(summarized.Location.unique()) - set(acres.Location.unique())}\")\n",
    "        ## merge with units file\n",
    "        summarized = pd.merge(summarized, acres, on=\"Location\", how=\"left\")\n",
    "        ## calculate hours per unit\n",
    "        summarized[\"HoursPerUnit\"] = summarized[\"duration\"] / summarized[\"Unit\"] * 26\n",
    "        summarized[\"Count\"] = 1\n",
    "        # summarize per location\n",
    "        summarized2 = summarized.groupby(by=[\"Location\",\"FiscalYear\"]).agg({\"HoursPerUnit\":\"mean\", \"Count\":\"sum\"}).reset_index(drop=False)\n",
    "        summarized2 = summarized2.rename(columns={\"HoursPerUnit\":\"Avg HoursPerUnit\"})\n",
    "\n",
    "        # saving\n",
    "        print(\"Saving ...\\n\")\n",
    "        self.check_file(self.gold_path[\"QBOTime\"])\n",
    "        timesheets.to_excel(self.gold_path[\"QBOTime\"]/\"QBOTime.xlsx\", sheet_name = \"QBOTime\", index=False)\n",
    "        summarized.to_excel(self.gold_path[\"QBOTime\"]/\"QBOTimeSummarized.xlsx\", sheet_name = \"QBOTimeSummarized\", index=False)\n",
    "        summarized2.to_excel(self.gold_path[\"QBOTime\"]/\"QBOTimeSummarized2.xlsx\", sheet_name = \"QBOTimeSummarized2\", index=False)\n",
    "\n",
    "    def _temp_get_product(self, entry:str) -> str:\n",
    "        \"\"\" \n",
    "            temporary function for aligning product classification with Traction for QBO accounts, will change for HP\n",
    "        \"\"\"\n",
    "        entry = entry.lower()\n",
    "        if \"durum\" in entry:\n",
    "            return \"Durum\"\n",
    "        elif \"wheat\" in entry:\n",
    "            return \"Wheat\"\n",
    "        elif \"canola\" in entry:\n",
    "            return \"Canola\"\n",
    "        elif (\"chickpea\" in entry) or (\"garbanzo bean\" in entry):\n",
    "            return \"Chickpeas\"\n",
    "        elif (\"peas\" in entry) or (\"field pea\" in entry):\n",
    "            return \"Peas\"\n",
    "        elif \"barley\" in entry:\n",
    "            return \"Barley\"\n",
    "        elif \"green lentil\" in entry:\n",
    "            return \"Green Lentils\"\n",
    "        elif \"red lentil\" in entry:\n",
    "            return \"Red Lentils\"\n",
    "        elif \"oats\" in entry:\n",
    "            return \"Oats\"\n",
    "        elif \"corn\" in entry:\n",
    "            return \"Corn\"\n",
    "        else:\n",
    "            return \"Others\" \n",
    "\n",
    "    def _raw_inventory(self) -> None:\n",
    "        \"\"\" \n",
    "            prepare the data from raw QBO table for inventory project: only extracting partial Invoice, SalesReceipt, and Journal Entry\n",
    "        \"\"\"\n",
    "        print(\"\\nStarting Inventory Project Transformation ...\\n\")\n",
    "        corps = [\"MFL\", \"MFUSA\"]\n",
    "        cols = [\"TransactionDate\", \"TransactionType\", \"TransactionID\", \"Corp\", \"Qty\", \"AccID\", \"FarmID\", \"CustomerID\",\n",
    "                \"DocNumber\", \"TransactionEntered\", \"Amount\"]\n",
    "        journal_cols = [col for col in cols if col != \"Qty\"]\n",
    "        # read tables\n",
    "        print(\"Loading raw tables ...\")\n",
    "        account = self.silver_acc.copy(deep=True)\n",
    "        account = account[account[\"Corp\"].isin(corps)]\n",
    "        account = account[account[\"AccountType\"] == \"Income\"]\n",
    "        farm = pd.read_csv(self.silver_path[\"QBO\"][\"Dimension_time\"]/\"Farm.csv\")\n",
    "        farm = farm[farm[\"Corp\"].isin(corps)]\n",
    "        customer = pd.read_csv(self.silver_path[\"QBO\"][\"Dimension_time\"]/\"Customer.csv\")\n",
    "        customer = customer[customer[\"Corp\"].isin(corps)]\n",
    "        first_date = dt.datetime(2023,11,1)\n",
    "        invoice = pd.read_csv(self.silver_path[\"QBO\"][\"Raw\"]/\"Invoice.csv\")\n",
    "        invoice = invoice[invoice[\"Corp\"].isin(corps)]\n",
    "        invoice[\"TransactionDate\"] = pd.to_datetime(invoice[\"TransactionDate\"])\n",
    "        invoice = invoice[invoice[\"TransactionDate\"]>=first_date]\n",
    "        invoice = invoice[invoice[\"AccID\"].isin(account.AccID.unique())]\n",
    "        sales = pd.read_csv(self.silver_path[\"QBO\"][\"Raw\"]/\"SalesReceipt.csv\")\n",
    "        sales = sales[sales[\"Corp\"].isin(corps)]\n",
    "        sales[\"TransactionDate\"] = pd.to_datetime(sales[\"TransactionDate\"])\n",
    "        sales = sales[sales[\"TransactionDate\"]>=first_date]\n",
    "        sales = sales[sales[\"AccID\"].isin(account.AccID.unique())]\n",
    "        journal = pd.read_csv(self.silver_path[\"QBO\"][\"Raw\"]/\"JournalEntry.csv\",usecols=journal_cols)\n",
    "        journal = journal[journal[\"AccID\"].isin(account.AccID.unique())]\n",
    "        journal[\"TransactionDate\"] = pd.to_datetime(journal[\"TransactionDate\"])\n",
    "        journal = journal[journal[\"TransactionDate\"]>=first_date]\n",
    "        journal = journal[~journal[\"TransactionEntered\"].str.contains(\"Delivered and not settled\", na=False)]\n",
    "        journal = journal[~journal[\"TransactionEntered\"].str.contains(\"Grain Inventory Receivable Adjustment\", na=False)]\n",
    "        # combining tables\n",
    "        print(\"Combining Fact Tables ...\")\n",
    "        invoice = invoice.loc[:,[col for col in cols if col in invoice.columns]]\n",
    "        sales = sales.loc[:,[col for col in cols if col in sales.columns]]\n",
    "        journal = journal.loc[:,[col for col in cols if col in journal.columns]]\n",
    "        facts = pd.concat([invoice, sales, journal], ignore_index=True)\n",
    "        del invoice, sales, journal\n",
    "        # join facts with dimension tables\n",
    "        facts = pd.merge(facts, account.loc[:,[\"AccID\",\"AccNum\",\"AccName\",\"Category\",\"Subcategory\"]], on=[\"AccID\"], how=\"left\")\n",
    "        facts = pd.merge(facts, farm.loc[:,[\"FarmID\",\"FarmName\"]], on=[\"FarmID\"], how=\"left\")\n",
    "        facts = pd.merge(facts, customer.loc[:,[\"CustomerID\",\"CustomerName\"]], on=[\"CustomerID\"], how=\"left\")\n",
    "        facts = facts[facts[\"Subcategory\"]==\"Grain - cash settlements\"]\n",
    "        print(f\"Total Fact Entries - {len(facts)}\")\n",
    "        # product column\n",
    "        facts[\"Product\"] = facts[\"AccName\"].apply(lambda x: self._temp_get_product(x))\n",
    "        # saving file\n",
    "        print(\"Saving Files ...\")\n",
    "        self.check_file(self.gold_path[\"inventory\"])\n",
    "        facts.to_excel(self.gold_path[\"inventory\"]/\"Excel\"/\"QBO_Grain_Settlements.xlsx\", sheet_name=\"settlement\", index=False)\n",
    "        print(\"Finished\\n\")\n",
    "\n",
    "    def _create_budget(self) -> None:\n",
    "        \"\"\" \n",
    "            In Progress: this function generates budgets\n",
    "        \"\"\"\n",
    "        if not self.pl_exist:\n",
    "            self._finance_operational()\n",
    "        inputdata_path = self.gold_path[\"budget\"] / \"Outside Data\"\n",
    "        processed_path = self.gold_path[\"budget\"] / \"Processed Data\"\n",
    "        rule_path = self.gold_path[\"budget\"] / \"Budget Rules\"\n",
    "        # define helper function to process produce \n",
    "        def _process_produce(budget_rules:pd.DataFrame,budget:pd.DataFrame,sheetname:str):\n",
    "            budget_rules = budget_rules[budget_rules[\"SheetRef\"] == sheetname].copy(deep=True)\n",
    "            budget_rules[\"Commodity\"] = budget_rules.apply(lambda x: self._identify_product(x,for_budget=True), axis=1)\n",
    "            budget[\"Type\"] = budget[\"Type\"].str.strip()\n",
    "            # gross income - by commodity\n",
    "            reference = budget[budget[\"Type\"].isin([\"Acres\",\"Unit Price\",\"YieldPerAc\"])]\n",
    "            reference = reference.groupby([\"Commodity\",\"ProfitType\",\"CommodityRaw\"]).agg({\"AmountCAD\":\"prod\"}).reset_index(drop=False)\n",
    "            reference = reference.groupby([\"Commodity\"]).agg({\"AmountCAD\":\"sum\"}).reset_index(drop=False)\n",
    "            reference = reference.rename(columns={\"AmountCAD\":\"TotalAmountCAD\"})\n",
    "            reference[\"Category\"] = \"Produce - production\"\n",
    "            if \"outlook\" in sheetname.lower():\n",
    "                for item in [\"Prairie Pathways\", \"Market Garden / CSA\"]:\n",
    "                    reference.loc[reference[\"Commodity\"] == item, \"Category\"] = \"Produce - cash settlements\"\n",
    "            # seed expense - by commodity\n",
    "            expense = budget[budget[\"Type\"] == \"Seed\"].copy(deep=True)\n",
    "            expense = expense.drop(columns=\"CommodityRaw\")\n",
    "            expense = expense.groupby([\"Commodity\"]).agg({\"AmountCAD\":\"sum\"}).reset_index(drop=False).rename(columns={\"AmountCAD\":\"TotalAmountCAD\"})\n",
    "            expense[\"Category\"] = \"Seed\"\n",
    "            # other expense - Fertilizer/Chemical - not by commodity\n",
    "            expense2 = budget[budget[\"Type\"].isin([\"Fertilizer\",\"Chemical\"])]\n",
    "            expense2 = expense2.groupby([\"Type\"]).agg({\"AmountCAD\":\"sum\"}).reset_index(drop=False).rename(columns={\"AmountCAD\":\"TotalAmountCAD\"})\n",
    "            expense2[\"Commodity\"] = \"Others\"\n",
    "            expense2 = expense2.rename(columns={\"Type\":\"Category\"})\n",
    "            # combine\n",
    "            budget_produce = pd.merge(budget_rules, pd.concat([reference,expense, expense2]), on=[\"Commodity\",\"Category\"], how=\"left\")\n",
    "            budget_produce = budget_produce.fillna(value={\"TotalAmountCAD\":0})\n",
    "            budget_produce[\"AmountCAD\"] = budget_produce.apply(lambda x: eval(f\"{x[\"TotalAmountCAD\"]}{x[\"Formula\"]}\"),axis=1)\n",
    "            return budget_produce\n",
    "        # actuals\n",
    "        transactions = self.gold_pl.copy(deep=True)\n",
    "        transactions = transactions[transactions[\"FiscalYear\"] >= 2024]\n",
    "        transactions[\"AccName\"] = transactions[\"AccName\"].str.strip()\n",
    "        transactions_location_rename = {\"Calderbank\":\"Calderbank (cattle)\"}\n",
    "        transactions[\"Location\"] = transactions[\"Location\"].replace(transactions_location_rename)\n",
    "        # processing input sheets data\n",
    "        ## commodity prices - everything is CAD except Winter Wheat is converted to USD\n",
    "        pricing = pd.read_csv(inputdata_path/\"25-Grain-Pricing.csv\")\n",
    "        pricing.loc[pricing[\"Commodity\"]==\"WW\", \"ForecastPrice\"] *= self.fx\n",
    "        ## production budget\n",
    "        budget_production = pd.read_csv(inputdata_path/\"25-Grain-Revenue.csv\")\n",
    "        budget_production = budget_production.melt(\n",
    "            id_vars=[\"Location\", \"Currency\", \"Type\"],\n",
    "            var_name=\"Commodity\",\n",
    "            value_name = \"Amount\"\n",
    "        )\n",
    "        budget_production = budget_production.fillna(value = {\"Amount\": 0})\n",
    "        budget_production[\"Commodity\"] = budget_production[\"Commodity\"].replace({\"Hay/Silage\":\"Hay\"})\n",
    "        budget_production.loc[((budget_production[\"Location\"]==\"Airdrie\")&(budget_production[\"Commodity\"]==\"Hay\")), \"Commodity\"] = \"Silage\" # only Airdrie has silage, others have hay\n",
    "        budget_production_summary = pd.DataFrame(budget_production.groupby([\"Location\",\"Currency\",\"Commodity\"]).agg({\"Amount\": \"prod\"})).reset_index(drop=False)\n",
    "        budget_production_summary = budget_production_summary.rename(columns={\"Amount\":\"TotalYield\"})\n",
    "        ### merge yield with commodity price to calculate forecast production value of commodities\n",
    "        budget_production_summary = pd.merge(budget_production_summary,pricing,on=[\"Commodity\"], how=\"left\")\n",
    "        ### manual adjustments to prices\n",
    "        budget_production_summary.loc[((budget_production_summary[\"Location\"] == \"Airdrie\") & (budget_production_summary[\"Commodity\"] == \"Hay\")), \"ForecastPrice\"] = 85\n",
    "        budget_production_summary.loc[((budget_production_summary[\"Location\"] == \"Colorado (Genoa)\") & (budget_production_summary[\"Commodity\"] == \"WW\")), \"ForecastPrice\"] = 13.75\n",
    "        budget_production_summary.loc[budget_production_summary[\"Location\"] == \"Yorkton\", \"ForecastPrice\"] *= 2/3\n",
    "        budget_production_summary[\"ForecastProductionCAD\"] = budget_production_summary[\"TotalYield\"] * budget_production_summary[\"ForecastPrice\"]\n",
    "        budget_production_summary = budget_production_summary[budget_production_summary[\"ForecastProductionCAD\"].notna()]\n",
    "        budget_production_summary = budget_production_summary[budget_production_summary[\"ForecastProductionCAD\"]!=0]\n",
    "        ### convert prices back to USD for a adjusted column\n",
    "        budget_production_summary[\"ForecastProductionAdj\"] = budget_production_summary.apply(lambda x: x[\"ForecastProductionCAD\"] / self.fx if x[\"Currency\"] == \"USD\" else x[\"ForecastProductionCAD\"],axis=1)\n",
    "        ### save production budget\n",
    "        budget_production_summary.to_csv(processed_path/\"budget_production.csv\",index=False)\n",
    "        ## input budget\n",
    "        input_budget = pd.read_csv(inputdata_path/\"25-Input-Budget.csv\")\n",
    "        input_budget = input_budget.drop(columns=[\"Total acres\"])\n",
    "        input_budget = input_budget.melt(\n",
    "            id_vars = [\"Location\", \"Type\"],\n",
    "            var_name = \"Commodity\",\n",
    "            value_name = \"Amount\"\n",
    "        )\n",
    "        input_budget = input_budget.fillna(value = {\"Amount\": 0})\n",
    "        input_budget.loc[((input_budget[\"Location\"]==\"Yorkton\")&(input_budget[\"Type\"].isin([\"Fertilizer\",\"Chemical\",\"Seed\"]))), \"Amount\"] *= 2/3\n",
    "        input_budget.to_csv(processed_path/\"input_budget.csv\",index=False)\n",
    "        ## labour budget\n",
    "        labour_budget = pd.read_csv(inputdata_path/\"25-Labour-Budget.csv\")\n",
    "        labour_budget = labour_budget.melt(\n",
    "            id_vars = [\"Location\",\"Currency\"],\n",
    "            var_name = \"Month\",\n",
    "            value_name = \"LabourBudgetCAD\"\n",
    "        )\n",
    "        labour_budget[\"LabourBudgetAdj\"] = labour_budget.apply(lambda x: x[\"LabourBudgetCAD\"]/fx if x[\"Currency\"]==\"USD\" else x[\"LabourBudgetCAD\"], axis=1)\n",
    "        labour_budget.to_csv(processed_path/\"labour_budget.csv\",index=False)\n",
    "        ## outlook budget\n",
    "        outlook = pd.read_csv(inputdata_path/\"25-Outlook-Detail.csv\")\n",
    "        outlook = outlook.melt(\n",
    "            id_vars=[\"Type\", \"ProfitType\"],\n",
    "            var_name=\"Commodity\",\n",
    "            value_name=\"Amount\"\n",
    "        )\n",
    "        outlook = outlook.fillna(value={\"Amount\": 0})\n",
    "        outlook.to_csv(processed_path/\"outlook_budget.csv\", index=False)\n",
    "        ## AZ budget\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "    def _budget_update(self) -> None:\n",
    "        \"\"\" \n",
    "            generate/update the actuals from the budget system\n",
    "        \"\"\"\n",
    "        if not self.pl_exist:\n",
    "            self._finance_operational()\n",
    "        \n",
    "\n",
    "    def run(self) -> None:\n",
    "        start = perf_counter()\n",
    "\n",
    "        self._weekly_banking()\n",
    "        self._finance_operational()\n",
    "        self._process_units()\n",
    "        self._payroll_project()\n",
    "        self._QBOTime_project()\n",
    "        self._raw_inventory()\n",
    "\n",
    "        end = perf_counter()\n",
    "        print(f\"\\nProjects Transformation Finished with {(end-start)/60:.3f} minutes\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb7e23c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = Projects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c92d352c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Weekly Banking Project Transformation\n",
      "\n",
      "None Match Transaction Types\n",
      "TxnType\n",
      "Sales Tax Payment    9\n",
      "Journal Entry        8\n",
      "BillPaymentCheck     1\n",
      "Name: count, dtype: int64\n",
      "Non matches - 18\n",
      "\n",
      "Starting Finance Operational Project Transformation\n",
      "\n",
      "location unaccounted for - [nan]\n",
      "Revising Signs ...\n",
      "Saving ...\n",
      "\n",
      "Starting Payroll Project Transformation\n",
      "\n",
      "Allocating PPNum for transactions ...\n",
      "Summarizing ...\n",
      "Unaccounted location for Acres Doc: {'Seeds USA', 'Airdrie (grain)'}\n",
      "Saving ...\n",
      "\n",
      "Starting QBO Time Project Transformation\n",
      "\n",
      "Read 94238 timesheet records, 92 jobcodes, 661 users, 35 groups\n",
      "Allocating PPNum for transactions ...\n",
      "Unaccounted location for Acres Doc: {'Seeds USA', 'Eddystone (cattle)', 'Corporate', 'Airdrie (grain)', 'Eddystone (grain)', 'Camp 4', 'Fly Creek'}\n",
      "Unaccounted location for timesheets: {'Eddystone (unspecified)', 'Unassigned'}\n",
      "Saving ...\n",
      "\n",
      "\n",
      "Starting Inventory Project Transformation ...\n",
      "\n",
      "Loading raw tables ...\n",
      "Combining Fact Tables ...\n",
      "Total Fact Entries - 1455\n",
      "Saving Files ...\n",
      "Finished\n",
      "\n",
      "\n",
      "Projects Transformation Finished with 2.996 minutes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "project.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "16f3735b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting QBO Time Project Transformation\n",
      "\n",
      "Read 94238 timesheet records, 92 jobcodes, 661 users, 35 groups\n",
      "Allocating PPNum for transactions ...\n",
      "Unaccounted location for Acres Doc: {'Eddystone (cattle)', 'Eddystone (grain)', 'Corporate', 'Airdrie (grain)', 'Airdrie (cattle)', 'Fly Creek', 'Camp 4'}\n",
      "Unaccounted location for timesheets: {'Unassigned', 'Airdrie (unspecified)', 'Arizona (grain)', 'Eddystone (unspecified)'}\n",
      "Saving ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "project._QBOTime_project()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9814fadd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3486783a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3300668c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0771700b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e67ab75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96b364f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed76f4f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5423c17f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736055b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babc2f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
