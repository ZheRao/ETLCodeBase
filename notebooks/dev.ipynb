{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b27fdfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path \n",
    "import os\n",
    "import datetime as dt\n",
    "import requests\n",
    "import json\n",
    "from intuitlib.client import AuthClient\n",
    "import urllib.parse\n",
    "from time import perf_counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8a0cc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Job:\n",
    "    def __init__(self):\n",
    "        base_dir = Path(\"c:/Users/ZheRao/OneDrive - Monette Farms/Monette Farms Team Site - Innovation Projects/Production/Database\")\n",
    "        self.base_dir = base_dir\n",
    "        self.today = dt.date.today()\n",
    "        month_format = \"\".join([\"0\",str(self.today.month)]) if self.today.month < 10 else str(self.today.month)\n",
    "        self.us_companies = [\"MFUSA\", \"MFAZ\", \"MSUSA\", \"MPUSA\"]\n",
    "        self.company_names = self.us_companies + [\"MSL\", \"NexGen\", \"MFBC\", \"MPL\", \"MFL\"]\n",
    "        self.raw_path = {\n",
    "            \"QBO\": {\n",
    "                \"Raw\": base_dir/\"Bronze\"/\"QBO\"/\"Raw\"/f\"{self.today.year}_{self.today.month}\",\n",
    "                \"GL\": base_dir/\"Bronze\"/\"QBO\"/\"GeneralLedger\",\n",
    "                \"PL\": base_dir/\"Bronze\"/\"QBO\"/\"ProfitAndLoss\",\n",
    "                \"Time\":base_dir/\"Bronze\"/\"QBOTime\"\n",
    "            },\n",
    "            \"Delivery\": {\"Traction\":base_dir/\"Bronze\"/\"Traction\", \"HP\":base_dir/\"Bronze\"/\"HarvestProfit\"},\n",
    "            \"Auth\": {\"QBO\":base_dir/\"Bronze\"/\"Authentication\"/\"QBO\", \"QBOTime\": base_dir/\"Bronze\"/\"Authentication\"/\"QBOTime\"},\n",
    "            \"Log\": base_dir/\"Load_History\"/f\"{self.today.year}\"/month_format\n",
    "        }\n",
    "        self.silver_path = {\n",
    "            \"QBO\": {\n",
    "                \"Dimension_time\": base_dir/\"Silver\"/\"QBO\"/\"Dimension\"/f\"{self.today.year}_{self.today.month}\",\n",
    "                \"Dimension\": base_dir/\"Silver\"/\"QBO\"/\"Dimension\",\n",
    "                \"Raw\": base_dir/\"Silver\"/\"QBO\"/\"Fact\"/\"Raw\",\n",
    "                \"PL\": base_dir/\"Silver\"/\"QBO\"/\"Fact\"/\"ProfitAndLoss\",\n",
    "                \"GL\": base_dir/\"Silver\"/\"QBO\"/\"Fact\"/\"GeneralLedger\",\n",
    "                \"Time\": base_dir/\"Silver\"/\"QBOTime\"\n",
    "            },\n",
    "            \"Delivery\": {\"Traction\":base_dir/\"Silver\"/\"Traction\", \"HP\":base_dir/\"Silver\"/\"HarvestProfit\"}\n",
    "        }\n",
    "        \n",
    "    \n",
    "    def get_fx(self):\n",
    "        key  = os.getenv(\"ALPHAVANTAGE_KEY\")\n",
    "        url  = (\"https://www.alphavantage.co/query?\"\n",
    "                \"function=CURRENCY_EXCHANGE_RATE\"\n",
    "                \"&from_currency=USD&to_currency=CAD\"\n",
    "                f\"&apikey={key}\")\n",
    "        rate = float(requests.get(url, timeout=10).json()\n",
    "                    [\"Realtime Currency Exchange Rate\"][\"5. Exchange Rate\"])\n",
    "        self.fx = rate\n",
    "    \n",
    "    def create_log(self, path: Path) -> None:\n",
    "        self.check_file(path)\n",
    "        day_format = \"\".join([\"0\",str(self.today.day)]) if self.today.day < 10 else str(self.today.day)\n",
    "        self.log = open(path/(day_format+\"_Log.txt\"), \"a\")\n",
    "\n",
    "    \n",
    "    def close_log(self):\n",
    "        self.log.close()\n",
    "\n",
    "    def check_file(self, path: Path) -> None:\n",
    "        if not Path.exists(path):\n",
    "            os.makedirs(path)\n",
    "    \n",
    "    def formulate_date(self, df:pd.DataFrame, date_cols:list[str], drop_time:bool=True) -> pd.DataFrame:\n",
    "        \"\"\" \n",
    "            format the date columns into datetime format\n",
    "        \"\"\"\n",
    "        assert len(set(date_cols) - set(df.columns)) == 0, \"Not all columns passed are inside dataframe passed\"\n",
    "        for col in date_cols:\n",
    "            df[col] = pd.to_datetime(df[col], utc=True)\n",
    "            if drop_time: df[col] = df[col].dt.date\n",
    "        return df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5e5eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Projects(Job):\n",
    "    \"\"\" \n",
    "        for project specific data transformations\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, focus_last_FY:bool = False):\n",
    "        super().__init__()\n",
    "        self.gold_path = {\n",
    "            \"weekly_banking\": self.base_dir / \"Gold\" / \"FinanceProject\" / \"WeeklyBanking\",\n",
    "            \"inventory\": self.base_dir / \"Gold\" / \"InventoryProject\",\n",
    "            \"payroll\": self.base_dir / \"Gold\" / \"HRProject\" /\"PayrollProject\",\n",
    "            \"finance_operational\": self.base_dir / \"Gold\" / \"FinanceOperationalProject\",\n",
    "            \"budget\": self.base_dir / \"Gold\" / \"BudgetProject\",\n",
    "            \"QBOTime\": self.base_dir / \"Gold\" / \"HRProject\" / \"QBOTimeProject\",\n",
    "            \"hr_combined\": self.base_dir / \"Gold\" / \"HRProject\" / \"CombinedSummary\"\n",
    "        }\n",
    "        self.silver_acc = pd.read_csv(self.silver_path[\"QBO\"][\"Dimension_time\"]/\"Account.csv\")\n",
    "        self.commodities = {\n",
    "            \"Produce\": [\"Strawberry\", \"Watermelon\", \"Cantaloupe\", \"Market Garden\", \"Broccoli\", \"Pumpkin\", \"Sweet Corn\", \"Cauliflower\", \"Squash\", \"Honeydew Melon\", \"Potato\", \"Carrot\", \"Cabbage\",\n",
    "                        \"Lettuce\", \"Brussel Sprouts\", \"Prairie Pathways\", \"Beet\", \"Corn Maze\", \"CSA\"],\n",
    "            \"Grain\": [\"Blackeye Pea\", \"Winter Wheat\", \"Durum\", \"Cotton\", \"Chickpea\", \"Barley\", \"Green Lentil\", \"Red Lentil\", \"Canola\", \n",
    "                        \"Wheat\",\"Field Pea\", \"Corn\", \"Oat\", \"Soybean\", \"Bean\"],\n",
    "            \"Cattle\": [\"Weaned Calves\", \"Cull Bull\", \"Cull Cow\", \"Bred Heifer\", \"Purebred Yealing Bull\", \"Purebred Heifer\", \n",
    "                        \"Purebred Cow\", \"Purebred Bull\", \"Cow\", \"Bull\", \"Steer\", \"Heifer\", \"Yearling\", \"Calf\"]\n",
    "        }\n",
    "        self.locations = {\n",
    "            \"Produce\": [\"BritishColumbia (produce)\", \"Outlook\", \"Arizona (produce)\"],\n",
    "            \"Cattle\": [\"Airdrie\", \"Eddystone (cattle)\", \"Ashcroft\", \"Home Ranch\", \"Diamond S\", \"Wolf Ranch\", \"Fraser River Ranch\", \"Moon Ranch\", \"Waldeck\", \"Calderbank\"],\n",
    "            \"Grain\": [\"Eddystone (grain)\", \"Arizona (grain)\", \"Colorado\", \"Swift Current\", \"Regina\", \"Raymore\", \"Prince Albert\", \"The Pas\",\n",
    "                      \"Kamsack\", \"Hafford\", \"Yorkton\", \"Fly Creek\", \"Camp 4\", \"Havre\", \"Billings\"],\n",
    "            \"Seed\": [\"NexGen\", \"Seeds\", \"Seeds USA\"],\n",
    "            \"Others\": [\"Eddystone (corporate)\", \"Arizona (corporate)\", \"Legacy\", \"BritishColumbia (corporate)\", \"-Corporate\"]\n",
    "        }\n",
    "        self.bc_ranches = [\"Ashcroft\", \"Fraser River Ranch\", \"Moon Ranch\", \"Wolf Ranch\", \"Home\", \"Diamond S\", \"BritishColumbia (corporate)\",\"Home Ranch\"]\n",
    "        self.pl_exist = False # determines whether _financial_operational has run and gold_pl is stored in self, if not, any subsequent downstream projects will run _financial_operational first\n",
    "        self.currentFY = self.today.year if self.today.month<=10 else self.today.year + 1\n",
    "        if focus_last_FY: self.currentFY -= 1\n",
    "\n",
    "    def _pillar_classification(self, entry: pd.Series) -> str:\n",
    "        \"\"\" \n",
    "            this function classifies pillar of a transaction based on location\n",
    "        \"\"\"\n",
    "        location = entry[\"Location\"]\n",
    "        if not isinstance(location, str):\n",
    "            return \"Missing\"\n",
    "        if \"produce\" in location:\n",
    "            return \"Produce\"\n",
    "        elif \"grain\" in location:\n",
    "            return \"Grain\"\n",
    "        elif \"cattle\" in location:\n",
    "            return \"Cattle\"\n",
    "        elif \"corporate\" in location:\n",
    "            return \"Unclassified\"\n",
    "        match location.lower():\n",
    "            case \"hafford\"|\"kamsack\"|\"prince albert\"|\"raymore\"|\"regina\"|\"swift current\"|\"the pas\"|\"camp 4\"|\"fly creek\"|\"havre\"|\"yorkton\"|\"colorado\"|\"billings\":\n",
    "                return \"Grain\"\n",
    "            case \"outlook\"|\"seeds usa\":\n",
    "                return \"Produce\"\n",
    "            case \"ashcroft\"|\"diamond s\"|\"fraser river ranch\"|\"home ranch\"|\"moon ranch\"|\"wolf ranch\"|\"waldeck\"|\"calderbank\"|\"airdrie\":\n",
    "                return \"Cattle\"\n",
    "            case \"seeds\"|\"nexgen\":\n",
    "                return \"Seed\"\n",
    "            case _:\n",
    "                return \"Unclassified\"\n",
    "    \n",
    "    def _identify_product(self, entry: pd.Series, for_budget:bool=False) -> str:\n",
    "        \"\"\" \n",
    "            this function identifies commodity from account names, except for seed, \n",
    "                if this function is called from budget project, it combines MG & CSA and take CM into consideration, and name forage differently\n",
    "        \"\"\"\n",
    "        if not for_budget:\n",
    "            if entry[\"AccPillar\"] == \"Seed\":\n",
    "                return \"SeedProduct\"\n",
    "        accname = entry[\"AccountName\"].lower() if not for_budget else entry[\"AccFull\"].lower()\n",
    "        if \"float\" in accname:\n",
    "            return \"Others\"\n",
    "        for x in self.commodities[\"Produce\"] + self.commodities[\"Grain\"] + self.commodities[\"Cattle\"]:\n",
    "            if x.lower() in accname:\n",
    "                if for_budget:\n",
    "                    match x:\n",
    "                        case \"Market Garden\"|\"CSA\":\n",
    "                            return \"Market Garden / CSA\"\n",
    "                        case \"Corn Maze\":\n",
    "                            return \"Prairie Pathways\"\n",
    "                    return x \n",
    "        if \"straw\" in accname or \"forage\" in accname or \"hay bale\" in accname:\n",
    "            if for_budget: \n",
    "                return \"Hay/Silage\" \n",
    "            else: \n",
    "                return \"Forage\"\n",
    "        return \"Others\"\n",
    "    \n",
    "    def _weekly_banking(self) -> None:\n",
    "        \"\"\" \n",
    "            weekly banking project: match latest GL bank transactions with raw activities - extract accounts for those activities\n",
    "                assumptions: a raw entry (e.g., invoice) can have multiple lines - multiple associated accounts, only considering the first one \n",
    "        \"\"\"\n",
    "        print(\"\\nStarting Weekly Banking Project Transformation\\n\")\n",
    "        # determine minal date to keep for GL\n",
    "        if self.today.month > 6:\n",
    "            year = self.today.year \n",
    "            month = self.today.month - 6 \n",
    "        else:\n",
    "            year = self.today.year - 1\n",
    "            month = self.today.month + 12 - 6\n",
    "        # load and prepare data\n",
    "        ## account\n",
    "        account = self.silver_acc.copy(deep=True)\n",
    "        ## change some accounts to Transfer category\n",
    "        acc_list = [\"MFL264\", \"MSL250\"]\n",
    "        account.loc[account[\"AccID\"].isin(acc_list), \"Profitem\"] = \"Asset\"\n",
    "        account.loc[account[\"AccID\"].isin(acc_list), \"Category\"] = \"Transfer\"\n",
    "        account_bank = account[account[\"AccountType\"]==\"Bank\"]\n",
    "        ## LinkedTxn for invoice and bill\n",
    "        invoice_linked = pd.read_csv(self.silver_path[\"QBO\"][\"Raw\"] / \"LinkedTxn\"/ \"LinkedTxn_Mapping_Invoice.csv\")\n",
    "        bill_linked = pd.read_csv(self.silver_path[\"QBO\"][\"Raw\"] / \"LinkedTxn\"/ \"LinkedTxn_Mapping_Bill.csv\")\n",
    "        mapping = pd.concat([invoice_linked, bill_linked])\n",
    "        mapping = mapping.drop(columns=[\"Corp\"])\n",
    "        # define customized function for processing other raw table\n",
    "        def _process_facts(df_type:str) -> pd.DataFrame:\n",
    "            \"\"\" \n",
    "                function for processing raw tables for mapping table - TransactionID_partial to AccID\n",
    "            \"\"\"\n",
    "            df = pd.read_csv(self.silver_path[\"QBO\"][\"Raw\"]/(df_type+\".csv\"), usecols = [\"TransactionID\", \"AccID\"])\n",
    "            df[\"TransactionID\"] = df[\"TransactionID\"].apply(lambda x: x.split(\"-\")[1])\n",
    "            df = df.drop_duplicates()\n",
    "            df = df.rename(columns={\"TransactionID\":\"TxnId\"})\n",
    "            return df\n",
    "        ## purchase table for expense transactions\n",
    "        purchase = _process_facts(\"Purchase\")\n",
    "        purchase[\"TxnType\"] = \"Expense\"\n",
    "        mapping = pd.concat([mapping,purchase])\n",
    "        ## journal entries - exclude most entries related to bank\n",
    "        journal = _process_facts(\"JournalEntry\")\n",
    "        journal[\"TxnType\"] = \"Journal Entry\"\n",
    "        # for journal entries, exclude most of entires where the activity account ID is a bank ID\n",
    "        exclude_list = list(account_bank.AccID.unique())\n",
    "        # mylist = [\"MFL51\", \"MFBC470\", \"MFBC471\", \"MFL28\", \"MFL27\", \"MFL1150040024\"]\n",
    "        mylist = [\"MFBC470\", \"MFBC471\"] # should include these accounts\n",
    "        for acc in mylist:\n",
    "            exclude_list.remove(acc)\n",
    "        journal = journal[~journal[\"AccID\"].isin(exclude_list)]\n",
    "        mapping = pd.concat([mapping,journal])\n",
    "        ## deposit\n",
    "        deposit = _process_facts(\"Deposit\")\n",
    "        deposit[\"TxnType\"] = \"Deposit\"\n",
    "        mapping = pd.concat([mapping,deposit])\n",
    "        ## salesreceipts\n",
    "        sales = _process_facts(\"SalesReceipt\")\n",
    "        sales[\"TxnType\"] = \"Sales Receipt\"\n",
    "        mapping = pd.concat([mapping,sales])\n",
    "        # process mapping table - dedup\n",
    "        mapping = mapping.drop_duplicates(subset=[\"TxnId\"],keep=\"first\")\n",
    "        ## load GL transacitons\n",
    "        cols = [\"TransactionType\",\"TransactionID_partial\",\"AccID\",\"AccNum\",\"AccName\", \"TransactionDate\", \"Amount\", \"SplitAcc\", \"SplitAccID\", \"Memo\", \"Corp\", \"Balance\"]\n",
    "        transactions = pd.read_csv(self.silver_path[\"QBO\"][\"GL\"]/\"GeneralLedger.csv\",dtype={\"TransactionID_partial\":str}, usecols=cols)\n",
    "        transactions = transactions[transactions[\"AccID\"].isin(account_bank.AccID.unique())]\n",
    "        transactions[\"TransactionDate\"] = pd.to_datetime(transactions[\"TransactionDate\"])\n",
    "        transactions = transactions[transactions[\"TransactionDate\"]>=dt.datetime(year, month, 1)]\n",
    "        transactions = transactions.rename(columns={\"TransactionType\":\"TxnType\",\"TransactionID_partial\":\"TxnId\",\n",
    "                                                    \"AccID\":\"BankAccID\",\"AccNum\":\"BankAccNum\",\"AccName\":\"BankAccName\",\n",
    "                                                    \"TransactionDate\":\"BankActivityDate\",\"Amount\":\"BankAmount\"})\n",
    "        # merge to get CurrencyID for bank_acc\n",
    "        transactions = pd.merge(transactions, account_bank.loc[:,[\"AccID\",\"CurrencyID\"]], left_on=[\"BankAccID\"], right_on=[\"AccID\"], how=\"left\")\n",
    "        transactions = transactions.drop(columns=[\"AccID\"])\n",
    "        # separating transfers - don't merge with mapping table\n",
    "        transfers = transactions[transactions[\"TxnType\"] == \"Transfer\"].copy(deep=True)\n",
    "        transactions = transactions[transactions[\"TxnType\"]!=\"Transfer\"]\n",
    "        transactions = transactions.drop(columns=[\"SplitAcc\", \"SplitAccID\"])\n",
    "        transactions[\"BankActivityDate\"] = pd.to_datetime(transactions[\"BankActivityDate\"])\n",
    "        transactions[\"TxnType\"] = transactions[\"TxnType\"].replace({\"Cheque Expense\":\"Expense\", \"Check\": \"Expense\"})\n",
    "        # merge with mapping table\n",
    "        transactions_mapped = pd.merge(transactions,mapping,on=[\"TxnId\",\"TxnType\"],how=\"left\")\n",
    "        non_match = transactions_mapped[transactions_mapped[\"AccID\"].isna()]\n",
    "        print(\"None Match Transaction Types\")\n",
    "        print(non_match.TxnType.value_counts())\n",
    "        print(f\"Non matches - {len(non_match)}\")\n",
    "        # function to determine transfer type\n",
    "        def _determine_transfer_type(entry:str) -> str:\n",
    "            \"\"\" \n",
    "                determine whether the transfer is for visa, bank, or other transfer\n",
    "            \"\"\"\n",
    "            if \"visa\" in entry.lower():\n",
    "                return \"Visa Payment\"\n",
    "            elif \"due\" in entry.lower():\n",
    "                return \"Bank Transfer\"\n",
    "            else:\n",
    "                return \"Other Transfer\"\n",
    "        # allocate transfer type \n",
    "        transfers[\"TransferType\"] = transfers[\"SplitAcc\"].apply(lambda x: _determine_transfer_type(x))\n",
    "        transfers = transfers.rename(columns={\"SplitAccID\":\"AccID\"})\n",
    "        transfers = transfers.drop(columns=[\"SplitAcc\"])\n",
    "        transactions_mapped = pd.concat([transactions_mapped,transfers], ignore_index=True)\n",
    "        # clean up the dataframe\n",
    "        transactions_mapped = transactions_mapped.rename(columns={\"CurrencyID\":\"BankCurrencyID\"})\n",
    "        transactions_mapped = pd.merge(transactions_mapped, account.loc[:,[\"AccID\",\"AccName\",\"AccNum\",\"Category\",\"Profitem\",\"CurrencyID\"]], on=\"AccID\", how=\"left\")\n",
    "        transactions_mapped.loc[transactions_mapped[\"TransferType\"]==\"Bank Transfer\",\"Category\"] = \"Bank Transfer\"\n",
    "        transactions_mapped.loc[((transactions_mapped[\"BankAccNum\"].str.startswith(\"MSL\"))&(transactions_mapped[\"AccNum\"]==\"MSL120001\")), \"Category\"] = \"Seed Processing Revenue\"\n",
    "        transactions_mapped = transactions_mapped.rename(columns={\"AccNum\":\"ActivityAccNum\", \"AccName\":\"ActivityAccName\"})\n",
    "        # csv from sharepoint is unstable, and produced unpredictable readings from Power BI\n",
    "        self.check_file(self.gold_path[\"weekly_banking\"])\n",
    "        transactions_mapped.to_excel(self.gold_path[\"weekly_banking\"]/\"BankingActivity.xlsx\", sheet_name=\"transactions\", index=False)\n",
    "\n",
    "    def _finance_operational(self) -> None:\n",
    "        \"\"\" \n",
    "            transform PL data into operational-ready\n",
    "                1. reclassify accounts\n",
    "                2. standardize location, classify pillar\n",
    "                3. revising signs\n",
    "        \"\"\"\n",
    "        print(\"\\nStarting Finance Operational Project Transformation\\n\")\n",
    "        # load data from silver space\n",
    "        data = pd.read_csv(self.silver_path[\"QBO\"][\"PL\"]/\"ProfitAndLoss.csv\")\n",
    "        assert len(data.FXRate.value_counts()) == 1, \"different FXRate detected\"\n",
    "        self.fx = data.loc[0,\"FXRate\"]\n",
    "        data[\"TransactionDate\"] = pd.to_datetime(data[\"TransactionDate\"])\n",
    "        data[\"FiscalYear\"] = data.TransactionDate.apply(lambda x: x.year + 1 if x.month >= 11 else x.year)\n",
    "        # add month to the PL\n",
    "        data[\"Month\"] = data[\"TransactionDate\"].dt.month_name()\n",
    "        ## add location for seed operation\n",
    "        data.loc[data[\"Corp\"]==\"MSL\",\"Location\"] = \"Seeds\"\n",
    "        data.loc[data[\"Corp\"]==\"NexGen\",\"Location\"] = \"NexGen\"\n",
    "        data.loc[data[\"Corp\"]==\"MSUSA\",\"Location\"] = \"Seeds USA\"\n",
    "        # clean location\n",
    "        data = data.rename(columns={\"Location\":\"LocationRaw\"})\n",
    "        data[\"Location\"] = data[\"LocationRaw\"]\n",
    "        # switch seeds usa to AZ produce\n",
    "        data.loc[data[\"Corp\"]==\"MSUSA\",\"Location\"] = \"Arizona (produce)\"\n",
    "        ## clean location\n",
    "        clean_location = {\"Airdrie - Grain\":\"Airdrie\", \"Airdrie - Cattle\":\"Airdrie\", \"Airdrie - General\":\"Airdrie\", \"Airdrie\":\"Airdrie\", \n",
    "                        \"Eddystone - Grain\": \"Eddystone (grain)\", \"Eddystone - Cattle\": \"Eddystone (cattle)\", \"Eddystone - General\":\"Eddystone (corporate)\",\n",
    "                        \"Outlook (JV)\":\"Outlook\", \"AZ Produce\":\"Arizona (produce)\", \"Corporate\":\"Arizona (corporate)\", \"BC Produce\":\"BritishColumbia (produce)\",\n",
    "                        \"Grain\":\"Arizona (grain)\", \"Cache/Fischer/Loon - DNU\":\"Legacy\", \"Ashcroft (CC, Fischer, Loon)\":\"Ashcroft\", \n",
    "                        \"Outlook (Capital)\":\"Outlook\", \"Colorado (MF)\":\"Colorado\", \"Colorado (JV)\":\"Colorado\", \"Cattle - General\":\"BritishColumbia (corporate)\",\n",
    "                        \"Home (70 M, LF/W, 105 M)\":\"Home Ranch\", \"Diamond S (BR)\":\"Diamond S\", \"North Farm (deleted)\":\"Legacy\"}\n",
    "        data[\"Location\"] = data[\"Location\"].replace(clean_location)\n",
    "        locations = self.locations[\"Produce\"] + self.locations[\"Grain\"] + self.locations[\"Cattle\"] + self.locations[\"Others\"] + self.locations[\"Seed\"]\n",
    "        unaccounted_location = list(set(data[\"Location\"].unique()) - set(locations))\n",
    "        print(f\"location unaccounted for - {unaccounted_location}\")\n",
    "        # classify pillar\n",
    "        data[\"Pillar\"] = data.apply(lambda x: self._pillar_classification(x),axis=1)\n",
    "        # reorganize corp\n",
    "        ## MPUSA missing location = Arizona (produce)\n",
    "        data.loc[((data[\"Corp\"] == \"MPUSA\")&(data[\"Location\"].isna())), \"Location\"] = \"Arizona (produce)\"\n",
    "        data.loc[((data[\"Corp\"] == \"MPUSA\")&(data[\"Location\"] == \"Arizona (produce)\")), \"Pillar\"] = \"Produce\"\n",
    "        ## AZ Produce --> MPUSA\n",
    "        data.loc[data[\"Location\"] == \"Arizona (produce)\", \"Corp\"] = \"MPUSA\"\n",
    "        ## move everything for AZ in 2025 to produce\n",
    "        data.loc[((data[\"FiscalYear\"] >= 2025) & (data[\"Location\"].str.contains(\"Arizona\",case=False))),\"Pillar\"] = \"Produce\"\n",
    "        data.loc[((data[\"FiscalYear\"] >= 2025) & (data[\"Location\"].str.contains(\"Arizona\",case=False))),\"Location\"] = \"Arizona (produce)\"\n",
    "        ## BC Produce --> MPL\n",
    "        data.loc[data[\"Location\"] == \"BritishColumbia (produce)\", \"Corp\"] = \"MPL\"\n",
    "        ## Outlook --> MPL\n",
    "        data.loc[data[\"Location\"]==\"Outlook\", \"Corp\"] = \"MPL\"\n",
    "        # Reclassify accounts for Operational Purpose\n",
    "        ## read & process operational classification\n",
    "        acc_operation = pd.read_csv(self.silver_path[\"QBO\"][\"Dimension\"]/\"Accounts Classification - Operation.csv\", dtype={\"Pillar\": str, \"IsGenric\": str}, keep_default_na=False)\n",
    "        acc_operation = acc_operation.rename(columns={\"Pillar\":\"AccPillar\", \"OperationProfiType\":\"OperationProfType\"})\n",
    "        acc_operation[\"AccNum\"] = acc_operation[\"AccountName\"].apply(lambda x: x.split(\" \")[0])\n",
    "        acc_operation[\"IsIntercompany\"] = acc_operation[\"AccountName\"].apply(lambda x: \"Yes\" if \"intercompany\" in x.lower() else \"No\")\n",
    "        ## classify commodity\n",
    "        acc_operation[\"Commodity\"] = acc_operation.apply(lambda x: self._identify_product(x), axis=1)\n",
    "        self.operation_acc = acc_operation\n",
    "        acc_operation.to_csv(self.gold_path[\"finance_operational\"]/\"accounts_classified_operation.csv\", index=False)\n",
    "        ## read accounts table and apply new classification\n",
    "        accounts = self.silver_acc\n",
    "        accounts1 = accounts[accounts[\"AccNum\"].isna()].copy(deep=True)\n",
    "        accounts = accounts[accounts[\"AccNum\"].notna()]\n",
    "        accounts = pd.merge(accounts, acc_operation.loc[:,[\"AccNum\",\"OperationProfType\",\"OperationCategory\",\"OperationSubCategory\",\"AccPillar\",\"Commodity\",\"IsGeneric\",\"IsIntercompany\"]],\n",
    "                            on = \"AccNum\", how = \"left\")\n",
    "        accounts = pd.concat([accounts,accounts1],ignore_index=True)\n",
    "        # Revising Signs according to Operational Classification\n",
    "        print(\"Revising Signs ...\")\n",
    "        expense_accounts = accounts[(accounts[\"OperationCategory\"] == \"Expense\") | (accounts[\"OperationCategory\"] ==\"Inventory Consumption\")]\n",
    "        data[\"AmountDisplay\"] = data.apply(lambda x: -x[\"AmountCAD\"] if x[\"AccID\"] in expense_accounts.AccID.unique() else x[\"AmountCAD\"], axis=1)\n",
    "        self.gold_pl = data\n",
    "        self.gold_acc = accounts\n",
    "        # save files\n",
    "        print(\"Saving ...\")\n",
    "        self.check_file(self.gold_path[\"finance_operational\"])\n",
    "        data.to_csv(self.gold_path[\"finance_operational\"]/\"PL.csv\", index=False)\n",
    "        accounts.to_excel(self.gold_path[\"finance_operational\"]/\"Account_table.xlsx\", sheet_name = \"Account\", index=False)\n",
    "        data.to_excel(self.gold_path[\"finance_operational\"]/\"PL.xlsx\", sheet_name=\"Transactions\", index=False)\n",
    "        self.pl_exist = True\n",
    "\n",
    "    def _process_pp(self, data:pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\" \n",
    "            This function takes original dataframe, apply the payperiod number classification based on transactions date, process payperiod columns, and return the new dataframe,\n",
    "                save the pp table for consolidated tables\n",
    "        \"\"\"\n",
    "        # load payperiods\n",
    "        payperiods = pd.read_csv(self.gold_path[\"payroll\"]/\"Payperiods.csv\")\n",
    "        payperiods[\"START\"] = pd.to_datetime(payperiods[\"START\"])\n",
    "        payperiods[\"END\"] = pd.to_datetime(payperiods[\"END\"])\n",
    "        payperiods = payperiods.loc[:,[\"PP\",\"START\",\"END\",\"Cycle\",\"FiscalYear\"]]\n",
    "        def _determine_pp(entry:pd.Series, date_col:str = \"TransactionDate\") -> str:\n",
    "            \"\"\" \n",
    "                This function determined which payperiod a transaction should be classified into, \n",
    "                    starting from most recent payperiod, the algorithm uses period start date + drift to determine which payperiod a transaction should fall into\n",
    "                Assumptions:\n",
    "                    1. for outlook and az, each payperiod is shifted by 5 + 7 days forward\n",
    "                    2. for other location, each payperiod is shifted by 5 days forward\n",
    "            \"\"\"\n",
    "            date = entry[date_col] \n",
    "            if isinstance(entry[\"Location\"],str):\n",
    "                location = entry[\"Location\"].lower()\n",
    "            else:\n",
    "                location = \"None\"\n",
    "            if \"outlook\" in location or \"az\" in location or \"arizona\" in location:\n",
    "                date_diff = dt.timedelta(days=5+7)\n",
    "            else:\n",
    "                date_diff = dt.timedelta(days=5)\n",
    "            year = date.year \n",
    "            month = date.month\n",
    "            # push back the most recent payperiod dates for older transactions to save compute\n",
    "            if month >= 11:\n",
    "                payperiods_subset = payperiods[payperiods[\"END\"] <= dt.datetime(year+1,2,1)] \n",
    "            else:  \n",
    "                payperiods_subset = payperiods[payperiods[\"END\"] <= dt.datetime(year,month+2,1)]\n",
    "            for i in range(len(payperiods_subset)-1,-1,-1):\n",
    "                if date > (payperiods_subset.loc[i,\"END\"]+date_diff):\n",
    "                    return \"Exceed Max PayPeriod\"\n",
    "                if date >= (payperiods_subset.loc[i,\"START\"]+date_diff):\n",
    "                    return str(payperiods_subset.loc[i,\"PP\"]) + \"-\" + str(payperiods_subset.loc[i,\"Cycle\"]) + \"-\" + str(payperiods_subset.loc[i,\"FiscalYear\"])\n",
    "            return \"Earlier than Min PayPeriod\"\n",
    "        print(\"Allocating PPNum for transactions ...\")\n",
    "        date_col = \"TransactionDate\" if \"TransactionDate\" in data.columns else \"date\"\n",
    "        data[\"PPNum\"] = data.apply(lambda x: _determine_pp(x,date_col),axis=1)\n",
    "        data = data[data[\"PPNum\"] != \"Earlier than Min PayPeriod\"].copy(deep=True).reset_index(drop=True) # eliminate earlier than min payperiod in the csv, note dates are shifted in the csv\n",
    "        data[\"Cycle\"] = data[\"PPNum\"].apply(lambda x: x.split(\"-\")[1])\n",
    "        data[\"FiscalYear\"] = data[\"PPNum\"].apply(lambda x: int(x.split(\"-\")[2]))\n",
    "        data[\"PPNum\"] = data[\"PPNum\"].apply(lambda x: x.split(\"-\")[0])\n",
    "        data[\"PPName\"] = data[\"PPNum\"].apply(lambda x: \"PP0\" + x if int(x) < 10 else \"PP\" + x)\n",
    "        data[\"PPName\"] = data[\"Cycle\"].str.slice(2,) + \"-\" + data[\"PPName\"]\n",
    "        data.loc[:,[\"PPName\", \"PPNum\", \"Cycle\", \"FiscalYear\"]].drop_duplicates().to_csv(self.gold_path[\"payroll\"].parent/ \"OtherTables\" / \"PayPeriods.csv\", index=False)\n",
    "        return data\n",
    "\n",
    "    def _process_units(self) -> None:\n",
    "        \"\"\" \n",
    "            this function read and process Unit files that contains unit numbers for each location\n",
    "        \"\"\"\n",
    "        acres = pd.read_csv(self.gold_path[\"payroll\"]/\"Unit.csv\",dtype={\"Location\":str, \"Unit\":float})\n",
    "        acres[\"Location\"] = acres[\"Location\"].str.strip()\n",
    "        doc_rename = {\"Airdrie Grain\": \"Airdrie (grain)\", \"Aridrie Cattle (head days 365)\":\"Airdrie\", \"Arizona All\":\"Arizona (produce)\",\n",
    "                    \"BC Cattle (head days 365)\":\"BritishColumbia (cattle)\", \"BC Produce\":\"BritishColumbia (produce)\", \n",
    "                    \"Box Elder\":\"Havre\", \"Eddystone Cattle (head days 365)\":\"Eddystone (cattle)\", \"Eddystone Grain\":\"Eddystone (grain)\",\n",
    "                    \"Monette Seeds CDN (avg met. ton)\":\"Seeds\", \"Monette Seeds USA\":\"Seeds USA\", \"NexGen (avg met. ton)\":\"NexGen\",\n",
    "                    \"Waldeck (head days 365)\":\"Waldeck\", \"Calderbank  (head days 365)\":\"Calderbank\"}\n",
    "        acres[\"Location\"] = acres[\"Location\"].replace(doc_rename)\n",
    "        acres[\"Pillar\"] = acres.apply(lambda x: self._pillar_classification(x),axis=1)\n",
    "        acres.to_csv(self.gold_path[\"payroll\"].parent/ \"OtherTables\" /\"Unit_PowerBI.csv\",index=False)\n",
    "\n",
    "    def _payroll_project(self) -> None: \n",
    "        \"\"\" \n",
    "            will run _finance_operational() first\n",
    "            output: details + cost per unit (units per location input sheet) + average cost per unit for FY\n",
    "        \"\"\"\n",
    "        self.check_file(self.gold_path[\"payroll\"].parent/ \"OtherTables\")\n",
    "        if not self.pl_exist:\n",
    "            self._finance_operational()\n",
    "        print(\"\\nStarting Payroll Project Transformation\\n\")\n",
    "\n",
    "        # load and filter accounts for wages and contract labor\n",
    "        account = self.silver_acc[(self.silver_acc[\"Category\"].isin([\"Wages and benefits - direct\",\"Wages and benefits - overhead\"]) | (self.silver_acc[\"AccNum\"].isin([\"MFAZ595001\",\"MFBC536030\"])))] \n",
    "        # load only with transaction date later than 2021-12-20, and without \"Accrual\" in the memo\n",
    "        data = self.gold_pl.copy(deep=True)\n",
    "        data = data[data[\"AccID\"].isin(account.AccID.unique())]\n",
    "        data[\"TransactionDate\"] = pd.to_datetime(data[\"TransactionDate\"])\n",
    "        data = data[data[\"TransactionDate\"]>=dt.datetime(2021,12,20)].reset_index(drop=True)\n",
    "        data = data[~data[\"Memo\"].str.contains(\"Accrual\",case=False,na=False)]\n",
    "        # allocating payperiods\n",
    "        data = self._process_pp(data=data)\n",
    "        # standardizing location\n",
    "        # data.loc[data[\"Location\"]==\"Airdrie (corporate)\", \"Pillar\"] = \"Cattle\"                # deprecated\n",
    "        # data.loc[data[\"Location\"]==\"Airdrie (corporate)\", \"Location\"] = \"Airdrie (cattle)\"    # deprecated\n",
    "        data.loc[data[\"Location\"]==\"Eddystone (corporate)\", \"Pillar\"] = \"Unclassified\"\n",
    "        data.loc[data[\"Location\"]==\"Eddystone (corporate)\", \"Location\"] = \"Unassigned\"\n",
    "        data.loc[data[\"Location\"]==\"Legacy\", \"Location\"] = \"Unassigned\"\n",
    "        data.loc[(data[\"Location\"].str.contains(\"corporate\",case=False,na=False)&(data[\"Location\"]!=\"BritishColumbia (corporate)\")),\"Location\"] = \"Corporate\"\n",
    "        ## move BC ranches into BC Cattle\n",
    "        data.loc[(data[\"Location\"].isin(self.bc_ranches)), \"Location\"] = \"BritishColumbia (cattle)\"\n",
    "        data.loc[data[\"Location\"] == \"BritishColumbia (cattle)\", \"Pillar\"] = \"Cattle\"\n",
    "        # summarizing data\n",
    "        ## by Location per PP\n",
    "        data_summarized = pd.DataFrame(data.groupby([\"Location\",\"PPName\",\"Pillar\",\"FiscalYear\",\"Cycle\",\"PPNum\"]).agg({\"AmountDisplay\":\"sum\"}).reset_index(drop=False))\n",
    "        assert len(data_summarized) == len(data.groupby([\"Location\",\"PPName\"]).agg({\"AmountDisplay\":\"sum\"}).reset_index(drop=False)), \"Duplicated value detected for per Location per PP calculation\"\n",
    "        ## join acres data for CostPerUnit compute\n",
    "        print(\"Summarizing ...\")\n",
    "        self._process_units()\n",
    "        acres = pd.read_csv(self.gold_path[\"payroll\"].parent/ \"OtherTables\" /\"Unit_PowerBI.csv\",dtype={\"Location\":str, \"Unit\":float})\n",
    "        acres = acres.loc[:,[\"Location\", \"Unit\"]]\n",
    "        print(f\"Unaccounted location for Acres Doc: {set(acres.Location.unique()) - set(data_summarized.Location.unique())}\")\n",
    "        data_summarized = pd.merge(data_summarized, acres, on=\"Location\", how=\"left\")\n",
    "        data_summarized[\"CostPerUnit\"] = data_summarized[\"AmountDisplay\"] / data_summarized[\"Unit\"] * 26\n",
    "        data_summarized[\"Count\"] = 1\n",
    "        ## by Location\n",
    "        data_summarized2 = data_summarized.groupby(by=[\"Location\",\"FiscalYear\",\"Pillar\"]).agg({\"CostPerUnit\":\"mean\", \"Count\":\"sum\"}).reset_index(drop=False)\n",
    "        data_summarized2 = data_summarized2.rename(columns={\"CostPerUnit\":\"Avg CostPerUnit\"})\n",
    "        assert len(data_summarized2) == len(data_summarized.groupby(by=[\"Location\",\"FiscalYear\"]).agg({\"CostPerUnit\":\"mean\"})), \"Duplicated value detected for per Location calculation\"\n",
    "        ## by pillar\n",
    "        data_summarized3 = data_summarized2.groupby(by=[\"FiscalYear\",\"Pillar\"]).agg({\"Avg CostPerUnit\":\"mean\", \"Count\":\"sum\"}).reset_index(drop=False)\n",
    "        assert len(data_summarized3) == len(data_summarized.groupby(by=[\"Pillar\",\"FiscalYear\"]).agg({\"CostPerUnit\":\"mean\"})), \"Duplicated value detected for per Pillar calculation\"\n",
    "        # saving\n",
    "        print(\"Saving ...\")\n",
    "        self.check_file(self.gold_path[\"payroll\"])\n",
    "        data.to_excel(self.gold_path[\"payroll\"]/\"Payroll.xlsx\", sheet_name=\"Payroll\", index=False)\n",
    "        self.check_file(self.gold_path[\"hr_combined\"] / \"CSV\")\n",
    "        data_summarized.to_csv(self.gold_path[\"hr_combined\"]/ \"CSV\" / \"payroll_summarized1.csv\", index=False)\n",
    "        data_summarized2.to_csv(self.gold_path[\"hr_combined\"]/ \"CSV\" / \"payroll_summarized2.csv\", index=False)\n",
    "        data_summarized3.to_csv(self.gold_path[\"hr_combined\"]/ \"CSV\" / \"payroll_summarized3.csv\", index=False)\n",
    "        # data_summarized.to_excel(self.gold_path[\"payroll\"]/\"PayrollSummarized.xlsx\", sheet_name=\"PayrollSummarized\", index=False)\n",
    "        # data_summarized2.to_excel(self.gold_path[\"payroll\"]/\"PayrollSummarized2.xlsx\", sheet_name=\"PayrollSummarized2\", index=False)\n",
    "        # data_summarized3.to_excel(self.gold_path[\"payroll\"]/\"PayrollSummarized3.xlsx\", sheet_name=\"PayrollSummarized3\", index=False)\n",
    "\n",
    "    def _QBOTime_project(self) -> None:\n",
    "        \"\"\" \n",
    "            apply PP allocation to QBO Time data, clean locaiton, and join relevant info into one table\n",
    "        \"\"\"\n",
    "        print(\"\\nStarting QBO Time Project Transformation\\n\")\n",
    "        # read files\n",
    "        timesheets = pd.read_csv(self.silver_path[\"QBO\"][\"Time\"]/\"timesheets.csv\")\n",
    "        jobcode = pd.read_csv(self.silver_path[\"QBO\"][\"Time\"]/\"jobcodes.csv\")\n",
    "        users = pd.read_csv(self.silver_path[\"QBO\"][\"Time\"]/\"users.csv\")\n",
    "        group = pd.read_csv(self.silver_path[\"QBO\"][\"Time\"]/\"group.csv\")\n",
    "        print(f\"Read {len(timesheets)} timesheet records, {len(jobcode)} jobcodes, {len(users)} users, {len(group)} groups\")\n",
    "        timesheets_len, users_len = len(timesheets), len(users)\n",
    "        # clean up location in group table\n",
    "        ## Arizona - all produce\n",
    "        group.loc[((group[\"corp_short\"]==\"A\")&(group[\"location_name\"]==\"Monette Farms AZ\")), \"Location\"] = \"Arizona (produce)\"\n",
    "        group.loc[((group[\"corp_short\"]==\"A\")&(group[\"location_name\"]==\"Monette Produce USA\")), \"Location\"] = \"Arizona (produce)\"\n",
    "        group.loc[((group[\"corp_short\"]==\"A\")&(group[\"location_name\"]==\"Monette Seeds USA\")), \"Location\"] = \"Arizona (produce)\"\n",
    "        ## BC\n",
    "        group.loc[((group[\"corp_short\"]==\"BC\")&(group[\"location_name\"]==\"Ashcroft Ranch\")), \"Location\"] = \"Ashcroft\"\n",
    "        group.loc[((group[\"corp_short\"]==\"BC\")&(group[\"location_name\"]==\"Cache/Fischer/Loon\")), \"Location\"] = \"Unassigned\"\n",
    "        group.loc[((group[\"corp_short\"]==\"BC\")&(group[\"location_name\"]==\"Diamond S Ranch\")), \"Location\"] = \"Diamond S\"\n",
    "        group.loc[((group[\"corp_short\"]==\"BC\")&(group[\"location_name\"]==\"Fraser River Ranch\")), \"Location\"] = \"Fraser River Ranch\"\n",
    "        group.loc[((group[\"corp_short\"]==\"BC\")&(group[\"location_name\"]==\"Home Ranch (70 Mile, LF/W, BR)\")), \"Location\"] = \"Home Ranch\"\n",
    "        group.loc[((group[\"corp_short\"]==\"BC\")&(group[\"location_name\"]==\"Moon Ranch\")), \"Location\"] = \"Moon Ranch\"\n",
    "        group.loc[((group[\"corp_short\"]==\"BC\")&(group[\"location_name\"]==\"Produce\")), \"Location\"] = \"BritishColumbia (produce)\"\n",
    "        group.loc[((group[\"corp_short\"]==\"BC\")&(group[\"location_name\"]==\"Wolf Ranch\")), \"Location\"] = \"Wolf Ranch\"\n",
    "        group.loc[((group[\"corp_short\"]==\"BC\")&(group[\"location_name\"]==\"SAWP\")), \"Location\"] = \"Unassigned\"\n",
    "        ## Outlook\n",
    "        group.loc[((group[\"corp_short\"]==\"O\")), \"Location\"] = \"Outlook\"\n",
    "        ## others\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"Airdrie\")), \"Location\"] = \"Airdrie\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"BC\")), \"Location\"] = \"Unassigned\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"Calderbank\")), \"Location\"] = \"Calderbank\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"Eddystone\")), \"Location\"] = \"Eddystone (unspecified)\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"Hafford\")), \"Location\"] = \"Hafford\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"Kamsack\")), \"Location\"] = \"Kamsack\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"MFUSA Billings\")), \"Location\"] = \"Billings\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"MFUSA Box Elder\")), \"Location\"] = \"Havre\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"Nexgen Seeds\")), \"Location\"] = \"NexGen\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"Prince Albert\")), \"Location\"] = \"Prince Albert\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"Raymore\")), \"Location\"] = \"Raymore\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"Regina\")), \"Location\"] = \"Regina\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"Russel Approvals\")), \"Location\"] = \"Unassigned\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"Seeds\")), \"Location\"] = \"Seeds\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"Swift Current\")), \"Location\"] = \"Swift Current\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"The Pas\")), \"Location\"] = \"The Pas\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"Waldeck\")), \"Location\"] = \"Waldeck\"\n",
    "        unclassified = group[group[\"Location\"].isna()].location_name.unique()\n",
    "        if len(unclassified) > 0: print(f\"\\nUnclassified location - {unclassified}\\n\")\n",
    "        # create another location column for general location where bc ranches are merged into one\n",
    "        group = group.rename(columns={\"Location\": \"Location (detail)\"})\n",
    "        group[\"Location\"] = group[\"Location (detail)\"]\n",
    "        group.loc[(group[\"Location (detail)\"].isin(self.bc_ranches)), \"Location\"] = \"BritishColumbia (cattle)\"\n",
    "        # merge tables into one table\n",
    "        ## merge location into users\n",
    "        users = pd.merge(users, group.loc[:,[\"group_id\", \"location_name\", \"Location\", \"Location (detail)\"]].drop_duplicates(), on=\"group_id\", how=\"left\")\n",
    "        ## merge users into timesheets\n",
    "        timesheets = pd.merge(timesheets,users.loc[:,[\"user_id\", \"group_id\", \"username\", \"full_name\", \"location_name\",\"Location\",\"Location (detail)\"]], on=\"user_id\", how=\"left\")\n",
    "        ## merge job into timesheets\n",
    "        timesheets = pd.merge(timesheets, jobcode.loc[:,[\"jobcode_id\",\"job_name\",\"type\"]].rename(columns={\"type\":\"job_type\"}), on=\"jobcode_id\", how=\"left\")\n",
    "        assert (len(users) == users_len) and (len(timesheets) == timesheets_len), f\"duplicated records found, timesheets - {timesheets_len} vs {len(timesheets)}; users - {users_len} vs {len(users)}\"\n",
    "        # classify payperiods\n",
    "        timesheets[\"date\"] = pd.to_datetime(timesheets[\"date\"])\n",
    "        timesheets = self._process_pp(data=timesheets)\n",
    "        # classify pillars\n",
    "        timesheets[\"Pillar\"] = timesheets.apply(lambda x: self._pillar_classification(x), axis=1)\n",
    "        # summarizing data\n",
    "        ## by Location per PP \n",
    "        summarized = timesheets.groupby([\"Location\",\"PPName\",\"FiscalYear\",\"Cycle\",\"PPNum\", \"Pillar\"]).agg({\"duration\":\"sum\"}).reset_index(drop=False)\n",
    "        assert len(summarized) == len(timesheets.groupby([\"Location\",\"PPName\"]).agg({\"duration\":\"sum\"})), \"duplicated value detected for timsheet per Location per PP summarization\"\n",
    "        ## read units file\n",
    "        acres = pd.read_csv(self.gold_path[\"payroll\"]/\"Unit_PowerBI.csv\",dtype={\"Location\":str, \"Unit\":float})\n",
    "        acres = acres.loc[:,[\"Location\", \"Unit\"]]\n",
    "        addition = pd.DataFrame(data={\"Location\":[\"Billings\"], \"Unit\":[acres[acres[\"Location\"].isin(['Fly Creek', 'Camp 4'])].Unit.sum()]})\n",
    "        acres = pd.concat([acres,addition],ignore_index=True)\n",
    "        print(f\"Unaccounted location for Acres Doc: {set(acres.Location.unique()) - set(summarized.Location.unique())}\")\n",
    "        print(f\"Unaccounted location for timesheets: {set(summarized.Location.unique()) - set(acres.Location.unique())}\")\n",
    "        ## merge with units file\n",
    "        summarized = pd.merge(summarized, acres, on=\"Location\", how=\"left\")\n",
    "        ## calculate hours per unit\n",
    "        summarized[\"HoursPerUnit\"] = summarized[\"duration\"] / summarized[\"Unit\"] * 26\n",
    "        summarized[\"Count\"] = 1\n",
    "        # summarize per location\n",
    "        summarized2 = summarized.groupby(by=[\"Location\",\"FiscalYear\", \"Pillar\"]).agg({\"HoursPerUnit\":\"mean\", \"Count\":\"sum\"}).reset_index(drop=False)\n",
    "        summarized2 = summarized2.rename(columns={\"HoursPerUnit\":\"Avg HoursPerUnit\"})\n",
    "        assert len(summarized2) == len(timesheets.groupby([\"Location\",\"FiscalYear\"]).agg({\"duration\":\"sum\"})), \"duplicated value detected for timsheet per Location summarization\"\n",
    "        # summarize per pillar\n",
    "        summarized3 = summarized2.groupby(by=[\"FiscalYear\", \"Pillar\"]).agg({\"Avg HoursPerUnit\":\"mean\", \"Count\":\"sum\"}).reset_index(drop=False)\n",
    "        assert len(summarized3) == len(timesheets[timesheets[\"Pillar\"]!=\"Missing\"].groupby([\"Pillar\",\"FiscalYear\"]).agg({\"duration\":\"sum\"})), \"duplicated value detected for timsheet per Pillar summarization\"\n",
    "\n",
    "        # saving\n",
    "        print(\"Saving ...\\n\")\n",
    "        self.check_file(self.gold_path[\"QBOTime\"])\n",
    "        timesheets.to_excel(self.gold_path[\"QBOTime\"]/\"QBOTime.xlsx\", sheet_name = \"QBOTime\", index=False)\n",
    "        self.check_file(self.gold_path[\"hr_combined\"]/ \"CSV\")\n",
    "        summarized.to_csv(self.gold_path[\"hr_combined\"]/ \"CSV\" / \"time_summarized1.csv\", index=False)\n",
    "        summarized2.to_csv(self.gold_path[\"hr_combined\"]/ \"CSV\" / \"time_summarized2.csv\", index=False)\n",
    "        summarized3.to_csv(self.gold_path[\"hr_combined\"]/ \"CSV\" / \"time_summarized3.csv\", index=False)\n",
    "        # summarized.to_excel(self.gold_path[\"QBOTime\"]/\"QBOTimeSummarized.xlsx\", sheet_name = \"QBOTimeSummarized\", index=False)\n",
    "        # summarized2.to_excel(self.gold_path[\"QBOTime\"]/\"QBOTimeSummarized2.xlsx\", sheet_name = \"QBOTimeSummarized2\", index=False)\n",
    "        # summarized3.to_excel(self.gold_path[\"QBOTime\"]/\"QBOTimeSummarized3.xlsx\", sheet_name = \"QBOTimeSummarized3\", index=False)\n",
    "\n",
    "    def _hr_summary(self) -> None:\n",
    "        \"\"\" \n",
    "            This function consolidate payroll and QBO time summaries into one table for consolidated insights\n",
    "        \"\"\"\n",
    "        final_df = [pd.DataFrame(), pd.DataFrame(), pd.DataFrame()]\n",
    "        for i in [1, 2, 3]:\n",
    "            payroll = pd.read_csv(self.gold_path[\"hr_combined\"] / \"CSV\" / f\"payroll_summarized{i}.csv\")\n",
    "            payroll_rename = {\"AmountDisplay\": \"TotalAmount\", \"CostPerUnit\": \"AmountPerUnit\", \"Avg CostPerUnit\": \"Avg AmountPerUnit\"}\n",
    "            payroll = payroll.rename(columns=payroll_rename)\n",
    "            payroll[\"Mode\"] = \"Payroll\"\n",
    "            time = pd.read_csv(self.gold_path[\"hr_combined\"] / \"CSV\" / f\"time_summarized{i}.csv\")\n",
    "            time_rename = {\"duration\": \"TotalAmount\", \"HoursPerUnit\": \"AmountPerUnit\", \"Avg HoursPerUnit\": \"Avg AmountPerUnit\"}\n",
    "            time = time.rename(columns=time_rename)\n",
    "            time[\"Mode\"] = \"Hours\"\n",
    "            final_df[i-1] = pd.concat([payroll, time], ignore_index=True)\n",
    "        final_df[0].to_excel(self.gold_path[\"hr_combined\"]/\"Summarized.xlsx\", sheet_name=\"Summarized\", index=False)\n",
    "        final_df[1].to_excel(self.gold_path[\"hr_combined\"]/\"Summarized2.xlsx\", sheet_name=\"Summarized2\", index=False)\n",
    "        final_df[2].to_excel(self.gold_path[\"hr_combined\"]/\"Summarized3.xlsx\", sheet_name=\"Summarized3\", index=False)\n",
    "\n",
    "    def _temp_get_product(self, entry:str) -> str:\n",
    "        \"\"\" \n",
    "            temporary function for aligning product classification with Traction for QBO accounts, will change for HP\n",
    "        \"\"\"\n",
    "        entry = entry.lower()\n",
    "        if \"durum\" in entry:\n",
    "            return \"Durum\"\n",
    "        elif \"wheat\" in entry:\n",
    "            return \"Wheat\"\n",
    "        elif \"canola\" in entry:\n",
    "            return \"Canola\"\n",
    "        elif (\"chickpea\" in entry) or (\"garbanzo bean\" in entry):\n",
    "            return \"Chickpeas\"\n",
    "        elif (\"peas\" in entry) or (\"field pea\" in entry):\n",
    "            return \"Peas\"\n",
    "        elif \"barley\" in entry:\n",
    "            return \"Barley\"\n",
    "        elif \"green lentil\" in entry:\n",
    "            return \"Green Lentils\"\n",
    "        elif \"red lentil\" in entry:\n",
    "            return \"Red Lentils\"\n",
    "        elif \"oats\" in entry:\n",
    "            return \"Oats\"\n",
    "        elif \"corn\" in entry:\n",
    "            return \"Corn\"\n",
    "        else:\n",
    "            return \"Others\" \n",
    "\n",
    "    def _raw_inventory(self) -> None:\n",
    "        \"\"\" \n",
    "            prepare the data from raw QBO table for inventory project: only extracting partial Invoice, SalesReceipt, and Journal Entry\n",
    "        \"\"\"\n",
    "        print(\"\\nStarting Inventory Project Transformation ...\\n\")\n",
    "        corps = [\"MFL\", \"MFUSA\"]\n",
    "        cols = [\"TransactionDate\", \"TransactionType\", \"TransactionID\", \"Corp\", \"Qty\", \"AccID\", \"FarmID\", \"CustomerID\",\n",
    "                \"DocNumber\", \"TransactionEntered\", \"Amount\"]\n",
    "        journal_cols = [col for col in cols if col != \"Qty\"]\n",
    "        # read tables\n",
    "        print(\"Loading raw tables ...\")\n",
    "        account = self.silver_acc.copy(deep=True)\n",
    "        account = account[account[\"Corp\"].isin(corps)]\n",
    "        account = account[account[\"AccountType\"] == \"Income\"]\n",
    "        farm = pd.read_csv(self.silver_path[\"QBO\"][\"Dimension_time\"]/\"Farm.csv\")\n",
    "        farm = farm[farm[\"Corp\"].isin(corps)]\n",
    "        customer = pd.read_csv(self.silver_path[\"QBO\"][\"Dimension_time\"]/\"Customer.csv\")\n",
    "        customer = customer[customer[\"Corp\"].isin(corps)]\n",
    "        first_date = dt.datetime(2023,11,1)\n",
    "        invoice = pd.read_csv(self.silver_path[\"QBO\"][\"Raw\"]/\"Invoice.csv\")\n",
    "        invoice = invoice[invoice[\"Corp\"].isin(corps)]\n",
    "        invoice[\"TransactionDate\"] = pd.to_datetime(invoice[\"TransactionDate\"])\n",
    "        invoice = invoice[invoice[\"TransactionDate\"]>=first_date]\n",
    "        invoice = invoice[invoice[\"AccID\"].isin(account.AccID.unique())]\n",
    "        sales = pd.read_csv(self.silver_path[\"QBO\"][\"Raw\"]/\"SalesReceipt.csv\")\n",
    "        sales = sales[sales[\"Corp\"].isin(corps)]\n",
    "        sales[\"TransactionDate\"] = pd.to_datetime(sales[\"TransactionDate\"])\n",
    "        sales = sales[sales[\"TransactionDate\"]>=first_date]\n",
    "        sales = sales[sales[\"AccID\"].isin(account.AccID.unique())]\n",
    "        journal = pd.read_csv(self.silver_path[\"QBO\"][\"Raw\"]/\"JournalEntry.csv\",usecols=journal_cols)\n",
    "        journal = journal[journal[\"AccID\"].isin(account.AccID.unique())]\n",
    "        journal[\"TransactionDate\"] = pd.to_datetime(journal[\"TransactionDate\"])\n",
    "        journal = journal[journal[\"TransactionDate\"]>=first_date]\n",
    "        journal = journal[~journal[\"TransactionEntered\"].str.contains(\"Delivered and not settled\", na=False)]\n",
    "        journal = journal[~journal[\"TransactionEntered\"].str.contains(\"Grain Inventory Receivable Adjustment\", na=False)]\n",
    "        # combining tables\n",
    "        print(\"Combining Fact Tables ...\")\n",
    "        invoice = invoice.loc[:,[col for col in cols if col in invoice.columns]]\n",
    "        sales = sales.loc[:,[col for col in cols if col in sales.columns]]\n",
    "        journal = journal.loc[:,[col for col in cols if col in journal.columns]]\n",
    "        facts = pd.concat([invoice, sales, journal], ignore_index=True)\n",
    "        del invoice, sales, journal\n",
    "        # join facts with dimension tables\n",
    "        facts = pd.merge(facts, account.loc[:,[\"AccID\",\"AccNum\",\"AccName\",\"Category\",\"Subcategory\"]], on=[\"AccID\"], how=\"left\")\n",
    "        facts = pd.merge(facts, farm.loc[:,[\"FarmID\",\"FarmName\"]], on=[\"FarmID\"], how=\"left\")\n",
    "        facts = pd.merge(facts, customer.loc[:,[\"CustomerID\",\"CustomerName\"]], on=[\"CustomerID\"], how=\"left\")\n",
    "        facts = facts[facts[\"Subcategory\"]==\"Grain - cash settlements\"]\n",
    "        print(f\"Total Fact Entries - {len(facts)}\")\n",
    "        # product column\n",
    "        facts[\"Product\"] = facts[\"AccName\"].apply(lambda x: self._temp_get_product(x))\n",
    "        # saving file\n",
    "        print(\"Saving Files ...\")\n",
    "        self.check_file(self.gold_path[\"inventory\"])\n",
    "        facts.to_excel(self.gold_path[\"inventory\"]/\"Excel\"/\"QBO_Grain_Settlements.xlsx\", sheet_name=\"settlement\", index=False)\n",
    "        print(\"Finished\\n\")\n",
    "\n",
    "    def _buget_process_input(self, inputdata_path:Path, processed_path:Path) -> None:\n",
    "        \"\"\" \n",
    "            this function processes and saves budget totals for production, input (chem/fert/seed), produce budgets, and JD Lease\n",
    "        \"\"\"\n",
    "        ## commodity prices - everything is CAD except Winter Wheat is converted to USD\n",
    "        pricing = pd.read_csv(inputdata_path/\"25-Grain-Pricing.csv\")\n",
    "        pricing.loc[pricing[\"Commodity\"]==\"WW\", \"ForecastPrice\"] *= self.fx\n",
    "        ## production budget\n",
    "        budget_production = pd.read_csv(inputdata_path/\"25-Grain-Revenue.csv\")\n",
    "        budget_production = budget_production.melt(\n",
    "            id_vars=[\"Location\", \"Currency\", \"Type\"],\n",
    "            var_name=\"Commodity\",\n",
    "            value_name = \"Amount\"\n",
    "        )\n",
    "        budget_production = budget_production.fillna(value = {\"Amount\": 0})\n",
    "        budget_production[\"Commodity\"] = budget_production[\"Commodity\"].replace({\"Hay/Silage\":\"Hay\"})\n",
    "        budget_production.loc[((budget_production[\"Location\"]==\"Airdrie\")&(budget_production[\"Commodity\"]==\"Hay\")), \"Commodity\"] = \"Silage\" # only Airdrie has silage, others have hay\n",
    "        budget_production_summary = pd.DataFrame(budget_production.groupby([\"Location\",\"Currency\",\"Commodity\"]).agg({\"Amount\": \"prod\"})).reset_index(drop=False)\n",
    "        budget_production_summary = budget_production_summary.rename(columns={\"Amount\":\"TotalYield\"})\n",
    "        ### merge yield with commodity price to calculate forecast production value of commodities\n",
    "        budget_production_summary = pd.merge(budget_production_summary,pricing,on=[\"Commodity\"], how=\"left\")\n",
    "        ### manual adjustments to prices\n",
    "        budget_production_summary.loc[((budget_production_summary[\"Location\"] == \"Airdrie\") & (budget_production_summary[\"Commodity\"] == \"Hay\")), \"ForecastPrice\"] = 85\n",
    "        budget_production_summary.loc[((budget_production_summary[\"Location\"] == \"Colorado (Genoa)\") & (budget_production_summary[\"Commodity\"] == \"WW\")), \"ForecastPrice\"] = 13.75\n",
    "        budget_production_summary.loc[budget_production_summary[\"Location\"] == \"Yorkton\", \"ForecastPrice\"] *= 2/3\n",
    "        budget_production_summary[\"ForecastProductionCAD\"] = budget_production_summary[\"TotalYield\"] * budget_production_summary[\"ForecastPrice\"]\n",
    "        budget_production_summary = budget_production_summary[budget_production_summary[\"ForecastProductionCAD\"].notna()]\n",
    "        budget_production_summary = budget_production_summary[budget_production_summary[\"ForecastProductionCAD\"]!=0]\n",
    "        ### convert prices back to USD for a adjusted column\n",
    "        budget_production_summary[\"ForecastProductionAdj\"] = budget_production_summary.apply(lambda x: x[\"ForecastProductionCAD\"] / self.fx if x[\"Currency\"] == \"USD\" else x[\"ForecastProductionCAD\"],axis=1)\n",
    "        ### save production budget\n",
    "        budget_production_summary.to_csv(processed_path/\"budget_production.csv\",index=False)\n",
    "        ## input budget\n",
    "        input_budget = pd.read_csv(inputdata_path/\"25-Input-Budget.csv\")\n",
    "        input_budget = input_budget.drop(columns=[\"Total acres\"])\n",
    "        input_budget = input_budget.melt(\n",
    "            id_vars = [\"Location\", \"Type\"],\n",
    "            var_name = \"Commodity\",\n",
    "            value_name = \"Amount\"\n",
    "        )\n",
    "        input_budget = input_budget.fillna(value = {\"Amount\": 0})\n",
    "        input_budget.loc[((input_budget[\"Location\"]==\"Yorkton\")&(input_budget[\"Type\"].isin([\"Fertilizer\",\"Chemical\",\"Seed\"]))), \"Amount\"] *= 2/3\n",
    "        input_budget.to_csv(processed_path/\"input_budget.csv\",index=False)\n",
    "        ## labour budget\n",
    "        labour_budget = pd.read_csv(inputdata_path/\"25-Labour-Budget.csv\")\n",
    "        labour_budget = labour_budget.melt(\n",
    "            id_vars = [\"Location\",\"Currency\"],\n",
    "            var_name = \"Month\",\n",
    "            value_name = \"LabourBudgetCAD\"\n",
    "        )\n",
    "        labour_budget[\"LabourBudgetAdj\"] = labour_budget.apply(lambda x: x[\"LabourBudgetCAD\"]/self.fx if x[\"Currency\"]==\"USD\" else x[\"LabourBudgetCAD\"], axis=1)\n",
    "        labour_budget.to_csv(processed_path/\"labour_budget.csv\",index=False)\n",
    "        ## outlook budget\n",
    "        outlook = pd.read_csv(inputdata_path/\"25-Outlook-Detail.csv\")\n",
    "        outlook = outlook.melt(\n",
    "            id_vars=[\"Type\", \"ProfitType\"],\n",
    "            var_name=\"Commodity\",\n",
    "            value_name=\"Amount\"\n",
    "        )\n",
    "        outlook = outlook.fillna(value={\"Amount\": 0})\n",
    "        outlook.to_csv(processed_path/\"outlook_budget.csv\", index=False)\n",
    "        ## AZ budget\n",
    "        az = pd.read_csv(inputdata_path / \"25-AZ-Detail.csv\")\n",
    "        az = az.melt(\n",
    "            id_vars=[\"Type\", \"ProfitType\"],\n",
    "            var_name=\"CommodityRaw\",\n",
    "            value_name=\"AmountCAD\"\n",
    "        )\n",
    "        az = az.fillna(value={\"AmountCAD\": 0})\n",
    "        az.to_csv(processed_path/\"az_budget.csv\", index=False)\n",
    "        ## BC produce details\n",
    "        bc = pd.read_csv(inputdata_path / \"25-BC-Detail.csv\")\n",
    "        bc = bc.melt(\n",
    "            id_vars=[\"Type\", \"ProfitType\"],\n",
    "            var_name=\"CommodityRaw\",\n",
    "            value_name=\"AmountCAD\"\n",
    "        )\n",
    "        bc = bc.fillna(value={\"AmountCAD\": 0})\n",
    "        bc.to_csv(processed_path/\"bc_budget.csv\", index=False)\n",
    "        ## JD lease\n",
    "        jdlease = pd.read_csv(inputdata_path/\"25-JD-Lease-Summary.csv\")\n",
    "        jdlease = jdlease[jdlease[\"AllocatedCost25\"] != 0]\n",
    "        jdlease.to_csv(processed_path/\"JD_lease.csv\", index=False)\n",
    "\n",
    "    def _budget_read_outsidedata(self,processed_path:Path) -> tuple[pd.DataFrame,pd.DataFrame,pd.DataFrame,pd.DataFrame,pd.DataFrame,pd.DataFrame,pd.DataFrame]:\n",
    "        \"\"\" \n",
    "            this function reads all the processed outside data and standardize the commodity and location naming\n",
    "        \"\"\"\n",
    "        production_budget = pd.read_csv(processed_path/\"budget_production.csv\")\n",
    "        input_budget = pd.read_csv(processed_path/\"input_budget.csv\")\n",
    "        labour_budget = pd.read_csv(processed_path/\"labour_budget.csv\")\n",
    "        outlook_budget = pd.read_csv(processed_path/\"outlook_budget.csv\")\n",
    "        jdlease = pd.read_csv(processed_path/\"JD_lease.csv\")\n",
    "        az_budget = pd.read_csv(processed_path/\"az_budget.csv\")\n",
    "        bc_budget = pd.read_csv(processed_path/\"bc_budget.csv\")\n",
    "        ## standardizing commodity naming\n",
    "        production_rename_commodity = {\"R Lentils\":\"Red Lentil\", \"G Lentils\":\"Green Lentil\",\"Chickpeas\":\"Chickpea\",\"Peas\":\"Field Pea\", \"WW\": \"Winter Wheat\"}\n",
    "        input_rename_commodity = {\"R Lentils\":\"Red Lentil\", \"G Lentils\":\"Green Lentil\",\"Chickpeas\":\"Chickpea\", \"WW\": \"Winter Wheat\"}\n",
    "        outlook_rename_commodity = {\"Broccoli-cases/ac\":\"Broccoli\", \"Cabbage-lbs/ac\":\"Cabbage\", \"Carrots-lbs\":\"Carrot\", \"Cauliflower-cases/ac\":\"Cauliflower\",\n",
    "                                    \"Table Potato-lbs\":\"Potato\", \"Seed Potato-lbs\":\"Potato\", \"Commercial Pumpkins-Bins/ac\":\"Pumpkin\", \"Strawberry Upick-lbs\":\"Strawberry\",\n",
    "                                    \"Pumpkin Upick-pieces/ac\":\"Pumpkin\", \"Corn Maze-lbs\":\"Prairie Pathways\", \"WW\": \"Winter Wheat\", \"Corn (Sweet) Cobs\":\"Sweet Corn\"}\n",
    "        az_rename_commodity = {\"Broccoli-cases/ac\":\"Broccoli\", \"Cabbage-lbs/ac\":\"Cabbage\", \"Pumpkins-Bins/ac\":\"Pumpkin\", \"WatermelonLG-bins/ac\": \"Watermelon\",\n",
    "                            \"WatermelonMini-cases/ac\": \"Watermelon\"}\n",
    "        bc_rename_commodity = {\"Broccoli-cases/ac\":\"Broccoli\", \"WatermelonLG-bins/ac\": \"Watermelon\", \"WatermelonMini-cases/ac\": \"Watermelon\", \"Pumpkins-Bins/ac\":\"Pumpkin\",\n",
    "                            \"Squash-lbs\": \"Squash\"}\n",
    "        outlook_budget[\"CommodityRaw\"] = outlook_budget[\"Commodity\"]\n",
    "        production_budget[\"Commodity\"] = production_budget[\"Commodity\"].replace(production_rename_commodity)\n",
    "        input_budget[\"Commodity\"] = input_budget[\"Commodity\"].replace(input_rename_commodity)\n",
    "        outlook_budget[\"Commodity\"] = outlook_budget[\"Commodity\"].replace(outlook_rename_commodity)\n",
    "        az_budget[\"Commodity\"] = az_budget[\"CommodityRaw\"].replace(az_rename_commodity)\n",
    "        bc_budget[\"Commodity\"] = bc_budget[\"CommodityRaw\"].replace(bc_rename_commodity)\n",
    "        ## standardizing location naming - merge calderbank grain with Swift Current\n",
    "        jdlease_rename_location = {\"Swift Current Total\":\"Swift Current\", \"Regina Farm\":\"Regina\", \"Calderbank\":\"Swift Current\",\n",
    "                                \"Airdrie\":\"Airdrie (grain)\", \"Eddystone\":\"Eddystone (grain)\"}\n",
    "        labour_rename_location = {\"NexGen (avg met. ton)\":\"NexGen\", \"Cache/Fisher/Look\":\"Aschroft\", \"MF AZ\":\"Arizona (produce)\", \"Box Elder\":\"Havre\", \n",
    "                                \"BC Veg\":\"BritishColumbia (produce)\",\"Monette Seeds CDN (avg met. ton)\":\"Monette Seeds\", \n",
    "                                \"BC Cattle (avg head)\":\"BritishColumbia (cattle)\", \"Eddystone Cattle (avg head)\":\"Eddystone (cattle)\",\n",
    "                                \"Swift Current Cattle (avg head)\":\"Waldeck\", \"Aridrie Cattle (avg head)\":\"Airdrie (cattle)\",\n",
    "                                \"Airdrie Farm\":\"Airdrie (grain)\", \"Eddystone Farm\":\"Eddystone (grain)\",\"Calderbank\":\"Calderbank (cattle)\"}\n",
    "        input_rename_location =  {\"Fly Creek/Camp 1\":\"Fly Creek\", \"Regina Farm\":\"Regina\",\"Swift Current Total\":\"Swift Current\", \"Box Elder\":\"Havre\", \"Regina Farm\":\"Regina\",\n",
    "                                \"Calderbank\":\"Calderbank (grain)\",\"Airdrie\":\"Airdrie (grain)\", \"Eddystone\":\"Eddystone (grain)\"}\n",
    "        production_rename_location = {\"Fly Creek/Camp 1\":\"Fly Creek\", \"Regina Farm\":\"Regina\",\"Swift Current Total\":\"Swift Current\", \"Box Elder\":\"Havre\", \"Regina Farm\":\"Regina\",\n",
    "                                    \"Colorado (Genoa)\":\"Colorado\", \"Calderbank\":\"Swift Current\",\"Airdrie\":\"Airdrie (grain)\", \"Eddystone\":\"Eddystone (grain)\"}\n",
    "        input_budget[\"Location\"] = input_budget[\"Location\"].replace(input_rename_location)\n",
    "        production_budget[\"Location\"] = production_budget[\"Location\"].replace(production_rename_location)\n",
    "        labour_budget[\"Location\"] = labour_budget[\"Location\"].replace(labour_rename_location)\n",
    "        jdlease[\"Location\"] = jdlease[\"Location\"].replace(jdlease_rename_location)\n",
    "        ## put input budget (chem/fert/seed) into aggregated totals\n",
    "        input_budget2 = input_budget.groupby([\"Location\",\"Type\"]).agg({\"Amount\":\"sum\"}).reset_index(drop=False)\n",
    "        ## aggregated totals for production budget and JD Lease\n",
    "        production_budget = pd.DataFrame(production_budget.groupby([\"Location\",\"Currency\",\"Commodity\",\"ForecastPrice\"]).agg({\"TotalYield\":\"sum\", \"ForecastProductionCAD\":\"sum\", \"ForecastProductionAdj\":\"sum\"}).reset_index(drop=False))\n",
    "        jdlease = pd.DataFrame(jdlease.groupby([\"Location\",\"Country\",\"Currency\",\"TotalCost25\"]).agg({\"Acres25\":\"sum\",\"AllocatedCost25\":\"sum\"}).reset_index(drop=False))\n",
    "        return input_budget2, production_budget, labour_budget, jdlease, az_budget, bc_budget, outlook_budget\n",
    "\n",
    "    def _budget_process_produce(self, budget_rules:pd.DataFrame,budget:pd.DataFrame,sheetname:str) -> pd.DataFrame:\n",
    "        \"\"\" \n",
    "            this function provides a standardized way to process produce budgets\n",
    "        \"\"\"\n",
    "        budget_rules = budget_rules[budget_rules[\"SheetRef\"] == sheetname].copy(deep=True)\n",
    "        budget_rules[\"Commodity\"] = budget_rules.apply(lambda x: self._identify_product(x,for_budget=True), axis=1)\n",
    "        budget[\"Type\"] = budget[\"Type\"].str.strip()\n",
    "        # gross income - by commodity\n",
    "        reference = budget[budget[\"Type\"].isin([\"Acres\",\"Unit Price\",\"YieldPerAc\"])]\n",
    "        reference = reference.groupby([\"Commodity\",\"ProfitType\",\"CommodityRaw\"]).agg({\"AmountCAD\":\"prod\"}).reset_index(drop=False)\n",
    "        reference = reference.groupby([\"Commodity\"]).agg({\"AmountCAD\":\"sum\"}).reset_index(drop=False)\n",
    "        reference = reference.rename(columns={\"AmountCAD\":\"TotalAmountCAD\"})\n",
    "        reference[\"Category\"] = \"Produce - production\"\n",
    "        if \"outlook\" in sheetname.lower():\n",
    "            for item in [\"Prairie Pathways\", \"Market Garden / CSA\"]:\n",
    "                reference.loc[reference[\"Commodity\"] == item, \"Category\"] = \"Produce - cash settlements\"\n",
    "        # seed expense - by commodity\n",
    "        expense = budget[budget[\"Type\"] == \"Seed\"].copy(deep=True)\n",
    "        expense = expense.drop(columns=\"CommodityRaw\")\n",
    "        expense = expense.groupby([\"Commodity\"]).agg({\"AmountCAD\":\"sum\"}).reset_index(drop=False).rename(columns={\"AmountCAD\":\"TotalAmountCAD\"})\n",
    "        expense[\"Category\"] = \"Seed\"\n",
    "        # other expense - Fertilizer/Chemical - not by commodity\n",
    "        expense2 = budget[budget[\"Type\"].isin([\"Fertilizer\",\"Chemical\"])]\n",
    "        expense2 = expense2.groupby([\"Type\"]).agg({\"AmountCAD\":\"sum\"}).reset_index(drop=False).rename(columns={\"AmountCAD\":\"TotalAmountCAD\"})\n",
    "        expense2[\"Commodity\"] = \"Others\"\n",
    "        expense2 = expense2.rename(columns={\"Type\":\"Category\"})\n",
    "        # combine\n",
    "        budget_produce = pd.merge(budget_rules, pd.concat([reference,expense, expense2]), on=[\"Commodity\",\"Category\"], how=\"left\")\n",
    "        budget_produce = budget_produce.fillna(value={\"TotalAmountCAD\":0})\n",
    "        budget_produce[\"AmountCAD\"] = budget_produce.apply(lambda x: eval(f\"{x[\"TotalAmountCAD\"]}{x[\"Formula\"]}\"),axis=1)\n",
    "        return budget_produce\n",
    "\n",
    "    def _budget_get_transactions(self) -> pd.DataFrame:\n",
    "        \"\"\" \n",
    "            get actuals\n",
    "        \"\"\"\n",
    "        transactions = self.gold_pl.copy(deep=True)\n",
    "        transactions = transactions[transactions[\"FiscalYear\"] >= 2024]\n",
    "        transactions[\"AccName\"] = transactions[\"AccName\"].str.strip()\n",
    "        # transactions_location_rename = {\"Calderbank\":\"Calderbank (cattle)\"}\n",
    "        # transactions[\"Location\"] = transactions[\"Location\"].replace(transactions_location_rename)\n",
    "        return transactions\n",
    "\n",
    "    def _create_budget(self, process_input:bool = False) -> None:\n",
    "        \"\"\" \n",
    "            In Progress: this function generates budgets\n",
    "        \"\"\"\n",
    "        print(\"\\nCreating Budget\\n\")\n",
    "        if not self.pl_exist:\n",
    "            self._finance_operational()\n",
    "        # self.gold_pl = pd.read_csv(self.gold_path[\"finance_operational\"]/\"PL.csv\")\n",
    "        # self.fx = 1.3807\n",
    "        inputdata_path = self.gold_path[\"budget\"] / \"Outside Data\"\n",
    "        processed_path = self.gold_path[\"budget\"] / \"Processed Data\"\n",
    "        rule_path = self.gold_path[\"budget\"] / \"Budget Rules\"\n",
    "        copied_path = self.gold_path[\"budget\"]/\"Copied Data\"\n",
    "\n",
    "        # load actuals\n",
    "        transactions = self._budget_get_transactions()\n",
    "        \n",
    "        # process outside data\n",
    "        if process_input:\n",
    "            self._buget_process_input(inputdata_path=inputdata_path, processed_path=processed_path)\n",
    "        \n",
    "        # read outside data\n",
    "        input_budget2, production_budget, labour_budget, jdlease, az_budget, bc_budget, outlook_budget = self._budget_read_outsidedata(processed_path=processed_path)\n",
    "\n",
    "        # calculate Budgets\n",
    "        ## outside data\n",
    "        ### read rules\n",
    "        budget_rules = pd.read_csv(rule_path/\"OutsideData.csv\")\n",
    "        budget_rename_category = {\"Seed - farm\":\"Seed\"}\n",
    "        budget_rules[\"Category\"] = budget_rules[\"Category\"].replace(budget_rename_category)\n",
    "        ### separate locations into individual rows when they are separated with + in the rules df\n",
    "        budget_rules[\"Location\"] = budget_rules[\"Location\"].str.split(\"+\")\n",
    "        budget_rules = budget_rules.explode(\"Location\").reset_index(drop=True)\n",
    "        ### extract formula\n",
    "        budget_rules = budget_rules.melt(\n",
    "            id_vars=[\"Location\",\"Category\",\"AccFull\",\"SheetRef\"],\n",
    "            var_name=\"Month\",\n",
    "            value_name=\"Formula\"\n",
    "        )\n",
    "        budget_rules = budget_rules.fillna(value={\"Formula\":\"0\"})\n",
    "        budget_rules[\"Formula\"] = budget_rules[\"Formula\"].astype(str)\n",
    "        budget_rules[\"Formula\"] = budget_rules[\"Formula\"].replace({\"0\": \"*0\"})\n",
    "        ### calculating input budget for accounts per location\n",
    "        budget_rules_input = budget_rules[budget_rules[\"SheetRef\"] == \"Input Budget\"].copy(deep=True)\n",
    "        #### workaround input budget for Airdrie grain \n",
    "        input_budget2.loc[((input_budget2[\"Location\"]==\"Airdrie (grain)\")&(input_budget2[\"Type\"]==\"Acres\")),\"Type\"] = \"Custom work\"\n",
    "        ### merge budget rules with budget total per location\n",
    "        budget_input = pd.merge(budget_rules_input,input_budget2.rename(columns={\"Type\":\"Category\",\"Amount\":\"TotalAmountCAD\"}),on=[\"Location\",\"Category\"],how=\"left\")\n",
    "        #### revert back from workaround\n",
    "        input_budget2.loc[((input_budget2[\"Location\"]==\"Airdrie (grain)\")&(input_budget2[\"Type\"]==\"Custom work\")),\"Type\"] = \"Acres\"\n",
    "        ### apply the formula to compute per month\n",
    "        budget_input[\"AmountCAD\"] = budget_input.apply(lambda x: eval(f\"{x[\"TotalAmountCAD\"]}{x[\"Formula\"]}\"), axis=1)\n",
    "\n",
    "        ## production budget\n",
    "        ### combine Hay and Silage\n",
    "        production_budget[\"Commodity\"] = production_budget[\"Commodity\"].replace({\"Hay\":\"Hay/Silage\", \"Silage\":\"Hay/Silage\"})\n",
    "        ### add commodity column to budget rules\n",
    "        budget_rules_production = budget_rules[budget_rules[\"SheetRef\"] == \"Production Budget\"].copy(deep=True)\n",
    "        budget_rules_production[\"Commodity\"] = budget_rules_production.apply(lambda x: self._identify_product(x, for_budget=True), axis=1)\n",
    "        ### merge budget rules with budget totals\n",
    "        budget_production = pd.merge(budget_rules_production,production_budget.loc[:,[\"Location\",\"Commodity\",\"ForecastProductionCAD\"]].rename(columns={\"ForecastProductionCAD\":\"TotalAmountCAD\"}),\n",
    "                                         on = [\"Location\", \"Commodity\"], how=\"left\")\n",
    "        budget_production = budget_production.fillna(value={\"TotalAmountCAD\":0})\n",
    "        ### compute budget\n",
    "        budget_production[\"AmountCAD\"] = budget_production.apply(lambda x: eval(f\"{x[\"TotalAmountCAD\"]}{x[\"Formula\"]}\"),axis=1)\n",
    "\n",
    "        ## labour budget\n",
    "        budget_rules_labour = budget_rules[budget_rules[\"SheetRef\"] == \"Labour Budget\"].copy(deep=True)\n",
    "        budget_labour = pd.merge(budget_rules_labour, labour_budget.loc[:,[\"Location\",\"Month\",\"LabourBudgetCAD\"]].rename(columns={\"LabourBudgetCAD\":\"AmountCAD\"}),\n",
    "                                    on=[\"Location\",\"Month\"],how=\"left\")\n",
    "        \n",
    "        ## produce budgets\n",
    "        ### BC\n",
    "        budget_bc_produce = self._budget_process_produce(budget_rules=budget_rules,budget=bc_budget,sheetname=\"BC Produce Details\")\n",
    "        ### AZ\n",
    "        budget_az_produce = self._budget_process_produce(budget_rules=budget_rules,budget=az_budget,sheetname=\"AZ Details\")\n",
    "        ### outlook\n",
    "        budget_outlook = self._budget_process_produce(budget_rules=budget_rules,budget=outlook_budget.rename(columns={\"Amount\":\"AmountCAD\"}),sheetname=\"Outlook Details\")\n",
    "\n",
    "        ## JD lease\n",
    "        budget_rules_jd = budget_rules[budget_rules[\"SheetRef\"]==\"JD Lease\"].copy(deep=True)\n",
    "        budget_equipment = pd.merge(budget_rules_jd, jdlease.loc[:,[\"Location\",\"AllocatedCost25\"]].rename(columns={\"AllocatedCost25\":\"TotalAmountCAD\"}),\n",
    "                                        on = \"Location\", how = \"left\")\n",
    "        budget_equipment = budget_equipment.fillna(value={\"TotalAmountCAD\":0})\n",
    "        budget_equipment[\"AmountCAD\"] = budget_equipment.apply(lambda x: eval(f\"{x[\"TotalAmountCAD\"]}{x[\"Formula\"]}\"),axis=1)\n",
    "\n",
    "        ## adjustment for Swift Current\n",
    "        months = [\"April\", \"July\"]\n",
    "        for month in months:\n",
    "            budget_input.loc[((budget_input[\"Location\"]==\"Swift Current\")&(budget_input[\"Category\"]==\"Fertilizer\")&(budget_input[\"Month\"]==month)),\"TotalAmountCAD\"] += \\\n",
    "            budget_input.loc[((budget_input[\"Location\"]==\"Calderbank (grain)\")&(budget_input[\"Category\"]==\"Fertilizer\")&(budget_input[\"Month\"]==month)),\"TotalAmountCAD\"].item()\n",
    "            budget_input.loc[((budget_input[\"Location\"]==\"Swift Current\")&(budget_input[\"Category\"]==\"Fertilizer\")&(budget_input[\"Month\"]==month)),\"AmountCAD\"] += \\\n",
    "            budget_input.loc[((budget_input[\"Location\"]==\"Calderbank (grain)\")&(budget_input[\"Category\"]==\"Fertilizer\")&(budget_input[\"Month\"]==month)),\"AmountCAD\"].item()\n",
    "        months = [\"June\", \"September\"]\n",
    "        for month in months:\n",
    "            budget_input.loc[((budget_input[\"Location\"]==\"Swift Current\")&(budget_input[\"Category\"]==\"Chemical\")&(budget_input[\"Month\"]==month)),\"TotalAmountCAD\"] += \\\n",
    "            budget_input.loc[((budget_input[\"Location\"]==\"Calderbank (grain)\")&(budget_input[\"Category\"]==\"Chemical\")&(budget_input[\"Month\"]==month)),\"TotalAmountCAD\"].item()\n",
    "            budget_input.loc[((budget_input[\"Location\"]==\"Swift Current\")&(budget_input[\"Category\"]==\"Chemical\")&(budget_input[\"Month\"]==month)),\"AmountCAD\"] += \\\n",
    "            budget_input.loc[((budget_input[\"Location\"]==\"Calderbank (grain)\")&(budget_input[\"Category\"]==\"Chemical\")&(budget_input[\"Month\"]==month)),\"AmountCAD\"].item()\n",
    "        months = [\"May\", \"June\", \"September\"]\n",
    "        for month in months:\n",
    "            budget_input.loc[((budget_input[\"Location\"]==\"Swift Current\")&(budget_input[\"Category\"]==\"Seed\")&(budget_input[\"Month\"]==month)),\"TotalAmountCAD\"] += \\\n",
    "            budget_input.loc[((budget_input[\"Location\"]==\"Calderbank (grain)\")&(budget_input[\"Category\"]==\"Seed\")&(budget_input[\"Month\"]==month)),\"TotalAmountCAD\"].item()\n",
    "            budget_input.loc[((budget_input[\"Location\"]==\"Swift Current\")&(budget_input[\"Category\"]==\"Seed\")&(budget_input[\"Month\"]==month)),\"AmountCAD\"] += \\\n",
    "            budget_input.loc[((budget_input[\"Location\"]==\"Calderbank (grain)\")&(budget_input[\"Category\"]==\"Seed\")&(budget_input[\"Month\"]==month)),\"AmountCAD\"].item()\n",
    "        \n",
    "        # arithmetic rules\n",
    "        arithmetic = pd.read_csv(rule_path/\"Arithmetic.csv\")\n",
    "        ## faltten location\n",
    "        arithmetic[\"Location\"] = arithmetic[\"Location\"].str.split(\"+\")\n",
    "        arithmetic = arithmetic.explode(\"Location\").reset_index(drop=True)\n",
    "        arithmetic_rules = arithmetic.melt(\n",
    "            id_vars=[\"Location\",\"Category\",\"AccFull\", \"AccRef\", \"FixedRef\"],\n",
    "            var_name=\"Month\",\n",
    "            value_name=\"FormulaFull\"\n",
    "        )\n",
    "        ## housekeeping\n",
    "        arithmetic_rules = arithmetic_rules.fillna(value={\"FormulaFull\":\"FY-1*0\"})\n",
    "        arithmetic_rules[\"FormulaFull\"] = arithmetic_rules[\"FormulaFull\"].astype(str)\n",
    "        arithmetic_rules[\"FormulaFull\"] = arithmetic_rules[\"FormulaFull\"].replace({\"0\":\"FY-1*0\"})\n",
    "        arithmetic_rules[\"ReferenceYear\"] = arithmetic_rules[\"FormulaFull\"].str.slice(0,4)\n",
    "        arithmetic_rules[\"Formula\"] = arithmetic_rules[\"FormulaFull\"].str.slice(4)\n",
    "        arithmetic_rules = arithmetic_rules.fillna(value={\"Formula\": \"0\"})\n",
    "        arithmetic_rules[\"Formula\"] = arithmetic_rules[\"Formula\"].astype(str)\n",
    "        arithmetic_rules[\"Formula\"] = arithmetic_rules[\"Formula\"].replace({\"0\":\"*0\"})\n",
    "        ## separating Fixed records\n",
    "        arithmetic_rules_fixed = arithmetic_rules[arithmetic_rules[\"AccRef\"] == \"Fixed\"].copy(deep=True)\n",
    "        arithmetic_rules = arithmetic_rules[arithmetic_rules[\"AccRef\"]!=\"Fixed\"].copy(deep=True)\n",
    "\n",
    "        ## process fixed records\n",
    "        arithmetic_rules_fixed = arithmetic_rules_fixed.drop(columns=[\"FormulaFull\",\"ReferenceYear\"]).rename(columns={\"FixedRef\":\"TotalAmountCAD\"})\n",
    "        arithmetic_rules_fixed[\"AmountCAD\"] = arithmetic_rules_fixed.apply(lambda x: eval(f\"{x[\"TotalAmountCAD\"]}{x[\"Formula\"]}\"),axis=1)\n",
    "\n",
    "        ## Extract Account Info\n",
    "        arithmetic_rules[\"AccNum\"] = arithmetic_rules[\"AccRef\"].apply(lambda x: \"\".join(x.split(\" \")[0:2]))\n",
    "        arithmetic_rules[\"AccName\"] = arithmetic_rules[\"AccRef\"].apply(lambda x: (\" \".join(x.split(\" \")[2:]).strip()))\n",
    "        assert \"Fixd\" not in arithmetic_rules.ReferenceYear.unique(), \"Fixd records incorrectly classified\"\n",
    "        ## separate FY-1 & FY+1\n",
    "        arithmetic_rules_prior = arithmetic_rules[arithmetic_rules[\"ReferenceYear\"] == \"FY-1\"].copy(deep=True)\n",
    "        arithmetic_rules = arithmetic_rules[arithmetic_rules[\"ReferenceYear\"] == \"FY+1\"].copy(deep=True)\n",
    "\n",
    "        ## process FY-1 with actuals\n",
    "        actuals = transactions.groupby([\"Location\", \"AccNum\", \"AccName\", \"FiscalYear\"]).agg({\"AmountDisplay\":\"sum\"}).reset_index(drop=False)\n",
    "        arithmetic_rules_prior[\"FiscalYear\"] = self.currentFY - 1\n",
    "        assert len(actuals[actuals.duplicated(subset=[\"AccNum\",\"FiscalYear\",\"Location\"],keep=False)]) == 0, \"Duplicated AccNum detected for FY-1 Actuals\"\n",
    "        budget_prior = pd.merge(arithmetic_rules_prior,actuals.rename(columns={\"AmountDisplay\":\"TotalAmountCAD\"}),\n",
    "                                on = [\"Location\",\"AccNum\",\"FiscalYear\"], how=\"left\")\n",
    "        budget_prior = budget_prior.fillna(value={\"TotalAmountCAD\": 0})\n",
    "        budget_prior[\"AmountCAD\"] = budget_prior.apply(lambda x: eval(f\"{x[\"TotalAmountCAD\"]}{x[\"Formula\"]}\"), axis=1)\n",
    "\n",
    "        ## processing FY+1 with current budget\n",
    "        ### budget sales that is based on production budget input sheet\n",
    "        arithmetic_rules_sales = arithmetic_rules[arithmetic_rules[\"Category\"].str.contains(\"cash settlements\")].copy(deep=True)\n",
    "        production_reference = pd.concat([budget_production.copy(deep=True), budget_outlook.copy(deep=True), budget_az_produce.copy(deep=True),budget_bc_produce.copy(deep=True)])\n",
    "        production_reference = production_reference.groupby([\"Location\",\"AccFull\"]).agg({\"AmountCAD\":\"sum\"}).reset_index(drop=False)\n",
    "        budget_sales = pd.merge(arithmetic_rules_sales,production_reference.rename(columns={\"AccFull\":\"AccRef\"}), on=[\"Location\",\"AccRef\"], how=\"left\")\n",
    "        budget_sales = budget_sales.rename(columns={\"AmountCAD\":\"TotalAmountCAD\"})\n",
    "        budget_sales[\"AmountCAD\"] = budget_sales.apply(lambda x: eval(f\"{x[\"TotalAmountCAD\"]}{x[\"Formula\"]}\"),axis=1)\n",
    "        budget_prior = pd.concat([budget_prior, budget_sales],ignore_index=True)\n",
    "\n",
    "        ### budget inventory adjustment \n",
    "        arithmetic_rules_inventory = arithmetic_rules[arithmetic_rules[\"Category\"].str.contains(\"inventory adjustment\",case=False)].copy(deep=True)\n",
    "        budget_inventory = pd.merge(arithmetic_rules_inventory, budget_prior.loc[:,[\"Location\",\"AccFull\",\"Month\",\"AmountCAD\"]].rename(columns={\"AccFull\":\"AccRef\"}),\n",
    "                                on = [\"Location\",\"AccRef\", \"Month\"], how = \"left\")\n",
    "        budget_inventory[\"AmountCAD\"] = -budget_inventory[\"AmountCAD\"]\n",
    "        budget_prior = pd.concat([budget_prior, budget_inventory], ignore_index=True)\n",
    "\n",
    "        ## combine with fixed budgets\n",
    "        budget_prior = pd.concat([budget_prior,arithmetic_rules_fixed],ignore_index=True)\n",
    "\n",
    "        # copied data\n",
    "        budget_copy = pd.read_csv(copied_path/\"Copied Data.csv\")\n",
    "        budget_copy = budget_copy.melt(\n",
    "            id_vars=[\"Location\",\"Category\",\"AccFull\"],\n",
    "            var_name = \"Month\",\n",
    "            value_name = \"AmountCAD\"\n",
    "        )\n",
    "        budget_copy = budget_copy.fillna(value={\"AmountCAD\":0})\n",
    "        budget_copy[\"AmountCAD\"] = budget_copy[\"AmountCAD\"].astype(float)\n",
    "        budget_copy[\"FiscalYear\"] = self.currentFY\n",
    "        budget_copy[\"AccRef\"] = \"Copy\"\n",
    "        budget_copy[\"ReferenceYear\"] = \"NA\"\n",
    "        budget_copy[\"Formula\"] = \"NA\"\n",
    "        budget_copy[\"TotalAmountCAD\"] = budget_copy[\"AmountCAD\"]\n",
    "        budget_copy.loc[budget_copy[\"Location\"]==\"Seeds USA\", \"AmountCAD\"] *= self.fx\n",
    "\n",
    "        # combining all budgets\n",
    "        budget_outside = pd.concat([budget_input,budget_production,budget_labour,budget_equipment, budget_outlook, budget_az_produce, budget_bc_produce],ignore_index=True)\n",
    "        budget_outside = budget_outside.drop(columns=[\"Commodity\"])\n",
    "        budget_prior = budget_prior.drop(columns=[\"FormulaFull\",\"AccNum\",\"AccName_x\", \"AccName_y\", \"AccName\", \"FixedRef\"])\n",
    "        budget_all = pd.concat([budget_outside,budget_prior,budget_copy],ignore_index=True)\n",
    "        budget_all[\"AccNum\"] = budget_all[\"AccFull\"].apply(lambda x: \"\".join(x.split(\" \")[0:2]))\n",
    "        budget_all[\"AccName\"] = budget_all[\"AccFull\"].apply(lambda x: \" \".join(x.split(\" \")[2:]))\n",
    "        budget_all[\"FiscalYear\"] = self.currentFY \n",
    "        budget_all[\"DataType\"] = \"Budget\"\n",
    "        budget_all.loc[budget_all[\"Category\"].str.contains(\"inventory adjustment\",case=False), \"AmountCAD\"] *= -1 # turn the sign positive for inventory adjustments\n",
    "\n",
    "        # save\n",
    "        self.check_file(self.gold_path[\"budget\"]/\"OutputFile\")\n",
    "        budget_all.to_csv(self.gold_path[\"budget\"]/\"OutputFile\"/\"budget_all.csv\", index=False)\n",
    "\n",
    "    def _budget_update(self, force_create:bool=False, force_process_input:bool=False) -> None:\n",
    "        \"\"\" \n",
    "            generate/update the actuals from the budget system\n",
    "        \"\"\"\n",
    "        print(\"\\nGenerating/Updating Actuals for budget system\\n\")\n",
    "        if not self.pl_exist:\n",
    "            self._finance_operational()\n",
    "        # self.gold_pl = pd.read_csv(self.gold_path[\"finance_operational\"]/\"PL.csv\")\n",
    "        # self.fx = 1.3807\n",
    "        budget_path = self.gold_path[\"budget\"]/\"OutputFile\"/\"budget_all.csv\"\n",
    "        if not Path.exists(budget_path) or force_create:\n",
    "            self._create_budget(process_input=force_process_input)\n",
    "        budget = pd.read_csv(budget_path)\n",
    "        budget = budget.loc[:,[\"Location\", \"SheetRef\", \"Month\", \"Formula\", \"TotalAmountCAD\", \"AmountCAD\", \"AccRef\", \"ReferenceYear\",\"FiscalYear\", \"AccNum\", \"DataType\", \"Category\"]]\n",
    "        budget_location_rename = {\"Airdrie (grain)\": \"Airdrie\", \"Airdrie (cattle)\": \"Airdrie\", \"Calderbank (cattle)\": \"Calderbank\",\n",
    "                                  \"Airdrie (corporate)\": \"Airdrie\", \"Seeds USA\":\"Arizona (produce)\"}\n",
    "        budget[\"Location\"] = budget[\"Location\"].replace(budget_location_rename)\n",
    "        category_mapping = budget.loc[:,[\"AccNum\", \"Category\"]].drop_duplicates()\n",
    "        # organize Actuals\n",
    "        transactions = self._budget_get_transactions()\n",
    "        actuals_all = transactions.groupby([\"Location\",\"AccNum\", \"FiscalYear\", \"Month\"]).agg({\"AmountDisplay\":\"sum\"}).reset_index(drop=False)\n",
    "        actuals_all = actuals_all[actuals_all[\"FiscalYear\"] == self.currentFY]\n",
    "        actuals_all[\"DataType\"] = \"Actual\"\n",
    "        actuals_all = actuals_all.rename(columns={\"AmountDisplay\": \"AmountCAD\"})\n",
    "        actuals_all = pd.merge(actuals_all,category_mapping,on=\"AccNum\",how=\"left\")\n",
    "        actuals_all.to_csv(self.gold_path[\"budget\"]/\"OutputFile\"/\"actuals_all.csv\", index=False)\n",
    "        print(f\"Location Unaccounted for in budget: {(set(budget.Location.unique()) - set(actuals_all.Location.unique()))}\")\n",
    "        # combine everything\n",
    "        all_all = pd.concat([budget,actuals_all],ignore_index=True)\n",
    "        all_all[\"FXRate\"] = self.fx\n",
    "        # operational classification\n",
    "        assert len(self.operation_acc[self.operation_acc.duplicated(subset=[\"AccNum\"],keep=False)]) == 0, \"Duplicated AccNum Detected - Operational Accounts Classification\"\n",
    "        all_all = pd.merge(all_all, self.operation_acc, on=\"AccNum\", how=\"left\")\n",
    "        # classify pillars\n",
    "        all_all[\"Pillar\"] = all_all.apply(lambda x: self._pillar_classification(x), axis=1)\n",
    "        # save\n",
    "        self.check_file(self.gold_path[\"budget\"]/\"OutputPowerBI\")\n",
    "        all_all.to_excel(self.gold_path[\"budget\"]/\"OutputPowerBI\"/\"BudgetActual.xlsx\", sheet_name=\"Budget\", index=False)\n",
    "\n",
    "    def run(self, force_run_time:bool=False, force_create_budget:bool=False, force_process_budget_input:bool=False) -> None:\n",
    "        start = perf_counter()\n",
    "\n",
    "        self._weekly_banking()\n",
    "        self._finance_operational()\n",
    "        self._payroll_project()\n",
    "        self._budget_update(force_create=force_create_budget, force_process_input=force_process_budget_input)\n",
    "        if force_run_time or (self.today.weekday()==0 or self.today.weekday() == 2): self._QBOTime_project()\n",
    "        self._hr_summary()\n",
    "        self._raw_inventory()\n",
    "\n",
    "        end = perf_counter()\n",
    "        print(f\"\\nProjects Transformation Finished with {(end-start)/60:.3f} minutes\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fb7e23c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = Projects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "752c0f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Finance Operational Project Transformation\n",
      "\n",
      "location unaccounted for - [nan]\n",
      "Revising Signs ...\n",
      "Saving ...\n",
      "\n",
      "Starting Payroll Project Transformation\n",
      "\n",
      "Allocating PPNum for transactions ...\n",
      "Summarizing ...\n",
      "Unaccounted location for Acres Doc: {'Airdrie (grain)', 'Seeds USA'}\n",
      "Saving ...\n"
     ]
    }
   ],
   "source": [
    "project._payroll_project()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4baf287",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "payroll = pd.read_csv(project.gold_path[\"hr_combined\"] / \"CSV\" / \"payroll_summarized3.csv\")\n",
    "payroll_rename = {\"AmountDisplay\": \"TotalAmount\", \"CostPerUnit\": \"AmountPerUnit\", \"Avg CostPerUnit\": \"Avg AmountPerUnit\"}\n",
    "payroll = payroll.rename(columns=payroll_rename)\n",
    "time = pd.read_csv(project.gold_path[\"hr_combined\"] / \"CSV\" / \"time_summarized3.csv\")\n",
    "time_rename = {\"duration\": \"TotalAmount\", \"HoursPerUnit\": \"AmountPerUnit\", \"Avg HoursPerUnit\": \"Avg AmountPerUnit\"}\n",
    "time = time.rename(columns=time_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "45984070",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = [pd.DataFrame(), pd.DataFrame(), pd.DataFrame()]\n",
    "for i in [1, 2, 3]:\n",
    "    payroll = pd.read_csv(project.gold_path[\"hr_combined\"] / \"CSV\" / f\"payroll_summarized{i}.csv\")\n",
    "    payroll_rename = {\"AmountDisplay\": \"TotalAmount\", \"CostPerUnit\": \"AmountPerUnit\", \"Avg CostPerUnit\": \"Avg AmountPerUnit\"}\n",
    "    payroll = payroll.rename(columns=payroll_rename)\n",
    "    payroll[\"Mode\"] = \"Payroll\"\n",
    "    time = pd.read_csv(project.gold_path[\"hr_combined\"] / \"CSV\" / f\"time_summarized{i}.csv\")\n",
    "    time_rename = {\"duration\": \"TotalAmount\", \"HoursPerUnit\": \"AmountPerUnit\", \"Avg HoursPerUnit\": \"Avg AmountPerUnit\"}\n",
    "    time = time.rename(columns=time_rename)\n",
    "    time[\"Mode\"] = \"Hours\"\n",
    "    final_df[i-1] = pd.concat([payroll, time], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ed7e5a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>PPName</th>\n",
       "      <th>Pillar</th>\n",
       "      <th>FiscalYear</th>\n",
       "      <th>Cycle</th>\n",
       "      <th>PPNum</th>\n",
       "      <th>TotalAmount</th>\n",
       "      <th>Unit</th>\n",
       "      <th>AmountPerUnit</th>\n",
       "      <th>Count</th>\n",
       "      <th>Mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Airdrie</td>\n",
       "      <td>24-PP18</td>\n",
       "      <td>Cattle</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024</td>\n",
       "      <td>18</td>\n",
       "      <td>1378.260000</td>\n",
       "      <td>1471771.0</td>\n",
       "      <td>0.024348</td>\n",
       "      <td>1</td>\n",
       "      <td>Payroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Airdrie</td>\n",
       "      <td>24-PP19</td>\n",
       "      <td>Cattle</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024</td>\n",
       "      <td>19</td>\n",
       "      <td>1339.090000</td>\n",
       "      <td>1471771.0</td>\n",
       "      <td>0.023656</td>\n",
       "      <td>1</td>\n",
       "      <td>Payroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Airdrie</td>\n",
       "      <td>24-PP20</td>\n",
       "      <td>Cattle</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024</td>\n",
       "      <td>20</td>\n",
       "      <td>3428.830000</td>\n",
       "      <td>1471771.0</td>\n",
       "      <td>0.060573</td>\n",
       "      <td>1</td>\n",
       "      <td>Payroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Airdrie</td>\n",
       "      <td>24-PP21</td>\n",
       "      <td>Cattle</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024</td>\n",
       "      <td>21</td>\n",
       "      <td>25672.860000</td>\n",
       "      <td>1471771.0</td>\n",
       "      <td>0.453531</td>\n",
       "      <td>1</td>\n",
       "      <td>Payroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Airdrie</td>\n",
       "      <td>24-PP22</td>\n",
       "      <td>Cattle</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024</td>\n",
       "      <td>22</td>\n",
       "      <td>37036.850000</td>\n",
       "      <td>1471771.0</td>\n",
       "      <td>0.654285</td>\n",
       "      <td>1</td>\n",
       "      <td>Payroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>Waldeck</td>\n",
       "      <td>25-PP14</td>\n",
       "      <td>Cattle</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025</td>\n",
       "      <td>14</td>\n",
       "      <td>498.433333</td>\n",
       "      <td>1460000.0</td>\n",
       "      <td>0.008876</td>\n",
       "      <td>1</td>\n",
       "      <td>Hours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>Waldeck</td>\n",
       "      <td>25-PP15</td>\n",
       "      <td>Cattle</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025</td>\n",
       "      <td>15</td>\n",
       "      <td>621.850000</td>\n",
       "      <td>1460000.0</td>\n",
       "      <td>0.011074</td>\n",
       "      <td>1</td>\n",
       "      <td>Hours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>Waldeck</td>\n",
       "      <td>25-PP16</td>\n",
       "      <td>Cattle</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025</td>\n",
       "      <td>16</td>\n",
       "      <td>711.616667</td>\n",
       "      <td>1460000.0</td>\n",
       "      <td>0.012673</td>\n",
       "      <td>1</td>\n",
       "      <td>Hours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>Waldeck</td>\n",
       "      <td>25-PP17</td>\n",
       "      <td>Cattle</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025</td>\n",
       "      <td>17</td>\n",
       "      <td>545.983333</td>\n",
       "      <td>1460000.0</td>\n",
       "      <td>0.009723</td>\n",
       "      <td>1</td>\n",
       "      <td>Hours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>Waldeck</td>\n",
       "      <td>25-PP18</td>\n",
       "      <td>Cattle</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025</td>\n",
       "      <td>18</td>\n",
       "      <td>29.650000</td>\n",
       "      <td>1460000.0</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>1</td>\n",
       "      <td>Hours</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2100 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Location   PPName  Pillar  FiscalYear  Cycle  PPNum   TotalAmount  \\\n",
       "0     Airdrie  24-PP18  Cattle        2024   2024     18   1378.260000   \n",
       "1     Airdrie  24-PP19  Cattle        2024   2024     19   1339.090000   \n",
       "2     Airdrie  24-PP20  Cattle        2024   2024     20   3428.830000   \n",
       "3     Airdrie  24-PP21  Cattle        2024   2024     21  25672.860000   \n",
       "4     Airdrie  24-PP22  Cattle        2024   2024     22  37036.850000   \n",
       "...       ...      ...     ...         ...    ...    ...           ...   \n",
       "2095  Waldeck  25-PP14  Cattle        2025   2025     14    498.433333   \n",
       "2096  Waldeck  25-PP15  Cattle        2025   2025     15    621.850000   \n",
       "2097  Waldeck  25-PP16  Cattle        2025   2025     16    711.616667   \n",
       "2098  Waldeck  25-PP17  Cattle        2025   2025     17    545.983333   \n",
       "2099  Waldeck  25-PP18  Cattle        2025   2025     18     29.650000   \n",
       "\n",
       "           Unit  AmountPerUnit  Count     Mode  \n",
       "0     1471771.0       0.024348      1  Payroll  \n",
       "1     1471771.0       0.023656      1  Payroll  \n",
       "2     1471771.0       0.060573      1  Payroll  \n",
       "3     1471771.0       0.453531      1  Payroll  \n",
       "4     1471771.0       0.654285      1  Payroll  \n",
       "...         ...            ...    ...      ...  \n",
       "2095  1460000.0       0.008876      1    Hours  \n",
       "2096  1460000.0       0.011074      1    Hours  \n",
       "2097  1460000.0       0.012673      1    Hours  \n",
       "2098  1460000.0       0.009723      1    Hours  \n",
       "2099  1460000.0       0.000528      1    Hours  \n",
       "\n",
       "[2100 rows x 11 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09c3f59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afce7250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef70489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1b1450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea35a901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dec410c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9814fadd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3486783a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3300668c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0771700b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e67ab75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96b364f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed76f4f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5423c17f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736055b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babc2f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
