{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97646f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path \n",
    "import os\n",
    "import datetime as dt\n",
    "import requests\n",
    "import json\n",
    "from intuitlib.client import AuthClient\n",
    "import urllib.parse\n",
    "from urllib.parse import urlparse, unquote, urljoin\n",
    "from time import perf_counter\n",
    "import re\n",
    "import yaml\n",
    "from io import StringIO\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "class Job:\n",
    "    def __init__(self):\n",
    "        base_dir = Path(\"c:/Users/ZheRao/OneDrive - Monette Farms/Monette Farms Team Site - Innovation Projects/Production/Database\")\n",
    "        self.base_dir = base_dir\n",
    "        self.today = dt.date.today()\n",
    "        month_format = \"\".join([\"0\",str(self.today.month)]) if self.today.month < 10 else str(self.today.month)\n",
    "        self.us_companies = [\"MFUSA\", \"MFAZ\", \"MSUSA\", \"MPUSA\"]\n",
    "        self.company_names = self.us_companies + [\"MSL\", \"NexGen\", \"MFBC\", \"MPL\", \"MFL\"]\n",
    "        self.raw_path = {\n",
    "            \"QBO\": {\n",
    "                \"Raw\": base_dir/\"Bronze\"/\"QBO\"/\"Raw\"/f\"{self.today.year}_{self.today.month}\",\n",
    "                \"GL\": base_dir/\"Bronze\"/\"QBO\"/\"GeneralLedger\",\n",
    "                \"PL\": base_dir/\"Bronze\"/\"QBO\"/\"ProfitAndLoss\",\n",
    "                \"Time\":base_dir/\"Bronze\"/\"QBOTime\",\n",
    "                \"APAR\": base_dir/\"Bronze\"/\"QBO\"/\"APAR\"\n",
    "            },\n",
    "            \"Delivery\": {\"Traction\":base_dir/\"Bronze\"/\"Traction\", \"HP\":base_dir/\"Bronze\"/\"HarvestProfit\"},\n",
    "            \"Auth\": {\"QBO\":base_dir/\"Bronze\"/\"Authentication\"/\"QBO\", \"QBOTime\": base_dir/\"Bronze\"/\"Authentication\"/\"QBOTime\",\n",
    "                     \"Harvest Profit\": base_dir/\"Bronze\"/\"Authentication\"/\"Harvest Profit\"},\n",
    "            \"Log\": base_dir/\"Load_History\"/f\"{self.today.year}\"/month_format\n",
    "        }\n",
    "        self.silver_path = {\n",
    "            \"QBO\": {\n",
    "                \"Dimension_time\": base_dir/\"Silver\"/\"QBO\"/\"Dimension\"/f\"{self.today.year}_{self.today.month}\",\n",
    "                \"Dimension\": base_dir/\"Silver\"/\"QBO\"/\"Dimension\",\n",
    "                \"Raw\": base_dir/\"Silver\"/\"QBO\"/\"Fact\"/\"Raw\",\n",
    "                \"PL\": base_dir/\"Silver\"/\"QBO\"/\"Fact\"/\"ProfitAndLoss\",\n",
    "                \"GL\": base_dir/\"Silver\"/\"QBO\"/\"Fact\"/\"GeneralLedger\",\n",
    "                \"Time\": base_dir/\"Silver\"/\"QBOTime\",\n",
    "                \"APAR\": base_dir/\"Silver\"/\"QBO\"/\"Fact\"/\"APAR\"\n",
    "            },\n",
    "            \"Delivery\": {\"Traction\":base_dir/\"Silver\"/\"Traction\", \"HP\":base_dir/\"Silver\"/\"HarvestProfit\"}\n",
    "        }\n",
    "        \n",
    "    \n",
    "    def get_fx(self):\n",
    "        key  = os.getenv(\"ALPHAVANTAGE_KEY\")\n",
    "        url  = (\"https://www.alphavantage.co/query?\"\n",
    "                \"function=CURRENCY_EXCHANGE_RATE\"\n",
    "                \"&from_currency=USD&to_currency=CAD\"\n",
    "                f\"&apikey={key}\")\n",
    "        rate = float(requests.get(url, timeout=10).json()\n",
    "                    [\"Realtime Currency Exchange Rate\"][\"5. Exchange Rate\"])\n",
    "        self.fx = rate\n",
    "    \n",
    "    def create_log(self, path: Path) -> None:\n",
    "        self.check_file(path)\n",
    "        day_format = \"\".join([\"0\",str(self.today.day)]) if self.today.day < 10 else str(self.today.day)\n",
    "        self.log = open(path/(day_format+\"_Log.txt\"), \"a\")\n",
    "\n",
    "    \n",
    "    def close_log(self):\n",
    "        self.log.close()\n",
    "\n",
    "    def check_file(self, path: Path) -> None:\n",
    "        if not Path.exists(path):\n",
    "            os.makedirs(path)\n",
    "    \n",
    "    def formulate_date(self, df:pd.DataFrame, date_cols:list[str], drop_time:bool=True) -> pd.DataFrame:\n",
    "        \"\"\" \n",
    "            format the date columns into datetime format\n",
    "        \"\"\"\n",
    "        assert len(set(date_cols) - set(df.columns)) == 0, \"Not all columns passed are inside dataframe passed\"\n",
    "        for col in date_cols:\n",
    "            df[col] = pd.to_datetime(df[col], utc=True)\n",
    "            if drop_time: df[col] = df[col].dt.date\n",
    "        return df\n",
    "\n",
    "\n",
    "class Projects(Job):\n",
    "    \"\"\" \n",
    "        for project specific data transformations\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, focus_last_FY:bool = False, is_dev:bool=False):\n",
    "        super().__init__()\n",
    "        self.gold_path = {\n",
    "            \"weekly_banking\": self.base_dir / \"Gold\" / \"FinanceProject\" / \"WeeklyBanking\",\n",
    "            \"inventory\": self.base_dir / \"Gold\" / \"InventoryProject\",\n",
    "            \"payroll\": self.base_dir / \"Gold\" / \"HRProject\" /\"PayrollProject\",\n",
    "            \"finance_operational\": self.base_dir / \"Gold\" / \"FinanceOperationalProject\",\n",
    "            \"budget\": self.base_dir / \"Gold\" / \"BudgetProject\",\n",
    "            \"QBOTime\": self.base_dir / \"Gold\" / \"HRProject\" / \"QBOTimeProject\",\n",
    "            \"hr_combined\": self.base_dir / \"Gold\" / \"HRProject\" / \"CombinedSummary\",\n",
    "            \"pillar_dashboard\": self.base_dir / \"Gold\" / \"DirectorDashboards\",\n",
    "            \"APReporting\": self.base_dir / \"Gold\" / \"FinanceProject\" / \"APReporting\"\n",
    "        }\n",
    "        self.silver_acc = pd.read_csv(self.silver_path[\"QBO\"][\"Dimension_time\"]/\"Account.csv\")\n",
    "        self.commodities = {\n",
    "            \"Produce\": [\"Strawberry\", \"Watermelon\", \"Cantaloupe\", \"Market Garden\", \"Broccoli\", \"Pumpkin\", \"Sweet Corn\", \"Cauliflower\", \"Squash\", \"Honeydew Melon\", \"Potato\", \"Carrot\", \"Cabbage\",\n",
    "                        \"Lettuce\", \"Brussel Sprouts\", \"Prairie Pathways\", \"Beet\", \"Corn Maze\", \"CSA\"],\n",
    "            \"Grain\": [\"Blackeye Pea\", \"Winter Wheat\", \"Durum\", \"Cotton\", \"Chickpea\", \"Barley\", \"Green Lentil\", \"Red Lentil\", \"Canola\", \n",
    "                        \"Wheat\",\"Field Pea\", \"Corn\", \"Oat\", \"Soybean\", \"Bean\"],\n",
    "            \"Cattle\": [\"Weaned Calves\", \"Cull Bull\", \"Cull Cow\", \"Bred Heifer\", \"Purebred Yealing Bull\", \"Purebred Heifer\", \n",
    "                        \"Purebred Cow\", \"Purebred Bull\", \"Cow\", \"Bull\", \"Steer\", \"Heifer\", \"Yearling\", \"Calf\"]\n",
    "        }\n",
    "        self.locations = {\n",
    "            \"Produce\": [\"BritishColumbia (produce)\", \"Outlook\", \"Arizona (produce)\", \"Montana (produce)\", \"Seeds USA\"],\n",
    "            \"Cattle\": [\"Airdrie\", \"Eddystone (cattle)\", \"Ashcroft\", \"Home Ranch\", \"Diamond S\", \"Wolf Ranch\", \"Fraser River Ranch\", \"Moon Ranch\", \"Waldeck\", \"Calderbank\"],\n",
    "            \"Grain\": [\"Eddystone (grain)\", \"Arizona (grain)\", \"Colorado\", \"Swift Current\", \"Regina\", \"Raymore\", \"Prince Albert\", \"The Pas\",\n",
    "                      \"Kamsack\", \"Hafford\", \"Yorkton\", \"Fly Creek\", \"Camp 4\", \"Havre\", \"Billings\"],\n",
    "            \"Seed\": [\"NexGen\", \"Seeds\"],\n",
    "            \"Others\": [\"Eddystone (corporate)\", \"Arizona (corporate)\", \"Legacy\", \"BritishColumbia (corporate)\", \"Corporate\"]\n",
    "        }\n",
    "        self.bc_ranches = [\"Ashcroft\", \"Fraser River Ranch\", \"Moon Ranch\", \"Wolf Ranch\", \"Diamond S\",\"Home Ranch\"]\n",
    "        self.pl_exist = False # determines whether _financial_operational has run and gold_pl is stored in self, if not, any subsequent downstream projects will run _financial_operational first\n",
    "        self.currentFY = self.today.year if self.today.month<=10 else self.today.year + 1\n",
    "        if focus_last_FY: self.currentFY -= 1\n",
    "        self.is_dev = is_dev\n",
    "        self.accnum_reroute = {\"MFL405101\": \"MFL405110\", \"MFL405102\":\"MFL405120\", \"MFL405103\":\"MFL405130\", \"MSL585000\":\"MSL562505\", \"MSL402110\": \"MSL402112\", \"MFBC575000\": \"MFBC575020\",\n",
    "                               \"MFBC629000\": \"MFBC629010\"}\n",
    "        self.accid_reroute = {\"MFBC250\": \"MFBC210\", \"MFBC216\":\"MFBC210\", \"MFBC358\":\"MFBC210\", \"MFBC255\":\"MFBC210\", \"MFBC314\":\"MFBC272\", \"MFBC268\":\"MFBC584\", \"MFBC188\":\"MFBC192\", \"MFBC374\":\"MFBC190\",\n",
    "                              \"MFBC61\":\"MFBC190\", \"MFBC26\":\"MFBC585\", \"MFBC412\":\"MFBC242\", \"MFBC66\": \"MFBC592\", \"MFBC65\":\"MFBC220\", \"MFBC19\":\"MFBC210\", \"MFBC60\":\"MFBC187\"}\n",
    "        self.conversion_mt_to_lb = 2204.62262185\n",
    "        self.conversion_bu_to_lb_canola = 55\n",
    "        self.conversion_bu_to_lb_others = 60\n",
    "\n",
    "    def _pillar_classification(self, entry: pd.Series) -> str:\n",
    "        \"\"\" \n",
    "            this function classifies pillar of a transaction based on location\n",
    "        \"\"\"\n",
    "        location = entry[\"Location\"]\n",
    "        if not isinstance(location, str) or (location == \"Missing\"):\n",
    "            return \"Missing\"\n",
    "        if \"produce\" in location:\n",
    "            return \"Produce\"\n",
    "        elif \"grain\" in location:\n",
    "            return \"Grain\"\n",
    "        elif \"cattle\" in location:\n",
    "            return \"Cattle\"\n",
    "        elif \"corporate\" in location:\n",
    "            return \"Unclassified\"\n",
    "        match location.lower():\n",
    "            case \"hafford\"|\"kamsack\"|\"prince albert\"|\"raymore\"|\"regina\"|\"swift current\"|\"the pas\"|\"camp 4\"|\"fly creek\"|\"havre\"|\"yorkton\"|\"colorado\"|\"billings\":\n",
    "                return \"Grain\"\n",
    "            case \"outlook\"|\"seeds usa\":\n",
    "                return \"Produce\"\n",
    "            case \"ashcroft\"|\"diamond s\"|\"fraser river ranch\"|\"home ranch\"|\"moon ranch\"|\"wolf ranch\"|\"waldeck\"|\"calderbank\"|\"airdrie\":\n",
    "                return \"Cattle\"\n",
    "            case \"seeds\"|\"nexgen\":\n",
    "                return \"Seed\"\n",
    "            case _:\n",
    "                return \"Unclassified\"\n",
    "    \n",
    "    def _identify_product(self, entry: pd.Series, for_budget:bool=False) -> str:\n",
    "        \"\"\" \n",
    "            this function identifies commodity from account names, except for seed, \n",
    "                if this function is called from budget project, it combines MG & CSA and take CM into consideration, and name forage differently\n",
    "        \"\"\"\n",
    "        if not for_budget:\n",
    "            if entry[\"Corp\"] in [\"MSL\", \"MSUSA\", \"NexGen\"]:\n",
    "                return \"SeedProduct\"\n",
    "        accname = entry[\"AccName\"].lower() if not for_budget else entry[\"AccFull\"].lower()\n",
    "        if \"float\" in accname:\n",
    "            return \"Others\"\n",
    "        for x in self.commodities[\"Produce\"] + self.commodities[\"Grain\"] + self.commodities[\"Cattle\"]:\n",
    "            if x.lower() in accname:\n",
    "                if for_budget:\n",
    "                    match x:\n",
    "                        case \"Market Garden\"|\"CSA\":\n",
    "                            return \"Market Garden / CSA\"\n",
    "                        case \"Corn Maze\":\n",
    "                            return \"Prairie Pathways\"\n",
    "                    return x \n",
    "                return x\n",
    "        if \"straw\" in accname or \"forage\" in accname or \"hay bale\" in accname:\n",
    "            if for_budget: \n",
    "                return \"Hay/Silage\" \n",
    "            else: \n",
    "                return \"Forage\"\n",
    "        return \"Others\"\n",
    "    \n",
    "    def _weekly_banking(self) -> None:\n",
    "        \"\"\" \n",
    "            weekly banking project: match latest GL bank transactions with raw activities - extract accounts for those activities\n",
    "                assumptions: a raw entry (e.g., invoice) can have multiple lines - multiple associated accounts, only considering the first one \n",
    "        \"\"\"\n",
    "        print(\"\\nStarting Weekly Banking Project Transformation\\n\")\n",
    "        # determine minal date to keep for GL\n",
    "        if self.today.month > 6:\n",
    "            year = self.today.year \n",
    "            month = self.today.month - 6 \n",
    "        else:\n",
    "            year = self.today.year - 1\n",
    "            month = self.today.month + 12 - 6\n",
    "        # load and prepare data\n",
    "        ## account\n",
    "        account = self.silver_acc.copy(deep=True)\n",
    "        ## change some accounts to Transfer category\n",
    "        acc_list = [\"MFL264\", \"MSL250\"]\n",
    "        account.loc[account[\"AccID\"].isin(acc_list), \"ProfitType\"] = \"Asset\"\n",
    "        account.loc[account[\"AccID\"].isin(acc_list), \"Category\"] = \"Transfer\"\n",
    "        account_bank = account[account[\"AccountType\"]==\"Bank\"]\n",
    "        ## LinkedTxn for invoice and bill\n",
    "        invoice_linked = pd.read_csv(self.silver_path[\"QBO\"][\"Raw\"] / \"LinkedTxn\"/ \"LinkedTxn_Mapping_Invoice.csv\")\n",
    "        bill_linked = pd.read_csv(self.silver_path[\"QBO\"][\"Raw\"] / \"LinkedTxn\"/ \"LinkedTxn_Mapping_Bill.csv\")\n",
    "        mapping = pd.concat([invoice_linked, bill_linked])\n",
    "        mapping = mapping.drop(columns=[\"Corp\"])\n",
    "        # define customized function for processing other raw table\n",
    "        def _process_facts(df_type:str) -> pd.DataFrame:\n",
    "            \"\"\" \n",
    "                function for processing raw tables for mapping table - TransactionID_partial to AccID\n",
    "            \"\"\"\n",
    "            df = pd.read_csv(self.silver_path[\"QBO\"][\"Raw\"]/(df_type+\".csv\"), usecols = [\"TransactionID\", \"AccID\"])\n",
    "            df[\"TransactionID\"] = df[\"TransactionID\"].apply(lambda x: x.split(\"-\")[1])\n",
    "            df = df.drop_duplicates()\n",
    "            df = df.rename(columns={\"TransactionID\":\"TxnId\"})\n",
    "            return df\n",
    "        ## purchase table for expense transactions\n",
    "        purchase = _process_facts(\"Purchase\")\n",
    "        purchase[\"TxnType\"] = \"Expense\"\n",
    "        mapping = pd.concat([mapping,purchase])\n",
    "        ## journal entries - exclude most entries related to bank\n",
    "        journal = _process_facts(\"JournalEntry\")\n",
    "        journal[\"TxnType\"] = \"Journal Entry\"\n",
    "        # for journal entries, exclude most of entires where the activity account ID is a bank ID\n",
    "        exclude_list = list(account_bank.AccID.unique())\n",
    "        # mylist = [\"MFL51\", \"MFBC470\", \"MFBC471\", \"MFL28\", \"MFL27\", \"MFL1150040024\"]\n",
    "        mylist = [\"MFBC470\", \"MFBC471\"] # should include these accounts\n",
    "        for acc in mylist:\n",
    "            exclude_list.remove(acc)\n",
    "        journal = journal[~journal[\"AccID\"].isin(exclude_list)]\n",
    "        mapping = pd.concat([mapping,journal])\n",
    "        ## deposit\n",
    "        deposit = _process_facts(\"Deposit\")\n",
    "        deposit[\"TxnType\"] = \"Deposit\"\n",
    "        mapping = pd.concat([mapping,deposit])\n",
    "        ## salesreceipts\n",
    "        sales = _process_facts(\"SalesReceipt\")\n",
    "        sales[\"TxnType\"] = \"Sales Receipt\"\n",
    "        mapping = pd.concat([mapping,sales])\n",
    "        # process mapping table - dedup\n",
    "        mapping = mapping.drop_duplicates(subset=[\"TxnId\"],keep=\"first\")\n",
    "        ## load GL transacitons\n",
    "        cols = [\"TransactionType\",\"TransactionID_partial\",\"AccID\",\"AccNum\",\"AccName\", \"TransactionDate\", \"Amount\", \"SplitAcc\", \"SplitAccID\", \"Memo\", \"Corp\", \"Balance\"]\n",
    "        transactions = pd.read_csv(self.silver_path[\"QBO\"][\"GL\"]/\"GeneralLedger.csv\",dtype={\"TransactionID_partial\":str}, usecols=cols)\n",
    "        transactions = transactions[transactions[\"AccID\"].isin(account_bank.AccID.unique())]\n",
    "        transactions[\"TransactionDate\"] = pd.to_datetime(transactions[\"TransactionDate\"])\n",
    "        transactions = transactions[transactions[\"TransactionDate\"]>=dt.datetime(year, month, 1)]\n",
    "        transactions = transactions.rename(columns={\"TransactionType\":\"TxnType\",\"TransactionID_partial\":\"TxnId\",\n",
    "                                                    \"AccID\":\"BankAccID\",\"AccNum\":\"BankAccNum\",\"AccName\":\"BankAccName\",\n",
    "                                                    \"TransactionDate\":\"BankActivityDate\",\"Amount\":\"BankAmount\"})\n",
    "        transactions[\"Sign\"] = transactions[\"BankAmount\"].apply(lambda x: \"Positive\" if x>=0 else \"Negative\")\n",
    "        # merge to get CurrencyID for bank_acc\n",
    "        transactions = pd.merge(transactions, account_bank.loc[:,[\"AccID\",\"CurrencyID\"]], left_on=[\"BankAccID\"], right_on=[\"AccID\"], how=\"left\")\n",
    "        transactions = transactions.drop(columns=[\"AccID\"])\n",
    "        # separating transfers - don't merge with mapping table\n",
    "        transfers = transactions[transactions[\"TxnType\"] == \"Transfer\"].copy(deep=True)\n",
    "        transactions = transactions[transactions[\"TxnType\"]!=\"Transfer\"]\n",
    "        transactions = transactions.drop(columns=[\"SplitAcc\", \"SplitAccID\"])\n",
    "        transactions[\"BankActivityDate\"] = pd.to_datetime(transactions[\"BankActivityDate\"])\n",
    "        transactions[\"TxnType\"] = transactions[\"TxnType\"].replace({\"Cheque Expense\":\"Expense\", \"Check\": \"Expense\"})\n",
    "        # merge with mapping table\n",
    "        transactions_mapped = pd.merge(transactions,mapping,on=[\"TxnId\",\"TxnType\"],how=\"left\")\n",
    "        non_match = transactions_mapped[transactions_mapped[\"AccID\"].isna()]\n",
    "        print(\"None Match Transaction Types\")\n",
    "        print(non_match.TxnType.value_counts())\n",
    "        print(f\"Non matches - {len(non_match)}\")\n",
    "        # function to determine transfer type\n",
    "        def _determine_transfer_type(entry:str) -> str:\n",
    "            \"\"\" \n",
    "                determine whether the transfer is for visa, bank, or other transfer\n",
    "            \"\"\"\n",
    "            if \"visa\" in entry.lower():\n",
    "                return \"Visa Payment\"\n",
    "            elif \"due\" in entry.lower():\n",
    "                return \"Bank Transfer\"\n",
    "            else:\n",
    "                return \"Other Transfer\"\n",
    "        # allocate transfer type \n",
    "        transfers[\"TransferType\"] = transfers[\"SplitAcc\"].apply(lambda x: _determine_transfer_type(x))\n",
    "        transfers = transfers.rename(columns={\"SplitAccID\":\"AccID\"})\n",
    "        transfers = transfers.drop(columns=[\"SplitAcc\"])\n",
    "        transactions_mapped = pd.concat([transactions_mapped,transfers], ignore_index=True)\n",
    "        # clean up the dataframe\n",
    "        transactions_mapped = transactions_mapped.rename(columns={\"CurrencyID\":\"BankCurrencyID\"})\n",
    "        transactions_mapped = pd.merge(transactions_mapped, account.loc[:,[\"AccID\",\"AccName\",\"AccNum\",\"Category\",\"ProfitType\",\"CurrencyID\"]], on=\"AccID\", how=\"left\")\n",
    "        transactions_mapped.loc[transactions_mapped[\"TransferType\"]==\"Bank Transfer\",\"Category\"] = \"Bank Transfer\"\n",
    "        transactions_mapped.loc[((transactions_mapped[\"BankAccNum\"].str.startswith(\"MSL\"))&(transactions_mapped[\"AccNum\"]==\"MSL120001\")), \"Category\"] = \"Seed Processing Revenue\"\n",
    "        transactions_mapped = transactions_mapped.rename(columns={\"AccNum\":\"ActivityAccNum\", \"AccName\":\"ActivityAccName\"})\n",
    "        transactions_mapped.loc[((transactions_mapped[\"TxnType\"]==\"Sales Tax Payment\")&(transactions_mapped[\"Sign\"]==\"Positive\")), \"ProfitType\"] = \"Other Operating Revenue\"\n",
    "        transactions_mapped.loc[((transactions_mapped[\"TxnType\"]==\"Sales Tax Payment\")&(transactions_mapped[\"Sign\"]==\"Positive\")), \"Category\"] = \"Miscellaneous income\"\n",
    "        transactions_mapped.loc[((transactions_mapped[\"TxnType\"]==\"Sales Tax Payment\")&(transactions_mapped[\"Sign\"]==\"Negative\")), \"ProfitType\"] = \"Operating Overheads\"\n",
    "        transactions_mapped.loc[((transactions_mapped[\"TxnType\"]==\"Sales Tax Payment\")&(transactions_mapped[\"Sign\"]==\"Negative\")), \"Category\"] = \"Office and miscellaneous\"\n",
    "        transactions_mapped.loc[((transactions_mapped[\"TxnType\"]==\"Sales Tax Payment\")), \"ActivityAccNum\"] = \"Manual Adjustment\"\n",
    "        transactions_mapped.loc[((transactions_mapped[\"TxnType\"]==\"Sales Tax Payment\")), \"ActivityAccName\"] = \"Manual Adjustment\"\n",
    "        # csv from sharepoint is unstable, and produced unpredictable readings from Power BI\n",
    "        self.check_file(self.gold_path[\"weekly_banking\"])\n",
    "        transactions_mapped.to_excel(self.gold_path[\"weekly_banking\"]/\"BankingActivity.xlsx\", sheet_name=\"transactions\", index=False)\n",
    "\n",
    "    def _extract_accnum_accid(self) -> None:\n",
    "        \"\"\" \n",
    "            this function creates a accnum to accID mapping table to avoid repeated merges\n",
    "        \"\"\"\n",
    "        self.acc_map = self.operation_acc.set_index([\"AccNum\"])[\"AccID\"]\n",
    "\n",
    "    def _perform_manual_adjust_GL_inventory(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\" \n",
    "            This function reads inventory account balances at the beginning of this fiscal year, and apply the amount to PL accounts for Fert/Chem/Seed\n",
    "        \"\"\"\n",
    "        # fixed column values \n",
    "        date = '2024-11-01'\n",
    "        transaction_type = 'Manual Adjustments'\n",
    "        memo = 'Adjustments from Trial Balance from beginning of this fiscal year'\n",
    "        FY = 2025\n",
    "        month = 'November'\n",
    "        # read adjustments csv file\n",
    "        adjustments = pd.read_csv(self.gold_path[\"finance_operational\"]/\"ManualAdjustments\"/\"2025.csv\",dtype={\"Amount\":float})\n",
    "        location_adj = {\"Camp 4\": \"Billings\", \"Fly Creek\":\"Billings\"}\n",
    "        adjustments[\"Location\"] = adjustments[\"Location\"].replace(location_adj)\n",
    "        # compute various Amount columns to match the other PL entries\n",
    "        adjustments[\"AmountAdj\"] = -adjustments[\"Amount\"]\n",
    "        adjustments[\"AmountCAD\"] = adjustments.apply(lambda x: x[\"AmountAdj\"] * self.fx if x[\"Currency\"]==\"USD\" else x[\"AmountAdj\"],axis=1)\n",
    "        adjustments[\"AmountDisplay\"] = -adjustments[\"AmountCAD\"]\n",
    "        adjustments[\"AccNum\"] = adjustments.apply(lambda x: \"\".join(x[\"DisplayName\"].split(\" \")[:2]),axis=1)\n",
    "        # create additional entries\n",
    "        addition_df = df.head(0).copy(deep=True)\n",
    "        row = {\"TransactionDate\":date, \"TransactionType\":transaction_type, \"Memo\":memo, \"FiscalYear\":FY, \"Month\":month, \"FXRate\": self.fx}\n",
    "        for i in range(len(adjustments)):\n",
    "            entry = row | {\"Amount\": adjustments.loc[i,\"Amount\"], \"AccID\": adjustments.loc[i,\"AccID\"], \"AmountAdj\": adjustments.loc[i,\"AmountAdj\"], \n",
    "                        \"AmountCAD\": adjustments.loc[i,\"AmountCAD\"], \"AmountDisplay\":adjustments.loc[i,\"AmountDisplay\"],\n",
    "                        \"Location\":adjustments.loc[i,\"Location\"], \"Pillar\": adjustments.loc[i,\"Pillar\"],\n",
    "                        \"AccNum\":adjustments.loc[i,\"AccNum\"] }\n",
    "            addition_df.loc[len(addition_df)] = entry\n",
    "        print(f\"\\nManual GL Inventory Accounts Adjustments created {len(addition_df)} entries\\n\")\n",
    "        df = pd.concat([df,addition_df],ignore_index=True)\n",
    "        return df\n",
    "\n",
    "    def _finance_operational(self) -> None:\n",
    "        \"\"\" \n",
    "            transform PL data into operational-ready\n",
    "                1. reclassify accounts\n",
    "                2. standardize location, classify pillar\n",
    "                3. revising signs\n",
    "        \"\"\"\n",
    "        print(\"\\nStarting Finance Operational Project Transformation\\n\")\n",
    "        # load data from silver space\n",
    "        data = pd.read_csv(self.silver_path[\"QBO\"][\"PL\"]/\"ProfitAndLoss.csv\")\n",
    "        assert len(data.FXRate.value_counts()) == 1, \"different FXRate detected\"\n",
    "        self.fx = data.loc[0,\"FXRate\"]\n",
    "        data[\"TransactionDate\"] = pd.to_datetime(data[\"TransactionDate\"])\n",
    "        data[\"FiscalYear\"] = data.TransactionDate.apply(lambda x: x.year + 1 if x.month >= 11 else x.year)\n",
    "        # add month to the PL\n",
    "        data[\"Month\"] = data[\"TransactionDate\"].dt.month_name()\n",
    "        ## add location for seed operation\n",
    "        data.loc[data[\"Corp\"]==\"MSL\",\"Location\"] = \"Seeds\"\n",
    "        data.loc[data[\"Corp\"]==\"NexGen\",\"Location\"] = \"NexGen\"\n",
    "        data.loc[data[\"Corp\"]==\"MSUSA\",\"Location\"] = \"Seeds USA\"\n",
    "        # clean location\n",
    "        data = data.rename(columns={\"Location\":\"LocationRaw\"})\n",
    "        data[\"Location\"] = data[\"LocationRaw\"]\n",
    "        data = data.fillna(value={\"Location\":\"Missing\"})\n",
    "        # switch seeds usa to AZ produce\n",
    "        data.loc[data[\"Corp\"]==\"MSUSA\",\"Location\"] = \"Arizona (produce)\"\n",
    "        ## clean location\n",
    "        clean_location = {\"Airdrie - Grain\":\"Airdrie\", \"Airdrie - Cattle\":\"Airdrie\", \"Airdrie - General\":\"Airdrie\", \"Airdrie\":\"Airdrie\", \n",
    "                        \"Eddystone - Grain\": \"Eddystone (grain)\", \"Eddystone - Cattle\": \"Eddystone (cattle)\", \"Eddystone - General\":\"Eddystone (corporate)\",\n",
    "                        \"Outlook (JV)\":\"Outlook\", \"AZ Produce\":\"Arizona (produce)\", \"Corporate\":\"Arizona (corporate)\", \"BC Produce\":\"BritishColumbia (produce)\",\n",
    "                        \"Grain\":\"Arizona (grain)\", \"Ashcroft (CC, Fischer, Loon)\":\"Ashcroft\", \n",
    "                        \"Outlook (Capital)\":\"Outlook\", \"Colorado (MF)\":\"Colorado\", \"Colorado (JV)\":\"Colorado\", \"Cattle - General\":\"BritishColumbia (corporate)\",\n",
    "                        \"Home (70 M, LF/W, 105 M)\":\"Home Ranch\", \"Diamond S (BR)\":\"Diamond S\", \"-Corporate\":\"Corporate\",\n",
    "                        \"MT Produce\": \"Montana (produce)\", \"Fly Creek\": \"Billings\", \"Camp 4\":\"Billings\"}\n",
    "        others = {\"North Farm (deleted)\":\"Legacy\", \"Cache/Fischer/Loon - DNU\":\"Legacy\"}\n",
    "        data[\"Location\"] = data[\"Location\"].replace(clean_location)\n",
    "        locations = self.locations[\"Produce\"] + self.locations[\"Grain\"] + self.locations[\"Cattle\"] + self.locations[\"Others\"] + self.locations[\"Seed\"]\n",
    "        unaccounted_location = list(set(data[\"Location\"].unique()) - set(locations))\n",
    "        print(f\"location unaccounted for - {unaccounted_location}\")\n",
    "        # classify pillar\n",
    "        data[\"Pillar\"] = data.apply(lambda x: self._pillar_classification(x),axis=1)\n",
    "        # reorganize corp\n",
    "        ## MPUSA missing location = Arizona (produce)\n",
    "        data.loc[((data[\"Corp\"] == \"MPUSA\")&(data[\"Location\"].isna())), \"Location\"] = \"Arizona (produce)\"\n",
    "        data.loc[((data[\"Corp\"] == \"MPUSA\")&(data[\"Location\"]==\"Missing\")), \"Location\"] = \"Arizona (produce)\"\n",
    "        data.loc[((data[\"Corp\"] == \"MPUSA\")&(data[\"Location\"] == \"Arizona (produce)\")), \"Pillar\"] = \"Produce\"\n",
    "        ## AZ Produce --> MPUSA\n",
    "        data.loc[data[\"Location\"] == \"Arizona (produce)\", \"Corp\"] = \"MPUSA\"\n",
    "        ## move everything for AZ in 2024 to produce\n",
    "        data.loc[((data[\"FiscalYear\"] >= 2024) & (data[\"Location\"].str.contains(\"Arizona\",case=False))),\"Pillar\"] = \"Produce\"\n",
    "        data.loc[((data[\"FiscalYear\"] >= 2024) & (data[\"Location\"].str.contains(\"Arizona\",case=False))),\"Location\"] = \"Arizona (produce)\"\n",
    "        ## BC Produce --> MPL\n",
    "        data.loc[data[\"Location\"] == \"BritishColumbia (produce)\", \"Corp\"] = \"MPL\"\n",
    "        ## Outlook --> MPL\n",
    "        data.loc[data[\"Location\"]==\"Outlook\", \"Corp\"] = \"MPL\"\n",
    "        # reroute accid\n",
    "        data[\"AccID\"] = data[\"AccID\"].replace(self.accid_reroute)\n",
    "        # Reclassify accounts for Operational Purpose\n",
    "        ## read & process operational classification\n",
    "        with open(self.silver_path[\"QBO\"][\"Dimension\"]/\"acc_classification.yaml\", \"r\", encoding=\"utf-8\") as f:\n",
    "            raw_acc = yaml.safe_load(f)\n",
    "        rows = [(l1, l2, l3, v) \n",
    "                for l1, l1_inner in raw_acc.items() \n",
    "                for l2, l2_inner in l1_inner.items() \n",
    "                for l3, l3_inner in l2_inner.items() \n",
    "                for v in l3_inner]\n",
    "        acc_operation = pd.DataFrame(rows, columns=[\"OperationProfType\", \"OperationCategory\", \"OperationSubCategory\", \"AccID\"])\n",
    "        ## read accounts table and apply new classification\n",
    "        accounts = self.silver_acc\n",
    "        accounts = pd.merge(accounts, acc_operation, on = \"AccID\", how = \"left\")\n",
    "        accounts[\"Commodity\"] = accounts.apply(lambda x: self._identify_product(x), axis=1)\n",
    "        commodities = pd.DataFrame(data={\"Commodity\": accounts[\"Commodity\"].unique()})\n",
    "        commodities.to_csv(self.gold_path[\"inventory\"]/\"Tables\"/\"commodities_acc.csv\", index=False)\n",
    "        # prepare account table for mapping AccID from AccNum\n",
    "        self.operation_acc = accounts[accounts[\"AccNum\"].notna()]   # AccNum must be non-missing\n",
    "        self.operation_acc = self.operation_acc[self.operation_acc[\"Active\"]] # avoid non-active accounts what share same AccNum with active accounts\n",
    "        self.operation_acc.to_csv(self.gold_path[\"finance_operational\"]/\"AccNumTOAccID.csv\", index=False)\n",
    "        # Revising Signs according to Operational Classification\n",
    "        print(\"Revising Signs ...\")\n",
    "        # expense_accounts = accounts[(accounts[\"OperationCategory\"] == \"Expense\") | (accounts[\"OperationCategory\"] ==\"Inventory Consumption\")] # for my classification\n",
    "        expense_accounts = accounts[accounts[\"ProfitType\"].isin([\"Cost of Goods Sold\", \"Direct Operating Expenses\", \"Operating Overheads\", \"Other Expense\"])]\n",
    "        data[\"AmountDisplay\"] = data.apply(lambda x: -x[\"AmountCAD\"] if x[\"AccID\"] in expense_accounts.AccID.unique() else x[\"AmountCAD\"], axis=1)\n",
    "        data = self._perform_manual_adjust_GL_inventory(data)\n",
    "        self.gold_pl = data\n",
    "        self.gold_acc = accounts\n",
    "        # save files\n",
    "        print(\"Saving ...\")\n",
    "        self.check_file(self.gold_path[\"finance_operational\"])\n",
    "        data.to_csv(self.gold_path[\"finance_operational\"]/\"PL.csv\", index=False)\n",
    "        accounts.to_excel(self.gold_path[\"finance_operational\"]/\"Account_table.xlsx\", sheet_name = \"Account\", index=False)\n",
    "        data.to_excel(self.gold_path[\"finance_operational\"]/\"PL.xlsx\", sheet_name=\"Transactions\", index=False)\n",
    "        for pillar in [\"Grain\", \"Cattle\", \"Seed\", \"Produce\"]:\n",
    "            data[data[\"Pillar\"]==pillar].to_excel(self.gold_path[\"pillar_dashboard\"]/pillar/\"PL.xlsx\", sheet_name=\"Transactions\", index=False)\n",
    "        self.pl_exist = True\n",
    "    \n",
    "    def _process_pp(self, data:pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\" \n",
    "            This function takes original dataframe, apply the payperiod number classification based on transactions date, process payperiod columns, and return the new dataframe,\n",
    "                save the pp table for consolidated tables\n",
    "        \"\"\"\n",
    "        date_col = \"TransactionDate\" if \"TransactionDate\" in data.columns else \"date\"\n",
    "        # load payperiods\n",
    "        payperiods = pd.read_csv(self.gold_path[\"payroll\"]/\"Payperiods.csv\")\n",
    "        payperiods[\"START\"] = pd.to_datetime(payperiods[\"START\"])\n",
    "        payperiods[\"END\"] = pd.to_datetime(payperiods[\"END\"])\n",
    "        payperiods = payperiods.loc[:,[\"PP\",\"START\",\"END\",\"Cycle\",\"FiscalYear\"]]\n",
    "        payperiods = payperiods.rename(columns={\"PP\":\"PPNum\"})\n",
    "        payperiods[\"PPName\"] = payperiods[\"Cycle\"].astype(str).str.slice(2) + \"-\" + \"PP\" + payperiods[\"PPNum\"].astype(str).str.zfill(2)\n",
    "        # shift transaction dates - AZ: left 12 days, others: left 5 days\n",
    "        offset_days = {\"Arizona (produce)\": 12, \"Outlook\": 12}\n",
    "        data[\"days_offset\"] = data[\"Location\"].map(offset_days).fillna(5)\n",
    "        data[\"date_shifted\"] = data[date_col] - pd.to_timedelta(data[\"days_offset\"],unit=\"days\")\n",
    "        data = data[data[\"date_shifted\"]>=dt.datetime(2021,12,20)].copy(deep=True)\n",
    "        # construct interval index object for all periods\n",
    "        idx = pd.IntervalIndex.from_arrays(\n",
    "            left = payperiods[\"START\"],\n",
    "            right = payperiods[\"END\"],\n",
    "            closed = \"both\"\n",
    "        )\n",
    "        # determine which payperiod a transaction date belongs to by identifying the positional index inside the interval index object\n",
    "        pos = idx.get_indexer(data[\"date_shifted\"])\n",
    "        # extract payperiod info based on positional indices\n",
    "        ppnum = payperiods[\"PPNum\"].to_numpy()\n",
    "        ppname = payperiods[\"PPName\"].to_numpy()\n",
    "        cycle = payperiods[\"Cycle\"].to_numpy()\n",
    "        data[\"PPNum\"] = ppnum[pos]\n",
    "        data[\"PPName\"] = ppname[pos]\n",
    "        data[\"Cycle\"] = cycle[pos]\n",
    "        # create mapping for max fiscal year per payperiod to determine which fiscal year a payperiod should bleong to\n",
    "        mapping_table = data.groupby([\"days_offset\",\"PPName\"]).agg({\"FiscalYear\":\"max\"}).reset_index(drop=False)\n",
    "        data = data.drop(columns=[\"FiscalYear\"])\n",
    "        data = pd.merge(data, mapping_table, on=[\"days_offset\", \"PPName\"], how=\"left\")\n",
    "        # drop intermediate columns\n",
    "        data = data.drop(columns=[\"days_offset\", \"date_shifted\"])\n",
    "        # data.loc[:,[\"PPName\", \"PPNum\", \"Cycle\", \"FiscalYear\"]].drop_duplicates().to_csv(self.gold_path[\"payroll\"].parent/ \"OtherTables\" / \"PayPeriods.csv\", index=False)\n",
    "        return data\n",
    "\n",
    "    def _process_units(self) -> None:\n",
    "        \"\"\" \n",
    "            this function read and process Unit files that contains unit numbers for each location\n",
    "        \"\"\"\n",
    "        acres = pd.read_csv(self.gold_path[\"payroll\"]/\"Unit.csv\",dtype={\"Location\":str, \"Unit\":float})\n",
    "        acres[\"Location\"] = acres[\"Location\"].str.strip()\n",
    "        doc_rename = {\"Airdrie Grain\": \"Airdrie (grain)\", \"Aridrie Cattle (head days 365)\":\"Airdrie\", \"Arizona All\":\"Arizona (produce)\",\n",
    "                    \"BC Cattle (head days 365)\":\"BritishColumbia (cattle)\", \"BC Produce\":\"BritishColumbia (produce)\", \n",
    "                    \"Box Elder\":\"Havre\", \"Eddystone Cattle (head days 365)\":\"Eddystone (cattle)\", \"Eddystone Grain\":\"Eddystone (grain)\",\n",
    "                    \"Monette Seeds CDN (avg met. ton)\":\"Seeds\", \"Monette Seeds USA\":\"Seeds USA\", \"NexGen (avg met. ton)\":\"NexGen\",\n",
    "                    \"Waldeck (head days 365)\":\"Waldeck\", \"Calderbank  (head days 365)\":\"Calderbank\"}\n",
    "        acres[\"Location\"] = acres[\"Location\"].replace(doc_rename)\n",
    "        acres[\"Pillar\"] = acres.apply(lambda x: self._pillar_classification(x),axis=1)\n",
    "        acres.to_csv(self.gold_path[\"payroll\"].parent/ \"OtherTables\" /\"Unit_PowerBI.csv\",index=False)\n",
    "\n",
    "    def _payroll_project(self) -> None: \n",
    "        \"\"\" \n",
    "            will run _finance_operational() first\n",
    "            output: details + cost per unit (units per location input sheet) + average cost per unit for FY\n",
    "        \"\"\"\n",
    "        self.check_file(self.gold_path[\"payroll\"].parent/ \"OtherTables\")\n",
    "        print(\"\\nStarting Payroll Project Transformation\\n\")\n",
    "\n",
    "        # load and filter accounts for wages and contract labor\n",
    "        account = self.silver_acc[(self.silver_acc[\"Category\"].isin([\"Wages and benefits - direct\",\"Wages and benefits - overhead\"]) | (self.silver_acc[\"AccNum\"].isin([\"MFAZ595001\",\"MFBC536030\"])))] \n",
    "        # load only with transaction date later than 2021-12-20, and without \"Accrual\" in the memo\n",
    "        if self.is_dev:\n",
    "            data = pd.read_csv(self.gold_path[\"finance_operational\"]/\"PL.csv\")\n",
    "        else:\n",
    "            if not self.pl_exist: self._finance_operational()\n",
    "            data = self.gold_pl.copy(deep=True)\n",
    "        data = data[data[\"AccID\"].isin(account.AccID.unique())]\n",
    "        data[\"TransactionDate\"] = pd.to_datetime(data[\"TransactionDate\"])\n",
    "        data = data[data[\"TransactionDate\"]>=dt.datetime(2021,12,20)].reset_index(drop=True)\n",
    "        data = data[~data[\"Memo\"].str.contains(\"Accrual\",case=False,na=False)]\n",
    "        # allocating payperiods\n",
    "        data = self._process_pp(data=data)\n",
    "        # standardizing location\n",
    "        # data.loc[data[\"Location\"]==\"Airdrie (corporate)\", \"Pillar\"] = \"Cattle\"                # deprecated\n",
    "        # data.loc[data[\"Location\"]==\"Airdrie (corporate)\", \"Location\"] = \"Airdrie (cattle)\"    # deprecated\n",
    "        data.loc[data[\"Location\"]==\"Eddystone (corporate)\", \"Pillar\"] = \"Unclassified\"\n",
    "        data.loc[data[\"Location\"]==\"Eddystone (corporate)\", \"Location\"] = \"Unassigned\"\n",
    "        data.loc[data[\"Location\"]==\"Legacy\", \"Location\"] = \"Unassigned\"\n",
    "        data.loc[(data[\"Location\"].str.contains(\"corporate\",case=False,na=False)&(data[\"Location\"]!=\"BritishColumbia (corporate)\")),\"Location\"] = \"Corporate\"\n",
    "        ## move BC ranches into BC Cattle\n",
    "        data.loc[(data[\"Location\"].isin(self.bc_ranches+[\"BritishColumbia (corporate)\"])), \"Location\"] = \"BritishColumbia (cattle)\"\n",
    "        data.loc[data[\"Location\"] == \"BritishColumbia (cattle)\", \"Pillar\"] = \"Cattle\"\n",
    "        # summarizing data\n",
    "        ## by Location per PP\n",
    "        data_summarized = pd.DataFrame(data.groupby([\"Location\",\"PPName\",\"Pillar\",\"FiscalYear\",\"Cycle\",\"PPNum\"]).agg({\"AmountDisplay\":\"sum\"}).reset_index(drop=False))\n",
    "        assert len(data_summarized) == len(data.groupby([\"Location\",\"PPName\"]).agg({\"AmountDisplay\":\"sum\"}).reset_index(drop=False)), \"Duplicated value detected for per Location per PP calculation\"\n",
    "        ## join acres data for CostPerUnit compute\n",
    "        print(\"Summarizing ...\")\n",
    "        acres = pd.read_csv(self.gold_path[\"payroll\"].parent/ \"OtherTables\" /\"Unit_PowerBI.csv\",dtype={\"Location\":str, \"Unit\":float})\n",
    "        acres = acres.loc[:,[\"Location\", \"Unit\"]]\n",
    "        ### create BC cattle total units\n",
    "        total_bc = 0\n",
    "        for l in self.bc_ranches+[\"BritishColumbia (corporate)\"]:\n",
    "            total_bc += acres.loc[acres[\"Location\"]==l, \"Unit\"].item()\n",
    "        acres.loc[acres[\"Location\"]==\"BritishColumbia (cattle)\", \"Unit\"] = total_bc\n",
    "        acres[\"Unit\"] = acres[\"Unit\"].replace({0: 1})\n",
    "        print(f\"Unaccounted location for Acres Doc: {set(acres.Location.unique()) - set(data_summarized.Location.unique())}\")\n",
    "        print(f\"Unaccounted location for QBO Payroll: {set(data_summarized.Location.unique()) - set(acres.Location.unique())}\")\n",
    "        data_summarized = pd.merge(data_summarized, acres, on=\"Location\", how=\"left\")\n",
    "        data_summarized[\"CostPerUnit\"] = data_summarized[\"AmountDisplay\"] / data_summarized[\"Unit\"] * 26\n",
    "        data_summarized[\"Count\"] = 1\n",
    "        ## by Location\n",
    "        data_summarized2 = data_summarized.groupby(by=[\"Location\",\"FiscalYear\",\"Pillar\"]).agg({\"CostPerUnit\":\"mean\", \"Count\":\"sum\"}).reset_index(drop=False)\n",
    "        data_summarized2 = data_summarized2.rename(columns={\"CostPerUnit\":\"Avg CostPerUnit\"})\n",
    "        assert len(data_summarized2) == len(data_summarized.groupby(by=[\"Location\",\"FiscalYear\"]).agg({\"CostPerUnit\":\"mean\"})), \"Duplicated value detected for per Location calculation\"\n",
    "        ## by pillar\n",
    "        data_summarized3 = data_summarized2.groupby(by=[\"FiscalYear\",\"Pillar\"]).agg({\"Avg CostPerUnit\":\"mean\", \"Count\":\"sum\"}).reset_index(drop=False)\n",
    "        assert len(data_summarized3) == len(data_summarized.groupby(by=[\"Pillar\",\"FiscalYear\"]).agg({\"CostPerUnit\":\"mean\"})), \"Duplicated value detected for per Pillar calculation\"\n",
    "        # saving\n",
    "        print(\"Saving ...\")\n",
    "        self.check_file(self.gold_path[\"payroll\"])\n",
    "        data.to_excel(self.gold_path[\"payroll\"]/\"Payroll.xlsx\", sheet_name=\"Payroll\", index=False)\n",
    "        self.check_file(self.gold_path[\"hr_combined\"] / \"CSV\")\n",
    "        data_summarized.to_csv(self.gold_path[\"hr_combined\"]/ \"CSV\" / \"payroll_summarized1.csv\", index=False)\n",
    "        data_summarized2.to_csv(self.gold_path[\"hr_combined\"]/ \"CSV\" / \"payroll_summarized2.csv\", index=False)\n",
    "        data_summarized3.to_csv(self.gold_path[\"hr_combined\"]/ \"CSV\" / \"payroll_summarized3.csv\", index=False)\n",
    "\n",
    "    def _QBOTime_project(self) -> None:\n",
    "        \"\"\" \n",
    "            apply PP allocation to QBO Time data, clean locaiton, and join relevant info into one table\n",
    "        \"\"\"\n",
    "        print(\"\\nStarting QBO Time Project Transformation\\n\")\n",
    "        # read files\n",
    "        timesheets = pd.read_csv(self.silver_path[\"QBO\"][\"Time\"]/\"timesheets.csv\")\n",
    "        jobcode = pd.read_csv(self.silver_path[\"QBO\"][\"Time\"]/\"jobcodes.csv\")\n",
    "        users = pd.read_csv(self.silver_path[\"QBO\"][\"Time\"]/\"users.csv\")\n",
    "        group = pd.read_csv(self.silver_path[\"QBO\"][\"Time\"]/\"group.csv\")\n",
    "        print(f\"Read {len(timesheets)} timesheet records, {len(jobcode)} jobcodes, {len(users)} users, {len(group)} groups\")\n",
    "        timesheets_len, users_len = len(timesheets), len(users)\n",
    "        # clean up location in group table\n",
    "        ## Arizona - all produce\n",
    "        group.loc[((group[\"corp_short\"]==\"A\")&(group[\"location_name\"]==\"Monette Farms AZ\")), \"Location\"] = \"Arizona (produce)\"\n",
    "        group.loc[((group[\"corp_short\"]==\"A\")&(group[\"location_name\"]==\"Monette Produce USA\")), \"Location\"] = \"Arizona (produce)\"\n",
    "        group.loc[((group[\"corp_short\"]==\"A\")&(group[\"location_name\"]==\"Monette Seeds USA\")), \"Location\"] = \"Arizona (produce)\"\n",
    "        ## BC\n",
    "        group.loc[((group[\"corp_short\"]==\"BC\")&(group[\"location_name\"]==\"Ashcroft Ranch\")), \"Location\"] = \"Ashcroft\"\n",
    "        group.loc[((group[\"corp_short\"]==\"BC\")&(group[\"location_name\"]==\"Cache/Fischer/Loon\")), \"Location\"] = \"BritishColumbia (cattle)\"\n",
    "        group.loc[((group[\"corp_short\"]==\"BC\")&(group[\"location_name\"].str.contains(\"silage\", case=False))), \"Location\"] = \"BritishColumbia (cattle)\"\n",
    "        group.loc[((group[\"corp_short\"]==\"BC\")&(group[\"location_name\"]==\"Diamond S Ranch\")), \"Location\"] = \"Diamond S\"\n",
    "        group.loc[((group[\"corp_short\"]==\"BC\")&(group[\"location_name\"]==\"Fraser River Ranch\")), \"Location\"] = \"Fraser River Ranch\"\n",
    "        group.loc[((group[\"corp_short\"]==\"BC\")&(group[\"location_name\"]==\"Home Ranch (70 Mile, LF/W, BR)\")), \"Location\"] = \"Home Ranch\"\n",
    "        group.loc[((group[\"corp_short\"]==\"BC\")&(group[\"location_name\"]==\"Moon Ranch\")), \"Location\"] = \"Moon Ranch\"\n",
    "        group.loc[((group[\"corp_short\"]==\"BC\")&(group[\"location_name\"]==\"Produce\")), \"Location\"] = \"BritishColumbia (produce)\"\n",
    "        group.loc[((group[\"corp_short\"]==\"BC\")&(group[\"location_name\"]==\"Wolf Ranch\")), \"Location\"] = \"Wolf Ranch\"\n",
    "        group.loc[((group[\"corp_short\"]==\"BC\")&(group[\"location_name\"]==\"SAWP\")), \"Location\"] = \"BritishColumbia (produce)\"\n",
    "        group.loc[((group[\"corp_short\"]==\"BC\")&(group[\"location_name\"]==\"SAWP Produce\")), \"Location\"] = \"BritishColumbia (produce)\"\n",
    "        ## Outlook\n",
    "        group.loc[((group[\"corp_short\"]==\"O\")), \"Location\"] = \"Outlook\"\n",
    "        ## others\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"Airdrie\")), \"Location\"] = \"Airdrie\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"BC\")), \"Location\"] = \"Unassigned\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"Calderbank\")), \"Location\"] = \"Calderbank\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"Eddystone\")), \"Location\"] = \"Eddystone (unspecified)\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"Hafford\")), \"Location\"] = \"Hafford\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"Kamsack\")), \"Location\"] = \"Kamsack\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"MFUSA Billings\")), \"Location\"] = \"Billings\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"MFUSA Box Elder\")), \"Location\"] = \"Havre\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"Nexgen Seeds\")), \"Location\"] = \"NexGen\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"Prince Albert\")), \"Location\"] = \"Prince Albert\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"Raymore\")), \"Location\"] = \"Raymore\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"Regina\")), \"Location\"] = \"Regina\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"Russel Approvals\")), \"Location\"] = \"Unassigned\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"Seeds\")), \"Location\"] = \"Seeds\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"Swift Current\")), \"Location\"] = \"Swift Current\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"The Pas\")), \"Location\"] = \"The Pas\"\n",
    "        group.loc[((group[\"corp_short\"]==\"CM\")&(group[\"location_name\"]==\"Waldeck\")), \"Location\"] = \"Waldeck\"\n",
    "        unclassified = group[group[\"Location\"].isna()].location_name.unique()\n",
    "        if len(unclassified) > 0: print(f\"\\nUnclassified location - {unclassified}\\n\")\n",
    "        # create another location column for general location where bc ranches are merged into one\n",
    "        group = group.rename(columns={\"Location\": \"Location (detail)\"})\n",
    "        group[\"Location\"] = group[\"Location (detail)\"]\n",
    "        group.loc[(group[\"Location (detail)\"].isin(self.bc_ranches+[\"BritishColumbia (corporate)\"])), \"Location\"] = \"BritishColumbia (cattle)\"\n",
    "        # merge tables into one table\n",
    "        ## merge location into users\n",
    "        users = pd.merge(users, group.loc[:,[\"group_id\", \"location_name\", \"Location\", \"Location (detail)\"]].drop_duplicates(), on=\"group_id\", how=\"left\")\n",
    "        ## merge users into timesheets\n",
    "        timesheets = pd.merge(timesheets,users.loc[:,[\"user_id\", \"group_id\", \"username\", \"full_name\", \"location_name\",\"Location\",\"Location (detail)\", \"first_name\", \"last_name\"]], on=\"user_id\", how=\"left\")\n",
    "        ## merge job into timesheets\n",
    "        timesheets = pd.merge(timesheets, jobcode.loc[:,[\"jobcode_id\",\"job_name\",\"type\"]].rename(columns={\"type\":\"job_type\"}), on=\"jobcode_id\", how=\"left\")\n",
    "        assert (len(users) == users_len) and (len(timesheets) == timesheets_len), f\"duplicated records found, timesheets - {timesheets_len} vs {len(timesheets)}; users - {users_len} vs {len(users)}\"\n",
    "        ## determine fiscal year\n",
    "        timesheets[\"date\"] = pd.to_datetime(timesheets[\"date\"])\n",
    "        timesheets[\"Month\"] = timesheets[\"date\"].dt.month_name()\n",
    "        timesheets[\"FiscalYear\"] = timesheets[\"date\"].dt.year \n",
    "        mask = timesheets[\"Month\"].isin([\"November\", \"December\"])\n",
    "        timesheets.loc[mask, \"FiscalYear\"] = timesheets.loc[mask, \"FiscalYear\"] + 1\n",
    "        # classify payperiods\n",
    "        timesheets = self._process_pp(data=timesheets)\n",
    "        # modify location for BC0\n",
    "        timesheets.loc[timesheets[\"user_id\"] == \"BC6107856\", \"Location\"] = \"Unassigned\"\n",
    "        # classify pillars\n",
    "        timesheets[\"Pillar\"] = timesheets.apply(lambda x: self._pillar_classification(x), axis=1)\n",
    "        timesheets.loc[timesheets[\"Pillar\"] == \"Missing\", \"Pillar\"] = \"Unclassified\"\n",
    "        # summarizing data\n",
    "        ## by Location per PP \n",
    "        summarized = timesheets.groupby([\"Location\",\"PPName\",\"FiscalYear\",\"Cycle\",\"PPNum\", \"Pillar\"]).agg({\"duration\":\"sum\"}).reset_index(drop=False)\n",
    "        assert len(summarized) == len(timesheets.groupby([\"Location\",\"PPName\"]).agg({\"duration\":\"sum\"})), \"duplicated value detected for timsheet per Location per PP summarization\"\n",
    "        ## read units file\n",
    "        acres = pd.read_csv(self.gold_path[\"payroll\"].parent/ \"OtherTables\" /\"Unit_PowerBI.csv\",dtype={\"Location\":str, \"Unit\":float})\n",
    "        acres = acres.loc[:,[\"Location\", \"Unit\"]]\n",
    "        print(f\"Unaccounted location for Acres Doc: {set(acres.Location.unique()) - set(summarized.Location.unique())}\")\n",
    "        print(f\"Unaccounted location for timesheets: {set(summarized.Location.unique()) - set(acres.Location.unique())}\")\n",
    "        ### create BC cattle + Billings total units\n",
    "        total_bc = 0\n",
    "        for l in self.bc_ranches+[\"BritishColumbia (corporate)\"]:\n",
    "            total_bc += acres.loc[acres[\"Location\"]==l, \"Unit\"].item()\n",
    "        acres.loc[acres[\"Location\"]==\"BritishColumbia (cattle)\", \"Unit\"] = total_bc\n",
    "        # acres.loc[acres[\"Location\"]==\"Billings\", \"Unit\"] = acres[acres[\"Location\"].isin([\"Fly Creek\", \"Camp 4\"])].Unit.sum()\n",
    "        acres[\"Unit\"] = acres[\"Unit\"].replace({0: 1})\n",
    "        ## merge with units file\n",
    "        summarized = pd.merge(summarized, acres, on=\"Location\", how=\"left\")\n",
    "        ## calculate hours per unit\n",
    "        summarized[\"HoursPerUnit\"] = summarized[\"duration\"] / summarized[\"Unit\"] * 26\n",
    "        summarized[\"Count\"] = 1\n",
    "        # summarize per location\n",
    "        summarized2 = summarized.groupby(by=[\"Location\",\"FiscalYear\", \"Pillar\"]).agg({\"HoursPerUnit\":\"mean\", \"Count\":\"sum\"}).reset_index(drop=False)\n",
    "        summarized2 = summarized2.rename(columns={\"HoursPerUnit\":\"Avg HoursPerUnit\"})\n",
    "        assert len(summarized2) == len(timesheets.groupby([\"Location\",\"FiscalYear\"]).agg({\"duration\":\"sum\"})), \"duplicated value detected for timsheet per Location summarization\"\n",
    "        # summarize per pillar\n",
    "        summarized3 = summarized2.groupby(by=[\"FiscalYear\", \"Pillar\"]).agg({\"Avg HoursPerUnit\":\"mean\", \"Count\":\"sum\"}).reset_index(drop=False)\n",
    "        assert len(summarized3) == len(timesheets[timesheets[\"Pillar\"]!=\"Missing\"].groupby([\"Pillar\",\"FiscalYear\"]).agg({\"duration\":\"sum\"})), \"duplicated value detected for timsheet per Pillar summarization\"\n",
    "\n",
    "        # saving\n",
    "        print(\"Saving ...\\n\")\n",
    "        self.check_file(self.gold_path[\"QBOTime\"])\n",
    "        timesheets.to_excel(self.gold_path[\"QBOTime\"]/\"QBOTime.xlsx\", sheet_name = \"QBOTime\", index=False)\n",
    "        self.check_file(self.gold_path[\"hr_combined\"]/ \"CSV\")\n",
    "        summarized.to_csv(self.gold_path[\"hr_combined\"]/ \"CSV\" / \"time_summarized1.csv\", index=False)\n",
    "        summarized2.to_csv(self.gold_path[\"hr_combined\"]/ \"CSV\" / \"time_summarized2.csv\", index=False)\n",
    "        summarized3.to_csv(self.gold_path[\"hr_combined\"]/ \"CSV\" / \"time_summarized3.csv\", index=False)\n",
    "\n",
    "    def _hr_summary(self) -> None:\n",
    "        \"\"\" \n",
    "            This function consolidate payroll and QBO time summaries into one table for consolidated insights\n",
    "        \"\"\"\n",
    "        final_df = [pd.DataFrame(), pd.DataFrame(), pd.DataFrame()]\n",
    "        for i in [1, 2, 3]:\n",
    "            payroll = pd.read_csv(self.gold_path[\"hr_combined\"] / \"CSV\" / f\"payroll_summarized{i}.csv\")\n",
    "            payroll_rename = {\"AmountDisplay\": \"TotalAmount\", \"CostPerUnit\": \"AmountPerUnit\", \"Avg CostPerUnit\": \"Avg AmountPerUnit\"}\n",
    "            payroll = payroll.rename(columns=payroll_rename)\n",
    "            payroll[\"Mode\"] = \"Payroll\"\n",
    "            time = pd.read_csv(self.gold_path[\"hr_combined\"] / \"CSV\" / f\"time_summarized{i}.csv\")\n",
    "            time_rename = {\"duration\": \"TotalAmount\", \"HoursPerUnit\": \"AmountPerUnit\", \"Avg HoursPerUnit\": \"Avg AmountPerUnit\"}\n",
    "            time = time.rename(columns=time_rename)\n",
    "            time[\"Mode\"] = \"Hours\"\n",
    "            final_df[i-1] = pd.concat([payroll, time], ignore_index=True)\n",
    "        final_df[0].to_excel(self.gold_path[\"hr_combined\"]/\"Summarized.xlsx\", sheet_name=\"Summarized\", index=False)\n",
    "        final_df[1].to_excel(self.gold_path[\"hr_combined\"]/\"Summarized2.xlsx\", sheet_name=\"Summarized2\", index=False)\n",
    "        final_df[2].to_excel(self.gold_path[\"hr_combined\"]/\"Summarized3.xlsx\", sheet_name=\"Summarized3\", index=False)\n",
    "\n",
    "    def _temp_get_product(self, entry:str) -> str:\n",
    "        \"\"\" \n",
    "            temporary function for aligning product classification with Traction for QBO accounts, will change for HP\n",
    "        \"\"\"\n",
    "        entry = entry.lower()\n",
    "        if \"durum\" in entry:\n",
    "            return \"Durum\"\n",
    "        elif \"wheat\" in entry:\n",
    "            return \"Wheat\"\n",
    "        elif \"canola\" in entry:\n",
    "            return \"Canola\"\n",
    "        elif (\"chickpea\" in entry) or (\"garbanzo bean\" in entry):\n",
    "            return \"Chickpeas\"\n",
    "        elif (\"peas\" in entry) or (\"field pea\" in entry):\n",
    "            return \"Peas\"\n",
    "        elif \"barley\" in entry:\n",
    "            return \"Barley\"\n",
    "        elif \"green lentil\" in entry:\n",
    "            return \"Green Lentils\"\n",
    "        elif \"red lentil\" in entry:\n",
    "            return \"Red Lentils\"\n",
    "        elif \"oats\" in entry:\n",
    "            return \"Oats\"\n",
    "        elif \"corn\" in entry:\n",
    "            return \"Corn\"\n",
    "        else:\n",
    "            return \"Others\" \n",
    "\n",
    "    def _raw_inventory(self) -> None:\n",
    "        \"\"\" \n",
    "            prepare the data from raw QBO table for inventory project: only extracting partial Invoice, SalesReceipt, and Journal Entry\n",
    "        \"\"\"\n",
    "        print(\"\\nStarting Inventory Project Transformation ...\\n\")\n",
    "        corps = [\"MFL\", \"MFUSA\"]\n",
    "        cols = [\"TransactionDate\", \"TransactionType\", \"TransactionID\", \"Corp\", \"Qty\", \"AccID\", \"FarmID\", \"CustomerID\",\n",
    "                \"DocNumber\", \"TransactionEntered\", \"Amount\"]\n",
    "        journal_cols = [col for col in cols if col != \"Qty\"]\n",
    "        # read tables\n",
    "        print(\"Loading raw tables ...\")\n",
    "        account = self.silver_acc.copy(deep=True)\n",
    "        account = account[account[\"Corp\"].isin(corps)]\n",
    "        account = account[account[\"AccountType\"] == \"Income\"]\n",
    "        farm = pd.read_csv(self.silver_path[\"QBO\"][\"Dimension_time\"]/\"Farm.csv\")\n",
    "        farm = farm[farm[\"Corp\"].isin(corps)]\n",
    "        customer = pd.read_csv(self.silver_path[\"QBO\"][\"Dimension_time\"]/\"Customer.csv\")\n",
    "        customer = customer[customer[\"Corp\"].isin(corps)]\n",
    "        first_date = dt.datetime(2023,11,1)\n",
    "        invoice = pd.read_csv(self.silver_path[\"QBO\"][\"Raw\"]/\"Invoice.csv\")\n",
    "        invoice = invoice[invoice[\"Corp\"].isin(corps)]\n",
    "        invoice[\"TransactionDate\"] = pd.to_datetime(invoice[\"TransactionDate\"])\n",
    "        invoice = invoice[invoice[\"TransactionDate\"]>=first_date]\n",
    "        invoice = invoice[invoice[\"AccID\"].isin(account.AccID.unique())]\n",
    "        sales = pd.read_csv(self.silver_path[\"QBO\"][\"Raw\"]/\"SalesReceipt.csv\")\n",
    "        sales = sales[sales[\"Corp\"].isin(corps)]\n",
    "        sales[\"TransactionDate\"] = pd.to_datetime(sales[\"TransactionDate\"])\n",
    "        sales = sales[sales[\"TransactionDate\"]>=first_date]\n",
    "        sales = sales[sales[\"AccID\"].isin(account.AccID.unique())]\n",
    "        journal = pd.read_csv(self.silver_path[\"QBO\"][\"Raw\"]/\"JournalEntry.csv\", dtype={\"FarmID\":str, \"ClassID\":str, \"CustomerID\":str, \"EmployeeID\":str}, usecols=journal_cols)\n",
    "        journal = journal[journal[\"AccID\"].isin(account.AccID.unique())]\n",
    "        journal[\"TransactionDate\"] = pd.to_datetime(journal[\"TransactionDate\"])\n",
    "        journal = journal[journal[\"TransactionDate\"]>=first_date]\n",
    "        journal = journal[~journal[\"TransactionEntered\"].str.contains(\"Delivered and not settled\", na=False)]\n",
    "        journal = journal[~journal[\"TransactionEntered\"].str.contains(\"Grain Inventory Receivable Adjustment\", na=False)]\n",
    "        # combining tables\n",
    "        print(\"Combining Fact Tables ...\")\n",
    "        invoice = invoice.loc[:,[col for col in cols if col in invoice.columns]]\n",
    "        sales = sales.loc[:,[col for col in cols if col in sales.columns]]\n",
    "        journal = journal.loc[:,[col for col in cols if col in journal.columns]]\n",
    "        facts = pd.concat([invoice, sales, journal], ignore_index=True)\n",
    "        del invoice, sales, journal\n",
    "        # join facts with dimension tables\n",
    "        facts = pd.merge(facts, account.loc[:,[\"AccID\",\"AccNum\",\"AccName\",\"Category\",\"Subcategory\"]], on=[\"AccID\"], how=\"left\")\n",
    "        facts = pd.merge(facts, farm.loc[:,[\"FarmID\",\"FarmName\"]], on=[\"FarmID\"], how=\"left\")\n",
    "        facts = pd.merge(facts, customer.loc[:,[\"CustomerID\",\"CustomerName\"]], on=[\"CustomerID\"], how=\"left\")\n",
    "        facts = facts[facts[\"Subcategory\"]==\"Grain - cash settlements\"]\n",
    "        print(f\"Total Fact Entries - {len(facts)}\")\n",
    "        # product column\n",
    "        facts[\"Product\"] = facts[\"AccName\"].apply(lambda x: self._temp_get_product(x))\n",
    "        # saving file\n",
    "        print(\"Saving Files ...\")\n",
    "        self.check_file(self.gold_path[\"inventory\"])\n",
    "        facts.to_excel(self.gold_path[\"inventory\"]/\"Excel\"/\"QBO_Grain_Settlements.xlsx\", sheet_name=\"settlement\", index=False)\n",
    "        print(\"Finished\\n\")\n",
    "\n",
    "    def _buget_process_input(self, inputdata_path:Path, processed_path:Path) -> None:\n",
    "        \"\"\" \n",
    "            this function processes and saves budget totals for production, input (chem/fert/seed), produce budgets, and JD Lease\n",
    "        \"\"\"\n",
    "        ## commodity prices - everything is CAD except Winter Wheat is converted to USD\n",
    "        pricing = pd.read_csv(inputdata_path/\"25-Grain-Pricing.csv\")\n",
    "        pricing.loc[pricing[\"Commodity\"]==\"WW\", \"ForecastPrice\"] *= self.fx\n",
    "        ## production budget\n",
    "        budget_production = pd.read_csv(inputdata_path/\"25-Grain-Revenue.csv\")\n",
    "        budget_production = budget_production.melt(\n",
    "            id_vars=[\"Location\", \"Currency\", \"Type\"],\n",
    "            var_name=\"Commodity\",\n",
    "            value_name = \"Amount\"\n",
    "        )\n",
    "        budget_production = budget_production.fillna(value = {\"Amount\": 0})\n",
    "        budget_production[\"Commodity\"] = budget_production[\"Commodity\"].replace({\"Hay/Silage\":\"Hay\"})\n",
    "        budget_production.loc[((budget_production[\"Location\"]==\"Airdrie\")&(budget_production[\"Commodity\"]==\"Hay\")), \"Commodity\"] = \"Silage\" # only Airdrie has silage, others have hay\n",
    "        budget_production_summary = pd.DataFrame(budget_production.groupby([\"Location\",\"Currency\",\"Commodity\"]).agg({\"Amount\": \"prod\"})).reset_index(drop=False)\n",
    "        budget_production_summary = budget_production_summary.rename(columns={\"Amount\":\"TotalYield\"})\n",
    "        ### merge yield with commodity price to calculate forecast production value of commodities\n",
    "        budget_production_summary = pd.merge(budget_production_summary,pricing,on=[\"Commodity\"], how=\"left\")\n",
    "        ### manual adjustments to prices\n",
    "        budget_production_summary.loc[((budget_production_summary[\"Location\"] == \"Airdrie\") & (budget_production_summary[\"Commodity\"] == \"Hay\")), \"ForecastPrice\"] = 85\n",
    "        budget_production_summary.loc[((budget_production_summary[\"Location\"] == \"Colorado (Genoa)\") & (budget_production_summary[\"Commodity\"] == \"WW\")), \"ForecastPrice\"] = 13.75\n",
    "        budget_production_summary.loc[budget_production_summary[\"Location\"] == \"Yorkton\", \"ForecastPrice\"] *= 2/3\n",
    "        budget_production_summary[\"ForecastProductionCAD\"] = budget_production_summary[\"TotalYield\"] * budget_production_summary[\"ForecastPrice\"]\n",
    "        budget_production_summary = budget_production_summary[budget_production_summary[\"ForecastProductionCAD\"].notna()]\n",
    "        budget_production_summary = budget_production_summary[budget_production_summary[\"ForecastProductionCAD\"]!=0]\n",
    "        ### convert prices back to USD for a adjusted column\n",
    "        budget_production_summary[\"ForecastProductionAdj\"] = budget_production_summary.apply(lambda x: x[\"ForecastProductionCAD\"] / self.fx if x[\"Currency\"] == \"USD\" else x[\"ForecastProductionCAD\"],axis=1)\n",
    "        ### save production budget\n",
    "        budget_production_summary.to_csv(processed_path/\"budget_production.csv\",index=False)\n",
    "        ## input budget\n",
    "        input_budget = pd.read_csv(inputdata_path/\"25-Input-Budget.csv\")\n",
    "        input_budget = input_budget.drop(columns=[\"Total acres\"])\n",
    "        input_budget = input_budget.melt(\n",
    "            id_vars = [\"Location\", \"Type\"],\n",
    "            var_name = \"Commodity\",\n",
    "            value_name = \"Amount\"\n",
    "        )\n",
    "        input_budget = input_budget.fillna(value = {\"Amount\": 0})\n",
    "        input_budget.loc[((input_budget[\"Location\"]==\"Yorkton\")&(input_budget[\"Type\"].isin([\"Fertilizer\",\"Chemical\",\"Seed\"]))), \"Amount\"] *= 2/3\n",
    "        input_budget.to_csv(processed_path/\"input_budget.csv\",index=False)\n",
    "        ## labour budget\n",
    "        labour_budget = pd.read_csv(inputdata_path/\"25-Labour-Budget.csv\")\n",
    "        labour_budget = labour_budget.melt(\n",
    "            id_vars = [\"Location\",\"Currency\"],\n",
    "            var_name = \"Month\",\n",
    "            value_name = \"LabourBudgetCAD\"\n",
    "        )\n",
    "        labour_budget[\"LabourBudgetAdj\"] = labour_budget.apply(lambda x: x[\"LabourBudgetCAD\"]/self.fx if x[\"Currency\"]==\"USD\" else x[\"LabourBudgetCAD\"], axis=1)\n",
    "        labour_budget.to_csv(processed_path/\"labour_budget.csv\",index=False)\n",
    "        ## outlook budget\n",
    "        outlook = pd.read_csv(inputdata_path/\"25-Outlook-Detail.csv\")\n",
    "        outlook = outlook.melt(\n",
    "            id_vars=[\"Type\", \"ProfitType\"],\n",
    "            var_name=\"Commodity\",\n",
    "            value_name=\"Amount\"\n",
    "        )\n",
    "        outlook = outlook.fillna(value={\"Amount\": 0})\n",
    "        outlook.to_csv(processed_path/\"outlook_budget.csv\", index=False)\n",
    "        ## AZ budget\n",
    "        az = pd.read_csv(inputdata_path / \"25-AZ-Detail.csv\")\n",
    "        az = az.melt(\n",
    "            id_vars=[\"Type\", \"ProfitType\"],\n",
    "            var_name=\"CommodityRaw\",\n",
    "            value_name=\"AmountCAD\"\n",
    "        )\n",
    "        az = az.fillna(value={\"AmountCAD\": 0})\n",
    "        az.to_csv(processed_path/\"az_budget.csv\", index=False)\n",
    "        ## BC produce details\n",
    "        bc = pd.read_csv(inputdata_path / \"25-BC-Detail.csv\")\n",
    "        bc = bc.melt(\n",
    "            id_vars=[\"Type\", \"ProfitType\"],\n",
    "            var_name=\"CommodityRaw\",\n",
    "            value_name=\"AmountCAD\"\n",
    "        )\n",
    "        bc = bc.fillna(value={\"AmountCAD\": 0})\n",
    "        bc.to_csv(processed_path/\"bc_budget.csv\", index=False)\n",
    "        ## JD lease\n",
    "        jdlease = pd.read_csv(inputdata_path/\"25-JD-Lease-Summary.csv\")\n",
    "        jdlease = jdlease[jdlease[\"AllocatedCost25\"] != 0]\n",
    "        jdlease.to_csv(processed_path/\"JD_lease.csv\", index=False)\n",
    "\n",
    "    def _budget_read_outsidedata(self,processed_path:Path) -> tuple[pd.DataFrame,pd.DataFrame,pd.DataFrame,pd.DataFrame,pd.DataFrame,pd.DataFrame,pd.DataFrame]:\n",
    "        \"\"\" \n",
    "            this function reads all the processed outside data and standardize the commodity and location naming\n",
    "        \"\"\"\n",
    "        production_budget = pd.read_csv(processed_path/\"budget_production.csv\")\n",
    "        input_budget = pd.read_csv(processed_path/\"input_budget.csv\")\n",
    "        labour_budget = pd.read_csv(processed_path/\"labour_budget.csv\")\n",
    "        outlook_budget = pd.read_csv(processed_path/\"outlook_budget.csv\")\n",
    "        jdlease = pd.read_csv(processed_path/\"JD_lease.csv\")\n",
    "        az_budget = pd.read_csv(processed_path/\"az_budget.csv\")\n",
    "        bc_budget = pd.read_csv(processed_path/\"bc_budget.csv\")\n",
    "        ## standardizing commodity naming\n",
    "        production_rename_commodity = {\"R Lentils\":\"Red Lentil\", \"G Lentils\":\"Green Lentil\",\"Chickpeas\":\"Chickpea\",\"Peas\":\"Field Pea\", \"WW\": \"Winter Wheat\"}\n",
    "        input_rename_commodity = {\"R Lentils\":\"Red Lentil\", \"G Lentils\":\"Green Lentil\",\"Chickpeas\":\"Chickpea\", \"WW\": \"Winter Wheat\"}\n",
    "        outlook_rename_commodity = {\"Broccoli-cases/ac\":\"Broccoli\", \"Cabbage-lbs/ac\":\"Cabbage\", \"Carrots-lbs\":\"Carrot\", \"Cauliflower-cases/ac\":\"Cauliflower\",\n",
    "                                    \"Table Potato-lbs\":\"Potato\", \"Seed Potato-lbs\":\"Potato\", \"Commercial Pumpkins-Bins/ac\":\"Pumpkin\", \"Strawberry Upick-lbs\":\"Strawberry\",\n",
    "                                    \"Pumpkin Upick-pieces/ac\":\"Pumpkin\", \"Corn Maze-lbs\":\"Prairie Pathways\", \"WW\": \"Winter Wheat\", \"Corn (Sweet) Cobs\":\"Sweet Corn\"}\n",
    "        az_rename_commodity = {\"Broccoli-cases/ac\":\"Broccoli\", \"Cabbage-lbs/ac\":\"Cabbage\", \"Pumpkins-Bins/ac\":\"Pumpkin\", \"WatermelonLG-bins/ac\": \"Watermelon\",\n",
    "                            \"WatermelonMini-cases/ac\": \"Watermelon\"}\n",
    "        bc_rename_commodity = {\"Broccoli-cases/ac\":\"Broccoli\", \"WatermelonLG-bins/ac\": \"Watermelon\", \"WatermelonMini-cases/ac\": \"Watermelon\", \"Pumpkins-Bins/ac\":\"Pumpkin\",\n",
    "                            \"Squash-lbs\": \"Squash\"}\n",
    "        outlook_budget[\"CommodityRaw\"] = outlook_budget[\"Commodity\"]\n",
    "        production_budget[\"Commodity\"] = production_budget[\"Commodity\"].replace(production_rename_commodity)\n",
    "        input_budget[\"Commodity\"] = input_budget[\"Commodity\"].replace(input_rename_commodity)\n",
    "        outlook_budget[\"Commodity\"] = outlook_budget[\"Commodity\"].replace(outlook_rename_commodity)\n",
    "        az_budget[\"Commodity\"] = az_budget[\"CommodityRaw\"].replace(az_rename_commodity)\n",
    "        bc_budget[\"Commodity\"] = bc_budget[\"CommodityRaw\"].replace(bc_rename_commodity)\n",
    "        ## standardizing location naming - merge calderbank grain with Swift Current\n",
    "        jdlease_rename_location = {\"Swift Current Total\":\"Swift Current\", \"Regina Farm\":\"Regina\", \"Calderbank\":\"Swift Current\",\n",
    "                                \"Airdrie\":\"Airdrie (grain)\", \"Eddystone\":\"Eddystone (grain)\"}\n",
    "        labour_rename_location = {\"NexGen (avg met. ton)\":\"NexGen\", \"Cache/Fisher/Look\":\"Aschroft\", \"MF AZ\":\"Arizona (produce)\", \"Box Elder\":\"Havre\", \n",
    "                                \"BC Veg\":\"BritishColumbia (produce)\",\"Monette Seeds CDN (avg met. ton)\":\"Monette Seeds\", \n",
    "                                \"BC Cattle (avg head)\":\"BritishColumbia (cattle)\", \"Eddystone Cattle (avg head)\":\"Eddystone (cattle)\",\n",
    "                                \"Swift Current Cattle (avg head)\":\"Waldeck\", \"Aridrie Cattle (avg head)\":\"Airdrie (cattle)\",\n",
    "                                \"Airdrie Farm\":\"Airdrie (grain)\", \"Eddystone Farm\":\"Eddystone (grain)\",\"Calderbank\":\"Calderbank (cattle)\"}\n",
    "        input_rename_location =  {\"Fly Creek/Camp 1\":\"Fly Creek\", \"Regina Farm\":\"Regina\",\"Swift Current Total\":\"Swift Current\", \"Box Elder\":\"Havre\", \"Regina Farm\":\"Regina\",\n",
    "                                \"Calderbank\":\"Calderbank (grain)\",\"Airdrie\":\"Airdrie (grain)\", \"Eddystone\":\"Eddystone (grain)\"}\n",
    "        production_rename_location = {\"Fly Creek/Camp 1\":\"Fly Creek\", \"Regina Farm\":\"Regina\",\"Swift Current Total\":\"Swift Current\", \"Box Elder\":\"Havre\", \"Regina Farm\":\"Regina\",\n",
    "                                    \"Colorado (Genoa)\":\"Colorado\", \"Calderbank\":\"Swift Current\",\"Airdrie\":\"Airdrie (grain)\", \"Eddystone\":\"Eddystone (grain)\"}\n",
    "        input_budget[\"Location\"] = input_budget[\"Location\"].replace(input_rename_location)\n",
    "        production_budget[\"Location\"] = production_budget[\"Location\"].replace(production_rename_location)\n",
    "        labour_budget[\"Location\"] = labour_budget[\"Location\"].replace(labour_rename_location)\n",
    "        jdlease[\"Location\"] = jdlease[\"Location\"].replace(jdlease_rename_location)\n",
    "        ## put input budget (chem/fert/seed) into aggregated totals\n",
    "        input_budget2 = input_budget.groupby([\"Location\",\"Type\"]).agg({\"Amount\":\"sum\"}).reset_index(drop=False)\n",
    "        ## aggregated totals for production budget and JD Lease\n",
    "        production_budget = pd.DataFrame(production_budget.groupby([\"Location\",\"Currency\",\"Commodity\",\"ForecastPrice\"]).agg({\"TotalYield\":\"sum\", \"ForecastProductionCAD\":\"sum\", \"ForecastProductionAdj\":\"sum\"}).reset_index(drop=False))\n",
    "        jdlease = pd.DataFrame(jdlease.groupby([\"Location\",\"Country\",\"Currency\",\"TotalCost25\"]).agg({\"Acres25\":\"sum\",\"AllocatedCost25\":\"sum\"}).reset_index(drop=False))\n",
    "        return input_budget2, production_budget, labour_budget, jdlease, az_budget, bc_budget, outlook_budget\n",
    "\n",
    "    def _budget_process_produce(self, budget_rules:pd.DataFrame,budget:pd.DataFrame,sheetname:str) -> pd.DataFrame:\n",
    "        \"\"\" \n",
    "            this function provides a standardized way to process produce budgets\n",
    "        \"\"\"\n",
    "        budget_rules = budget_rules[budget_rules[\"SheetRef\"] == sheetname].copy(deep=True)\n",
    "        budget_rules[\"Commodity\"] = budget_rules.apply(lambda x: self._identify_product(x,for_budget=True), axis=1)\n",
    "        budget[\"Type\"] = budget[\"Type\"].str.strip()\n",
    "        # gross income - by commodity\n",
    "        reference = budget[budget[\"Type\"].isin([\"Acres\",\"Unit Price\",\"YieldPerAc\"])]\n",
    "        reference = reference.groupby([\"Commodity\",\"ProfitType\",\"CommodityRaw\"]).agg({\"AmountCAD\":\"prod\"}).reset_index(drop=False)\n",
    "        reference = reference.groupby([\"Commodity\"]).agg({\"AmountCAD\":\"sum\"}).reset_index(drop=False)\n",
    "        reference = reference.rename(columns={\"AmountCAD\":\"TotalAmountCAD\"})\n",
    "        reference[\"Category\"] = \"Produce - production\"\n",
    "        if \"outlook\" in sheetname.lower():\n",
    "            for item in [\"Prairie Pathways\", \"Market Garden / CSA\"]:\n",
    "                reference.loc[reference[\"Commodity\"] == item, \"Category\"] = \"Produce - cash settlements\"\n",
    "        # seed expense - by commodity\n",
    "        expense = budget[budget[\"Type\"] == \"Seed\"].copy(deep=True)\n",
    "        expense = expense.drop(columns=\"CommodityRaw\")\n",
    "        expense = expense.groupby([\"Commodity\"]).agg({\"AmountCAD\":\"sum\"}).reset_index(drop=False).rename(columns={\"AmountCAD\":\"TotalAmountCAD\"})\n",
    "        expense[\"Category\"] = \"Seed\"\n",
    "        # other expense - Fertilizer/Chemical - not by commodity\n",
    "        expense2 = budget[budget[\"Type\"].isin([\"Fertilizer\",\"Chemical\"])]\n",
    "        expense2 = expense2.groupby([\"Type\"]).agg({\"AmountCAD\":\"sum\"}).reset_index(drop=False).rename(columns={\"AmountCAD\":\"TotalAmountCAD\"})\n",
    "        expense2[\"Commodity\"] = \"Others\"\n",
    "        expense2 = expense2.rename(columns={\"Type\":\"Category\"})\n",
    "        # combine\n",
    "        budget_produce = pd.merge(budget_rules, pd.concat([reference,expense, expense2]), on=[\"Commodity\",\"Category\"], how=\"left\")\n",
    "        budget_produce = budget_produce.fillna(value={\"TotalAmountCAD\":0})\n",
    "        budget_produce[\"AmountCAD\"] = budget_produce.apply(lambda x: eval(f\"{x[\"TotalAmountCAD\"]}{x[\"Formula\"]}\"),axis=1)\n",
    "        return budget_produce\n",
    "\n",
    "    def _budget_get_transactions(self) -> pd.DataFrame:\n",
    "        \"\"\" \n",
    "            get actuals\n",
    "        \"\"\"\n",
    "        if self.is_dev:\n",
    "            transactions = pd.read_csv(self.gold_path[\"finance_operational\"]/\"PL.csv\")\n",
    "            self.operation_acc = pd.read_csv(self.gold_path[\"finance_operational\"]/\"AccNumTOAccID.csv\")\n",
    "        else:\n",
    "            transactions = self.gold_pl.copy(deep=True)\n",
    "        transactions = transactions[transactions[\"FiscalYear\"] >= 2024]\n",
    "        transactions[\"AccName\"] = transactions[\"AccName\"].str.strip()\n",
    "        return transactions\n",
    "\n",
    "    def _create_budget(self, process_input:bool = False) -> None:\n",
    "        \"\"\" \n",
    "            this function generates budgets\n",
    "        \"\"\"\n",
    "        location_adj = {\"Camp 4\": \"Billings\", \"Fly Creek\":\"Billings\"}\n",
    "        print(\"\\nCreating Budget\\n\")\n",
    "        if not self.is_dev:\n",
    "            if not self.pl_exist: self._finance_operational()\n",
    "        inputdata_path = self.gold_path[\"budget\"] / \"Outside Data\"\n",
    "        processed_path = self.gold_path[\"budget\"] / \"Processed Data\"\n",
    "        rule_path = self.gold_path[\"budget\"] / \"Budget Rules\"\n",
    "        copied_path = self.gold_path[\"budget\"]/\"Copied Data\"\n",
    "\n",
    "        # load actuals\n",
    "        transactions = self._budget_get_transactions()\n",
    "        \n",
    "        # process outside data\n",
    "        if process_input:\n",
    "            self._buget_process_input(inputdata_path=inputdata_path, processed_path=processed_path)\n",
    "        \n",
    "        # read outside data\n",
    "        input_budget2, production_budget, labour_budget, jdlease, az_budget, bc_budget, outlook_budget = self._budget_read_outsidedata(processed_path=processed_path)\n",
    "\n",
    "        # calculate Budgets\n",
    "        ## outside data\n",
    "        ### read rules\n",
    "        budget_rules = pd.read_csv(rule_path/\"OutsideData.csv\")\n",
    "        budget_rename_category = {\"Seed - farm\":\"Seed\"}\n",
    "        budget_rules[\"Category\"] = budget_rules[\"Category\"].replace(budget_rename_category)\n",
    "        ### separate locations into individual rows when they are separated with + in the rules df\n",
    "        budget_rules[\"Location\"] = budget_rules[\"Location\"].str.split(\"+\")\n",
    "        budget_rules = budget_rules.explode(\"Location\").reset_index(drop=True)\n",
    "        ### extract formula\n",
    "        budget_rules = budget_rules.melt(\n",
    "            id_vars=[\"Location\",\"Category\",\"AccFull\",\"SheetRef\"],\n",
    "            var_name=\"Month\",\n",
    "            value_name=\"Formula\"\n",
    "        )\n",
    "        budget_rules = budget_rules.fillna(value={\"Formula\":\"0\"})\n",
    "        budget_rules[\"Formula\"] = budget_rules[\"Formula\"].astype(str)\n",
    "        budget_rules[\"Formula\"] = budget_rules[\"Formula\"].replace({\"0\": \"*0\"})\n",
    "        ### calculating input budget for accounts per location\n",
    "        budget_rules_input = budget_rules[budget_rules[\"SheetRef\"] == \"Input Budget\"].copy(deep=True)\n",
    "        #### workaround input budget for Airdrie grain \n",
    "        input_budget2.loc[((input_budget2[\"Location\"]==\"Airdrie (grain)\")&(input_budget2[\"Type\"]==\"Acres\")),\"Type\"] = \"Custom work\"\n",
    "        ### merge budget rules with budget total per location\n",
    "        budget_input = pd.merge(budget_rules_input,input_budget2.rename(columns={\"Type\":\"Category\",\"Amount\":\"TotalAmountCAD\"}),on=[\"Location\",\"Category\"],how=\"left\")\n",
    "        #### revert back from workaround\n",
    "        input_budget2.loc[((input_budget2[\"Location\"]==\"Airdrie (grain)\")&(input_budget2[\"Type\"]==\"Custom work\")),\"Type\"] = \"Acres\"\n",
    "        ### apply the formula to compute per month\n",
    "        budget_input[\"AmountCAD\"] = budget_input.apply(lambda x: eval(f\"{x[\"TotalAmountCAD\"]}{x[\"Formula\"]}\"), axis=1)\n",
    "\n",
    "        ## production budget\n",
    "        ### combine Hay and Silage\n",
    "        production_budget[\"Commodity\"] = production_budget[\"Commodity\"].replace({\"Hay\":\"Hay/Silage\", \"Silage\":\"Hay/Silage\"})\n",
    "        ### add commodity column to budget rules\n",
    "        budget_rules_production = budget_rules[budget_rules[\"SheetRef\"] == \"Production Budget\"].copy(deep=True)\n",
    "        budget_rules_production[\"Commodity\"] = budget_rules_production.apply(lambda x: self._identify_product(x, for_budget=True), axis=1)\n",
    "        ### merge budget rules with budget totals\n",
    "        budget_production = pd.merge(budget_rules_production,production_budget.loc[:,[\"Location\",\"Commodity\",\"ForecastProductionCAD\"]].rename(columns={\"ForecastProductionCAD\":\"TotalAmountCAD\"}),\n",
    "                                         on = [\"Location\", \"Commodity\"], how=\"left\")\n",
    "        budget_production = budget_production.fillna(value={\"TotalAmountCAD\":0})\n",
    "        ### compute budget\n",
    "        budget_production[\"AmountCAD\"] = budget_production.apply(lambda x: eval(f\"{x[\"TotalAmountCAD\"]}{x[\"Formula\"]}\"),axis=1)\n",
    "\n",
    "        ## labour budget\n",
    "        budget_rules_labour = budget_rules[budget_rules[\"SheetRef\"] == \"Labour Budget\"].copy(deep=True)\n",
    "        budget_labour = pd.merge(budget_rules_labour, labour_budget.loc[:,[\"Location\",\"Month\",\"LabourBudgetCAD\"]].rename(columns={\"LabourBudgetCAD\":\"AmountCAD\"}),\n",
    "                                    on=[\"Location\",\"Month\"],how=\"left\")\n",
    "        \n",
    "        ## produce budgets\n",
    "        ### BC\n",
    "        budget_bc_produce = self._budget_process_produce(budget_rules=budget_rules,budget=bc_budget,sheetname=\"BC Produce Details\")\n",
    "        ### AZ\n",
    "        budget_az_produce = self._budget_process_produce(budget_rules=budget_rules,budget=az_budget,sheetname=\"AZ Details\")\n",
    "        ### outlook\n",
    "        budget_outlook = self._budget_process_produce(budget_rules=budget_rules,budget=outlook_budget.rename(columns={\"Amount\":\"AmountCAD\"}),sheetname=\"Outlook Details\")\n",
    "\n",
    "        ## JD lease\n",
    "        budget_rules_jd = budget_rules[budget_rules[\"SheetRef\"]==\"JD Lease\"].copy(deep=True)\n",
    "        budget_equipment = pd.merge(budget_rules_jd, jdlease.loc[:,[\"Location\",\"AllocatedCost25\"]].rename(columns={\"AllocatedCost25\":\"TotalAmountCAD\"}),\n",
    "                                        on = \"Location\", how = \"left\")\n",
    "        budget_equipment = budget_equipment.fillna(value={\"TotalAmountCAD\":0})\n",
    "        budget_equipment[\"AmountCAD\"] = budget_equipment.apply(lambda x: eval(f\"{x[\"TotalAmountCAD\"]}{x[\"Formula\"]}\"),axis=1)\n",
    "\n",
    "        ## adjustment for Swift Current\n",
    "        months = [\"April\", \"July\"]\n",
    "        for month in months:\n",
    "            budget_input.loc[((budget_input[\"Location\"]==\"Swift Current\")&(budget_input[\"Category\"]==\"Fertilizer\")&(budget_input[\"Month\"]==month)),\"TotalAmountCAD\"] += \\\n",
    "            budget_input.loc[((budget_input[\"Location\"]==\"Calderbank (grain)\")&(budget_input[\"Category\"]==\"Fertilizer\")&(budget_input[\"Month\"]==month)),\"TotalAmountCAD\"].item()\n",
    "            budget_input.loc[((budget_input[\"Location\"]==\"Swift Current\")&(budget_input[\"Category\"]==\"Fertilizer\")&(budget_input[\"Month\"]==month)),\"AmountCAD\"] += \\\n",
    "            budget_input.loc[((budget_input[\"Location\"]==\"Calderbank (grain)\")&(budget_input[\"Category\"]==\"Fertilizer\")&(budget_input[\"Month\"]==month)),\"AmountCAD\"].item()\n",
    "        months = [\"June\", \"September\"]\n",
    "        for month in months:\n",
    "            budget_input.loc[((budget_input[\"Location\"]==\"Swift Current\")&(budget_input[\"Category\"]==\"Chemical\")&(budget_input[\"Month\"]==month)),\"TotalAmountCAD\"] += \\\n",
    "            budget_input.loc[((budget_input[\"Location\"]==\"Calderbank (grain)\")&(budget_input[\"Category\"]==\"Chemical\")&(budget_input[\"Month\"]==month)),\"TotalAmountCAD\"].item()\n",
    "            budget_input.loc[((budget_input[\"Location\"]==\"Swift Current\")&(budget_input[\"Category\"]==\"Chemical\")&(budget_input[\"Month\"]==month)),\"AmountCAD\"] += \\\n",
    "            budget_input.loc[((budget_input[\"Location\"]==\"Calderbank (grain)\")&(budget_input[\"Category\"]==\"Chemical\")&(budget_input[\"Month\"]==month)),\"AmountCAD\"].item()\n",
    "        months = [\"May\", \"June\", \"September\"]\n",
    "        for month in months:\n",
    "            budget_input.loc[((budget_input[\"Location\"]==\"Swift Current\")&(budget_input[\"Category\"]==\"Seed\")&(budget_input[\"Month\"]==month)),\"TotalAmountCAD\"] += \\\n",
    "            budget_input.loc[((budget_input[\"Location\"]==\"Calderbank (grain)\")&(budget_input[\"Category\"]==\"Seed\")&(budget_input[\"Month\"]==month)),\"TotalAmountCAD\"].item()\n",
    "            budget_input.loc[((budget_input[\"Location\"]==\"Swift Current\")&(budget_input[\"Category\"]==\"Seed\")&(budget_input[\"Month\"]==month)),\"AmountCAD\"] += \\\n",
    "            budget_input.loc[((budget_input[\"Location\"]==\"Calderbank (grain)\")&(budget_input[\"Category\"]==\"Seed\")&(budget_input[\"Month\"]==month)),\"AmountCAD\"].item()\n",
    "        \n",
    "        # arithmetic rules\n",
    "        arithmetic = pd.read_csv(rule_path/\"Arithmetic.csv\")\n",
    "        ## faltten location\n",
    "        arithmetic[\"Location\"] = arithmetic[\"Location\"].str.split(\"+\")\n",
    "        arithmetic = arithmetic.explode(\"Location\").reset_index(drop=True)\n",
    "        arithmetic_rules = arithmetic.melt(\n",
    "            id_vars=[\"Location\",\"Category\",\"AccFull\", \"AccRef\", \"FixedRef\"],\n",
    "            var_name=\"Month\",\n",
    "            value_name=\"FormulaFull\"\n",
    "        )\n",
    "        ## housekeeping\n",
    "        arithmetic_rules = arithmetic_rules.fillna(value={\"FormulaFull\":\"FY-1*0\"})\n",
    "        arithmetic_rules[\"FormulaFull\"] = arithmetic_rules[\"FormulaFull\"].astype(str)\n",
    "        arithmetic_rules[\"FormulaFull\"] = arithmetic_rules[\"FormulaFull\"].replace({\"0\":\"FY-1*0\"})\n",
    "        arithmetic_rules[\"ReferenceYear\"] = arithmetic_rules[\"FormulaFull\"].str.slice(0,4)\n",
    "        arithmetic_rules[\"Formula\"] = arithmetic_rules[\"FormulaFull\"].str.slice(4)\n",
    "        arithmetic_rules = arithmetic_rules.fillna(value={\"Formula\": \"0\"})\n",
    "        arithmetic_rules[\"Formula\"] = arithmetic_rules[\"Formula\"].astype(str)\n",
    "        arithmetic_rules[\"Formula\"] = arithmetic_rules[\"Formula\"].replace({\"0\":\"*0\"})\n",
    "        ## separating Fixed records\n",
    "        ### processing arithmetic_rules for billings - 1.ignore camp 4, 2. rename Fly Creek to Billings\n",
    "        ###     this is to avoid applying the arithmetic twice for billings, and all accounts except on are fly creek + camp 4 (identical calculation)\n",
    "        ###     the only exception is for amortization, camp 4 was fixed and fly creek was arithmetic - ignore the fixed cost for camp 4 for fixed as well\n",
    "        ### adjusted in excel sheet instead\n",
    "        # arithmetic_rules = arithmetic_rules[~((arithmetic_rules[\"Location\"]==\"Camp 4\") & (arithmetic_rules[\"Category\"]))]\n",
    "        # arithmetic_rules[\"Location\"] = arithmetic_rules[\"Location\"].replace(location_adj)\n",
    "        arithmetic_rules_fixed = arithmetic_rules[arithmetic_rules[\"AccRef\"] == \"Fixed\"].copy(deep=True)\n",
    "        arithmetic_rules = arithmetic_rules[arithmetic_rules[\"AccRef\"]!=\"Fixed\"].copy(deep=True)\n",
    "\n",
    "        ## process fixed records\n",
    "        arithmetic_rules_fixed = arithmetic_rules_fixed.drop(columns=[\"FormulaFull\",\"ReferenceYear\"]).rename(columns={\"FixedRef\":\"TotalAmountCAD\"})\n",
    "        arithmetic_rules_fixed[\"AmountCAD\"] = arithmetic_rules_fixed.apply(lambda x: eval(f\"{x[\"TotalAmountCAD\"]}{x[\"Formula\"]}\"),axis=1)\n",
    "\n",
    "        ## Extract Account Info\n",
    "        arithmetic_rules[\"AccNum\"] = arithmetic_rules[\"AccRef\"].apply(lambda x: \"\".join(x.split(\" \")[0:2]))\n",
    "        arithmetic_rules[\"AccName\"] = arithmetic_rules[\"AccRef\"].apply(lambda x: (\" \".join(x.split(\" \")[2:]).strip()))\n",
    "        assert \"Fixd\" not in arithmetic_rules.ReferenceYear.unique(), \"Fixd records incorrectly classified\"\n",
    "        ## separate FY-1 & FY+1\n",
    "        arithmetic_rules_prior = arithmetic_rules[arithmetic_rules[\"ReferenceYear\"] == \"FY-1\"].copy(deep=True)\n",
    "        arithmetic_rules = arithmetic_rules[arithmetic_rules[\"ReferenceYear\"] == \"FY+1\"].copy(deep=True)\n",
    "\n",
    "        ## process FY-1 with actuals\n",
    "        actuals = transactions.groupby([\"Location\", \"AccNum\", \"AccName\", \"FiscalYear\"]).agg({\"AmountDisplay\":\"sum\"}).reset_index(drop=False)\n",
    "        arithmetic_rules_prior[\"FiscalYear\"] = self.currentFY - 1\n",
    "        assert len(actuals[actuals.duplicated(subset=[\"AccNum\",\"FiscalYear\",\"Location\"],keep=False)]) == 0, \"Duplicated AccNum detected for FY-1 Actuals\"\n",
    "        budget_prior = pd.merge(arithmetic_rules_prior,actuals.rename(columns={\"AmountDisplay\":\"TotalAmountCAD\"}),\n",
    "                                on = [\"Location\",\"AccNum\",\"FiscalYear\"], how=\"left\")\n",
    "        budget_prior = budget_prior.fillna(value={\"TotalAmountCAD\": 0})\n",
    "        budget_prior[\"AmountCAD\"] = budget_prior.apply(lambda x: eval(f\"{x[\"TotalAmountCAD\"]}{x[\"Formula\"]}\"), axis=1)\n",
    "\n",
    "        ## processing FY+1 with current budget\n",
    "        ### budget sales that is based on production budget input sheet\n",
    "        arithmetic_rules_sales = arithmetic_rules[arithmetic_rules[\"Category\"].str.contains(\"cash settlements\")].copy(deep=True)\n",
    "        production_reference = pd.concat([budget_production.copy(deep=True), budget_outlook.copy(deep=True), budget_az_produce.copy(deep=True),budget_bc_produce.copy(deep=True)])\n",
    "        production_reference = production_reference.groupby([\"Location\",\"AccFull\"]).agg({\"AmountCAD\":\"sum\"}).reset_index(drop=False)\n",
    "        budget_sales = pd.merge(arithmetic_rules_sales,production_reference.rename(columns={\"AccFull\":\"AccRef\"}), on=[\"Location\",\"AccRef\"], how=\"left\")\n",
    "        budget_sales = budget_sales.rename(columns={\"AmountCAD\":\"TotalAmountCAD\"})\n",
    "        budget_sales[\"AmountCAD\"] = budget_sales.apply(lambda x: eval(f\"{x[\"TotalAmountCAD\"]}{x[\"Formula\"]}\"),axis=1)\n",
    "        budget_prior = pd.concat([budget_prior, budget_sales],ignore_index=True)\n",
    "\n",
    "        ### budget inventory adjustment \n",
    "        arithmetic_rules_inventory = arithmetic_rules[arithmetic_rules[\"Category\"].str.contains(\"inventory adjustment\",case=False)].copy(deep=True)\n",
    "        budget_inventory = pd.merge(arithmetic_rules_inventory, budget_prior.loc[:,[\"Location\",\"AccFull\",\"Month\",\"AmountCAD\"]].rename(columns={\"AccFull\":\"AccRef\"}),\n",
    "                                on = [\"Location\",\"AccRef\", \"Month\"], how = \"left\")\n",
    "        budget_inventory[\"AmountCAD\"] = -budget_inventory[\"AmountCAD\"]\n",
    "        budget_prior = pd.concat([budget_prior, budget_inventory], ignore_index=True)\n",
    "\n",
    "        ## combine with fixed budgets\n",
    "        budget_prior = pd.concat([budget_prior,arithmetic_rules_fixed],ignore_index=True)\n",
    "\n",
    "        # copied data\n",
    "        budget_copy = pd.read_csv(copied_path/\"Copied Data.csv\")\n",
    "        budget_copy = budget_copy.melt(\n",
    "            id_vars=[\"Location\",\"Category\",\"AccFull\"],\n",
    "            var_name = \"Month\",\n",
    "            value_name = \"AmountCAD\"\n",
    "        )\n",
    "        budget_copy = budget_copy.fillna(value={\"AmountCAD\":0})\n",
    "        budget_copy[\"AmountCAD\"] = budget_copy[\"AmountCAD\"].astype(float)\n",
    "        budget_copy[\"FiscalYear\"] = self.currentFY\n",
    "        budget_copy[\"AccRef\"] = \"Copy\"\n",
    "        budget_copy[\"ReferenceYear\"] = \"NA\"\n",
    "        budget_copy[\"Formula\"] = \"NA\"\n",
    "        budget_copy[\"TotalAmountCAD\"] = budget_copy[\"AmountCAD\"]\n",
    "        budget_copy.loc[budget_copy[\"Location\"]==\"Seeds USA\", \"AmountCAD\"] *= self.fx\n",
    "\n",
    "        # combining all budgets\n",
    "        budget_outside = pd.concat([budget_input,budget_production,budget_labour,budget_equipment, budget_outlook, budget_az_produce, budget_bc_produce],ignore_index=True)\n",
    "        budget_outside = budget_outside.drop(columns=[\"Commodity\"])\n",
    "        budget_prior = budget_prior.drop(columns=[\"FormulaFull\",\"AccNum\",\"AccName_x\", \"AccName_y\", \"AccName\", \"FixedRef\"])\n",
    "        budget_all = pd.concat([budget_outside,budget_prior,budget_copy],ignore_index=True)\n",
    "        budget_all[\"AccNum\"] = budget_all[\"AccFull\"].apply(lambda x: \"\".join(x.split(\" \")[0:2]))\n",
    "        budget_all[\"AccName\"] = budget_all[\"AccFull\"].apply(lambda x: \" \".join(x.split(\" \")[2:]))\n",
    "        budget_all[\"FiscalYear\"] = self.currentFY \n",
    "        budget_all[\"DataType\"] = \"Budget\"\n",
    "        # budget_all.loc[budget_all[\"Category\"].str.contains(\"inventory adjustment\",case=False), \"AmountCAD\"] *= -1 # turn the sign positive for inventory adjustments (my classification only)\n",
    "\n",
    "        # enbale location to be modified, e.g., for Camp 4 + Fly Creek = Billings\n",
    "        budget_all[\"LocationRaw\"] = budget_all[\"Location\"]\n",
    "        budget_all[\"Location\"] = budget_all[\"Location\"].replace(location_adj)\n",
    "\n",
    "        # save\n",
    "        self.check_file(self.gold_path[\"budget\"]/\"OutputFile\")\n",
    "        budget_all.to_csv(self.gold_path[\"budget\"]/\"OutputFile\"/\"budget_all.csv\", index=False)\n",
    "\n",
    "    def _budget_update(self, force_create:bool=True, force_process_input:bool=False) -> None:\n",
    "        \"\"\" \n",
    "            generate/update the actuals from the budget system\n",
    "        \"\"\"\n",
    "        print(\"\\nGenerating/Updating Actuals for budget system\\n\")\n",
    "        if self.is_dev:\n",
    "            self.operation_acc = pd.read_csv(self.gold_path[\"finance_operational\"]/\"AccNumTOAccID.csv\")\n",
    "            self.gold_pl = pd.read_csv(self.gold_path[\"finance_operational\"]/\"PL.csv\")\n",
    "            self.fx = 1.3807\n",
    "        else:\n",
    "            if not self.pl_exist:\n",
    "                self._finance_operational()\n",
    "        budget_path = self.gold_path[\"budget\"]/\"OutputFile\"/\"budget_all.csv\"\n",
    "        if (not Path.exists(budget_path)) or force_create:\n",
    "            self._create_budget(process_input=force_process_input)\n",
    "        budget = pd.read_csv(budget_path)\n",
    "        budget = budget.loc[:,[\"Location\", \"SheetRef\", \"Month\", \"Formula\", \"TotalAmountCAD\", \"AmountCAD\", \"AccRef\", \"ReferenceYear\",\"FiscalYear\", \"AccNum\", \"DataType\", \"Category\"]]\n",
    "        budget_location_rename = {\"Airdrie (grain)\": \"Airdrie\", \"Airdrie (cattle)\": \"Airdrie\", \"Calderbank (cattle)\": \"Calderbank\",\n",
    "                                  \"Airdrie (corporate)\": \"Airdrie\", \"Seeds USA\":\"Arizona (produce)\"}\n",
    "        budget[\"Location\"] = budget[\"Location\"].replace(budget_location_rename)\n",
    "        # category_mapping = budget.loc[:,[\"AccNum\", \"Category\"]].drop_duplicates()     # problem with old changed AccNum mapped to incorrect Category\n",
    "        # organize Actuals\n",
    "        transactions = self._budget_get_transactions()\n",
    "        actuals_all = transactions.groupby([\"Location\",\"AccNum\", \"FiscalYear\", \"Month\"]).agg({\"AmountDisplay\":\"sum\"}).reset_index(drop=False)\n",
    "        actuals_all = actuals_all[actuals_all[\"FiscalYear\"] == self.currentFY]\n",
    "        actuals_all[\"DataType\"] = \"Actual\"\n",
    "        actuals_all = actuals_all.rename(columns={\"AmountDisplay\": \"AmountCAD\"})\n",
    "        # actuals_all = pd.merge(actuals_all,category_mapping,on=\"AccNum\",how=\"left\")   # problem with old changed AccNum mapped to incorrect Category\n",
    "        actuals_all.to_csv(self.gold_path[\"budget\"]/\"OutputFile\"/\"actuals_all.csv\", index=False)\n",
    "        print(f\"Location Unaccounted for in budget: {(set(budget.Location.unique()) - set(actuals_all.Location.unique()))}\")\n",
    "        # combine everything\n",
    "        all_all = pd.concat([budget,actuals_all],ignore_index=True)\n",
    "        all_all[\"FXRate\"] = self.fx\n",
    "        # reroute accounts for changing acc numbers\n",
    "        all_all[\"AccNum\"] = all_all[\"AccNum\"].replace(self.accnum_reroute)\n",
    "        # operational classification - AccNum to AccID mapping processed from _finance_operational() function\n",
    "        assert len(self.operation_acc[self.operation_acc.duplicated(subset=[\"AccNum\"],keep=False)]) == 0, \"Duplicated AccNum Detected - Operational Accounts Classification\"\n",
    "        self._extract_accnum_accid()\n",
    "        all_all[\"AccID\"] = all_all[\"AccNum\"].map(self.acc_map)\n",
    "        mismatch = all_all[all_all[\"AccID\"].isna()]\n",
    "        mismatch = mismatch[mismatch['AmountCAD']!=0]\n",
    "        print(f\"Total amount unaccounted for because of accnum mismatching - ${mismatch.AmountCAD.sum()}\")\n",
    "        print(f\"AccIDs with non-zero amount: {mismatch.AccNum.unique()}\")\n",
    "        # classify pillars\n",
    "        all_all[\"Pillar\"] = all_all.apply(lambda x: self._pillar_classification(x), axis=1)\n",
    "        # save\n",
    "        all_all.to_csv(self.gold_path[\"budget\"]/\"OutputFile\"/\"all_all.csv\", index=False)\n",
    "        self.check_file(self.gold_path[\"budget\"]/\"OutputPowerBI\")\n",
    "        if not self.is_dev: \n",
    "            print(\"Saving ...\")\n",
    "            all_all.to_excel(self.gold_path[\"budget\"]/\"OutputPowerBI\"/\"BudgetActual.xlsx\", sheet_name=\"Budget\", index=False)\n",
    "            for pillar in [\"Grain\", \"Cattle\", \"Seed\", \"Produce\"]:\n",
    "                all_all[all_all[\"Pillar\"]==pillar].to_excel(self.gold_path[\"pillar_dashboard\"]/pillar/\"BudgetActual.xlsx\", sheet_name=\"Budget\", index=False)\n",
    "            \n",
    "    def _create_additional_financial(self, summary:pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\" \n",
    "            this function create Gross Margin, Contribution Margin, EBITDA, Net Income financial terms in the summary table\n",
    "                summary table must be broken down to fiscal year, month, location\n",
    "        \"\"\"\n",
    "        complement_data = summary.head(0).copy(deep=True)\n",
    "        for y in summary.FiscalYear.unique():\n",
    "            subset_year = summary[summary[\"FiscalYear\"] == y]\n",
    "            for m in summary.Month.unique():\n",
    "                subset_month = subset_year[subset_year[\"Month\"] == m]\n",
    "                for l in summary.Location.unique():\n",
    "                    subset_location = subset_month[subset_month[\"Location\"] == l]\n",
    "                    if len(subset_location) == 0:\n",
    "                        continue\n",
    "                    items = [\"Sales Revenue\", \"Cost of Goods Sold\", \"Direct Operating Expenses\", \"Other Operating Revenue\", \"Operating Overheads\", \"Other Income\", \"Other Expense\"]\n",
    "                    values = dict.fromkeys(items, 0)\n",
    "                    for i in items:\n",
    "                        if i in subset_location.ProfitType.unique():\n",
    "                            values[i] = subset_location.loc[subset_location[\"ProfitType\"]==i, \"AmountDisplay\"].item()\n",
    "                    gross_margin = values[\"Sales Revenue\"] - values[\"Cost of Goods Sold\"]\n",
    "                    contribution_margin = gross_margin - values[\"Direct Operating Expenses\"] + values[\"Other Operating Revenue\"]\n",
    "                    ebitda = contribution_margin - values[\"Operating Overheads\"]\n",
    "                    net_income = ebitda + values[\"Other Income\"] - values[\"Other Expense\"]\n",
    "                    pillar = subset_location.Pillar.unique().item()\n",
    "                    row = {\"FiscalYear\": y, \"Month\": m, \"Location\": l, \"Pillar\":pillar}\n",
    "                    row_GM = row | {\"ProfitType\": \"Gross Margin\", \"AmountDisplay\": gross_margin}\n",
    "                    row_CM = row | {\"ProfitType\": \"Contribution Margin\", \"AmountDisplay\": contribution_margin}\n",
    "                    row_ebitda = row | {\"ProfitType\": \"EBITDA\", \"AmountDisplay\": ebitda}\n",
    "                    row_NI = row | {\"ProfitType\": \"Net Income\", \"AmountDisplay\": net_income}\n",
    "                    complement_data.loc[len(complement_data)] = row_GM\n",
    "                    complement_data.loc[len(complement_data)] = row_CM \n",
    "                    complement_data.loc[len(complement_data)] = row_ebitda \n",
    "                    complement_data.loc[len(complement_data)] = row_NI \n",
    "        return complement_data\n",
    "\n",
    "    def _finance_summary(self, create_allocation_reference = True) -> None:\n",
    "        \"\"\" \n",
    "            this function assemble summary tables for financial income statement style, including Gross Margin, EBITDA, Net Income, \n",
    "                compared to (with % change compared to last year and budget)\n",
    "                    1. Last Year\n",
    "                    2. Budget\n",
    "                    3. month-by-month\n",
    "                includes Units (e.g., Acres)\n",
    "        \"\"\"\n",
    "        if self.is_dev:\n",
    "            self.operation_acc = pd.read_csv(self.gold_path[\"finance_operational\"]/\"AccNumTOAccID.csv\")\n",
    "            self.gold_pl = pd.read_csv(self.gold_path[\"finance_operational\"]/\"PL.csv\")\n",
    "            self.fx = 1.3844\n",
    "        else:\n",
    "            if not self.pl_exist:\n",
    "                self._finance_operational()\n",
    "        # prepare dfs \n",
    "        data = self.gold_pl[self.gold_pl[\"FiscalYear\"] >=  2024].copy(deep=True)\n",
    "        account = self.gold_acc[self.gold_acc[\"AccountingType\"] == \"Income Statement\"]\n",
    "        # create AccID -> ProfitType mapping\n",
    "        id_prof_map = account.set_index(\"AccID\")[\"ProfitType\"]\n",
    "        data[\"ProfitType\"] = data[\"AccID\"].map(id_prof_map)\n",
    "        # summary by location, by pillar, by ProfitType, by Fiscal Year, by Month\n",
    "        summary = data.groupby([\"FiscalYear\", \"Month\", \"Location\", \"Pillar\", \"ProfitType\"]).agg({\"AmountDisplay\":\"sum\"}).reset_index(drop=False)\n",
    "        assert len(summary) == len(data.groupby([\"FiscalYear\", \"Month\", \"Location\", \"ProfitType\"]).agg({\"AmountDisplay\":\"sum\"})), \"duplicated location-pillar detected\"\n",
    "        # prepare df for additional financial lines, e.g., Gross Margin, Net Income, ...\n",
    "        complement_data = self._create_additional_financial(summary)\n",
    "        # concat two dfs\n",
    "        summary = pd.concat([summary, complement_data],ignore_index=True)\n",
    "        # assign datatype before budget summary\n",
    "        summary[\"DataType\"] = \"Actual\"\n",
    "        # read processed budget transactions\n",
    "        budget = pd.read_csv(self.gold_path[\"budget\"]/\"OutputFile\"/\"all_all.csv\")\n",
    "        budget = budget[budget[\"DataType\"] == \"Budget\"]\n",
    "        budget = budget.loc[:,[\"Location\", \"Month\", \"FiscalYear\", \"AmountCAD\", \"DataType\", \"AccID\", \"Pillar\",\"AccNum\"]]\n",
    "        budget = budget.rename(columns={\"AmountCAD\":\"AmountDisplay\"})\n",
    "        budget = budget[~((budget[\"AccID\"].isna())&(budget[\"AmountDisplay\"] == 0))].reset_index(drop=True)\n",
    "        assert len(budget[budget[\"AccID\"].isna()]) == 0, f\"Unaccounted accounts - {budget[budget[\"AccID\"].isna()].AccNum.unique()}\"\n",
    "        budget = budget.drop(columns=[\"AccNum\"])\n",
    "        # map ProfitType\n",
    "        budget[\"ProfitType\"] = budget[\"AccID\"].map(id_prof_map)\n",
    "        # budget summary\n",
    "        summary_budget = budget.groupby([\"FiscalYear\",\"Month\",\"Location\",\"Pillar\",\"ProfitType\"]).agg({\"AmountDisplay\":\"sum\"}).reset_index(drop=False)\n",
    "        assert len(summary_budget) == len(budget.groupby([\"FiscalYear\",\"Month\",\"Location\",\"ProfitType\"]).agg({\"AmountDisplay\":\"sum\"})), \"repeat Pillar detected when summarizing budget\"\n",
    "        # additional financial terms\n",
    "        complement_data_budget = self._create_additional_financial(summary_budget)\n",
    "        # final processing\n",
    "        summary_budget = pd.concat([summary_budget,complement_data_budget],ignore_index=True)\n",
    "        summary_budget[\"DataType\"] = \"Budget\"\n",
    "        print(f\"Location missing from budget - {set(summary.Location.unique()) - set(summary_budget.Location.unique())}\")\n",
    "        print(f\"Location missing from actual - {set(summary_budget.Location.unique()) - set(summary.Location.unique())}\")\n",
    "        # save\n",
    "        summary_all = pd.concat([summary, summary_budget],ignore_index=True)\n",
    "        summary_all.to_csv(self.gold_path[\"finance_operational\"]/\"ProfitTypeSummary.csv\", index=False) # for reclassifying accounts\n",
    "        summary_all.to_excel(self.gold_path[\"finance_operational\"]/\"ProfitTypeSummary.xlsx\", sheet_name=\"ProfitTypeSummary\", index=False)\n",
    "        for pillar in [\"Grain\", \"Cattle\", \"Seed\", \"Produce\"]:\n",
    "            summary_all[summary_all[\"Pillar\"]==pillar].to_excel(self.gold_path[\"pillar_dashboard\"]/pillar/\"ProfitTypeSummary.xlsx\", sheet_name=\"ProfitTypeSummary\", index=False)\n",
    "\n",
    "    def _APAR_concat_memo(self, df:pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\" \n",
    "            This function concatenates all 'TransactionEntered' column per TransactionID_partial\n",
    "        \"\"\"\n",
    "        df_map = df.loc[:,[\"TransactionID_partial\", \"TransactionEntered\", \"Line_Id\", \"PrivateNote\", \"TransactionType\"]]\n",
    "        # fill missing TransactionEntered as Missing so it is string and can be concatenated\n",
    "        df_map = df_map.fillna(value={\"TransactionEntered\":\"Missing\", \"PrivateNote\": \"Missing\"})\n",
    "        # concatenate the line number into TransactionEntered so it's not too messy when concatenate TransactionEntered for multiple lines\n",
    "        df_map[\"TransactionEntered\"] = df_map[\"Line_Id\"].astype(str) + \". \" + df_map[\"TransactionEntered\"]\n",
    "        # concatenate -> one TransactionEntered per TransactionID_partial\n",
    "        df_map2 = df_map.sort_values(by=[\"TransactionID_partial\", \"Line_Id\"],ignore_index=True)\\\n",
    "                        .groupby([\"TransactionID_partial\",\"PrivateNote\",\"TransactionType\"])[\"TransactionEntered\"].agg(\" \".join).reset_index(drop=False)\n",
    "        assert len(df_map2[df_map2.duplicated(subset=\"TransactionID_partial\")]) == 0, \"duplicated transactionID spotted when creating TransactionEntered Concatenation\"\n",
    "        return df_map2\n",
    "    \n",
    "    def _APRporting_project(self, date:set[int] = None) -> None:\n",
    "        \"\"\" \n",
    "            This function connects APAgingDetails report from QBO API, and combined with raw tables such as Bill to form a comprehensive report that meets finance team's need\n",
    "                This function supports date input for processing the report at that exact date\n",
    "        \"\"\"\n",
    "        print(\"\\nProcessing AP Rerpot\\n\")\n",
    "        if date is not None:\n",
    "            assert len(date) == 3, f\"please pass the date as (YYYY, M, D), passed {date}\"\n",
    "            year, month, day = date\n",
    "        else:\n",
    "            year, month, day = self.today.year, self.today.month, self.today.day\n",
    "        # read APAging report from silver space\n",
    "        try:\n",
    "            report = pd.read_csv(self.silver_path[\"QBO\"][\"APAR\"] / \"AgedPayableDetail\" / str(year) / str(month) / f\"{day}.csv\")\n",
    "        except:\n",
    "            print(f'csv file not found at {self.silver_path[\"QBO\"][\"APAR\"] / \"AgedPayableDetail\" / str(year) / str(month) / f\"{day}.csv\"}')\n",
    "        report = report.rename(columns={\"TransactionTypeID\":\"TransactionID_partial\"})\n",
    "        report_transactiontype_rename = {\"Bill Payment (Cheque)\":\"BillPaymentCheck\", \"Bill Payment (Credit Card)\":\"BillPaymentCheck\", \"Bill Payment (Check)\":\"BillPaymentCheck\",\n",
    "                                        \"Cheque Expense\":\"Purchase\", \"Supplier Credit\": \"Vendor Credit\"}\n",
    "        # standardize the Transaction Types\n",
    "        report[\"TransactionType\"] = report[\"TransactionType\"].replace(report_transactiontype_rename)\n",
    "        # create mapping table from facts\n",
    "        cols = [\"TransactionDate\", \"TotalAmt\", \"PrivateNote\", \"APAccID\", \"DocNumber\", \"TransactionEntered\", \"Amount\", \"TransactionID\", \"VendorID\", \"FarmID\", \"TransactionID_partial\", \"Line_Id\",\n",
    "                \"AccID\"]\n",
    "        ## get bill table ready for mapping - only taking bill transactions that are relevant to AP report\n",
    "        bill_col = cols + [\"TermID\"]\n",
    "        bill = pd.read_csv(self.silver_path[\"QBO\"][\"Raw\"]/\"Bill.csv\",usecols=bill_col)\n",
    "        bill = bill[bill[\"TransactionID_partial\"].isin(report[report[\"TransactionType\"]==\"Bill\"][\"TransactionID_partial\"].unique())]\n",
    "        bill[\"TransactionType\"] = \"Bill\"\n",
    "        bill_map = self._APAR_concat_memo(bill) # results should only have 4 columns:  TransactionID_partial, PrivateNote, TransactionType, TransactionEntered (concatenated)\n",
    "        ## vendorcredit\n",
    "        vc = pd.read_csv(self.silver_path[\"QBO\"][\"Raw\"] / \"VendorCredit.csv\", usecols=cols)\n",
    "        vc = vc[vc[\"TransactionID_partial\"].isin(report[report[\"TransactionType\"]==\"Vendor Credit\"][\"TransactionID_partial\"].unique())]\n",
    "        vc[\"TransactionType\"] = \"Vendor Credit\"\n",
    "        vc_map = self._APAR_concat_memo(vc)\n",
    "        ## journal entry\n",
    "        journal_cols = cols + [\"JEType\"]\n",
    "        journal = pd.read_csv(self.silver_path[\"QBO\"][\"Raw\"] / \"JournalEntry.csv\", usecols=[x for x in journal_cols if x not in ['TotalAmt', 'APAccID']])\n",
    "        journal = journal[journal[\"TransactionID_partial\"].isin(report[report[\"TransactionType\"]==\"Journal Entry\"][\"TransactionID_partial\"].unique())]\n",
    "        journal[\"TransactionType\"] = \"Journal Entry\"\n",
    "        journal_map = self._APAR_concat_memo(journal)\n",
    "        # merging and save facts\n",
    "        fact = pd.concat([bill, vc, journal], ignore_index=True)\n",
    "        fact.to_excel(self.gold_path[\"APReporting\"]/\"Facts.xlsx\", index=False, sheet_name = \"Facts\")\n",
    "        # use map table to concate PrivateNote and TransactionEntered into AP Report\n",
    "        fact_map = pd.concat([bill_map, vc_map, journal_map],ignore_index=True)\n",
    "        report2 = pd.merge(report, fact_map, on=[\"TransactionID_partial\", \"TransactionType\"], how=\"left\")\n",
    "        assert len(report) == len(report2), \"After concatenating the TransactionEntered column, duplicated transactionID detected\"\n",
    "        report2.to_excel(self.gold_path[\"APReporting\"]/\"APReport.xlsx\", index=False, sheet_name=\"APReport\")\n",
    "        # save the Vendor and Location table\n",
    "        vendor = pd.read_csv(self.silver_path[\"QBO\"][\"Dimension\"]/\"CSV\"/\"Vendor.csv\")\n",
    "        vendor.to_excel(self.gold_path[\"APReporting\"].parent / \"Vendor.xlsx\", sheet_name = \"Vendor\", index=False)\n",
    "        farm = pd.read_csv(self.silver_path[\"QBO\"][\"Dimension\"]/\"CSV\"/\"Farm.csv\")\n",
    "        farm.to_excel(self.gold_path[\"APReporting\"].parent / \"Location.xlsx\", sheet_name = \"Location\", index=False)\n",
    "        print(\"AP Report Done \\n\")\n",
    "\n",
    "    def _HP_transformation(self) -> None:\n",
    "        \"\"\" \n",
    "            This function transforms the raw data from Harvest Profit in the csv format from Silver space to curated data in Gold space for Power BI\n",
    "        \"\"\"\n",
    "        print(\"\\nTransforming Harvest Profit Data\\n\")\n",
    "        # file paths\n",
    "        silver_path_Delivery_HP = self.silver_path[\"Delivery\"][\"HP\"]\n",
    "        gold_path_inventory = self.gold_path[\"inventory\"]\n",
    "        gold_HP = gold_path_inventory/\"Grain\"\n",
    "        product_path = gold_path_inventory / \"Tables\" / \"commodities_acc.csv\"\n",
    "        folder_fields = silver_path_Delivery_HP / \"Fields\" / \"2025\"\n",
    "        # read raw data\n",
    "        df = pd.read_csv(silver_path_Delivery_HP/f\"Loads_{self.today.year}_{self.today.month}.csv\")\n",
    "        # standardizing df\n",
    "        df_rename = {\"crop\": \"ProductRaw\", \"amount\":\"AmountRaw\", \"accepted_amount\":\"AcceptedAmountRaw\", \"amount_unit\":\"AmountRawUnit\", \"date\":\"TransactionDate\", \"entity_share\":\"LocationRaw\",\n",
    "                    \"contract\":\"ContractRaw\"}\n",
    "        df = df.rename(columns=df_rename)\n",
    "        df[\"TransactionDate\"] = pd.to_datetime(df[\"TransactionDate\"], format=\"%m/%d/%Y %I:%M %p\")\n",
    "        df[\"TransactionDate\"] = df[\"TransactionDate\"].dt.date\n",
    "        # standardize location\n",
    "        df_location_map = {\"MFB Billings - US\": \"Billings\", \"MFS Swift Current - CA\": \"SwiftCurrent\", \"MFH Hafford - CA\": \"Hafford\", \"MFK Kamsack - CA\":\"Kamsack\",\n",
    "                   \"MFR Regina - CA\": \"Regina\", \"MFPAS The Pas - CA\": \"ThePas\", \"MFPA  Prince Albert - CA\":\"PA\", \"MFRAY Raymore - CA\":\"Raymore\", \n",
    "                   \"MFE Eddystone - CA\": \"Eddystone\", \"MFO Outlook - CA\": \"Outlook\", \"MFAIR Airdrie - CA\": \"Airdrie\"}\n",
    "        df[\"Location\"] = df[\"LocationRaw\"].replace(df_location_map)\n",
    "        # compute MT\n",
    "        ## convert Bu to MT for every location excpet Billings where they might have legit Bu measures\n",
    "        # df.loc[((df[\"Location\"]!=\"Billings\")&(df[\"AmountRawUnit\"]==\"Bu\")&(df[\"harvest_profit_id\"]!=1010153)), \"AmountRawUnit\"] = \"Mt\"\n",
    "        bushels = df[df[\"AmountRawUnit\"] == \"Bu\"].copy(deep=True)\n",
    "        ## when units are not Bu\n",
    "        df = df[df[\"AmountRawUnit\"] != \"Bu\"].copy(deep=True)\n",
    "        ## create unit mapping table\n",
    "        units = [\"Lbs\", \"Kg\", \"Mt\"]\n",
    "        divisor = [self.conversion_mt_to_lb, 1000, 1]\n",
    "        mapping_table = pd.DataFrame(data={\"AmountRawUnit\": units, \"divisor\":divisor})\n",
    "        mapping_table = mapping_table.set_index(\"AmountRawUnit\")[\"divisor\"]\n",
    "        ## map mapping table and perform arithmetics\n",
    "        df[\"divisor\"] = df[\"AmountRawUnit\"].map(mapping_table)\n",
    "        df[\"AcceptedAmount\"] = df[\"AcceptedAmountRaw\"] / df[\"divisor\"]\n",
    "        df[\"Amount\"] = df[\"AmountRaw\"] / df[\"divisor\"]\n",
    "        df = df.drop(columns=[\"divisor\"])\n",
    "        ## when units are bushels\n",
    "        bushels[\"Amount\"] = bushels.apply(lambda x: x[\"AmountRaw\"] * self.conversion_bu_to_lb_canola / self.conversion_mt_to_lb if \"canola\" in x[\"ProductRaw\"].lower() \n",
    "                                          else x[\"AmountRaw\"] * self.conversion_bu_to_lb_others / self.conversion_mt_to_lb, axis=1)\n",
    "        bushels[\"AcceptedAmount\"] = bushels.apply(lambda x: x[\"AcceptedAmountRaw\"] * self.conversion_bu_to_lb_canola / self.conversion_mt_to_lb if \"canola\" in x[\"ProductRaw\"].lower() \n",
    "                                                  else x[\"AcceptedAmountRaw\"] * self.conversion_bu_to_lb_others / self.conversion_mt_to_lb, axis=1)\n",
    "        df = pd.concat([df, bushels], ignore_index=True)\n",
    "        # standardizing product - matching with QBO except Uncategorized Lentil\n",
    "        def _create_hp_product_mapping(products:list[str]) -> dict[str,str]:\n",
    "            \"\"\" \n",
    "                This function create mapping ProductRaw -> Product for Harvest Profit, only process strings, ignores missing values\n",
    "            \"\"\"\n",
    "            mapping = {}\n",
    "            for p in products:\n",
    "                if isinstance(p, str):\n",
    "                    p_lower = p.lower()\n",
    "                    if 'green lentil' in p_lower:\n",
    "                        mapping[p] = \"Green Lentil\"\n",
    "                    elif 'red lentil' in p_lower:\n",
    "                        mapping[p] = \"Red Lentil\"\n",
    "                    elif 'lentil' in p_lower:\n",
    "                        mapping[p] = \"Unclassified Lentil\"\n",
    "                    elif 'barley' in p_lower:\n",
    "                        mapping[p] = \"Barley\"\n",
    "                    elif 'canola' in p_lower:\n",
    "                        mapping[p] = \"Canola\"\n",
    "                    elif 'durum' in p_lower:\n",
    "                        mapping[p] = \"Durum\"\n",
    "                    elif 'winter' in p_lower and 'wheat' in p_lower:\n",
    "                        mapping[p] = \"Winter Wheat\"\n",
    "                    elif 'wheat' in p_lower:\n",
    "                        mapping[p] = \"Wheat\"\n",
    "                    elif 'chickpea' in p_lower:\n",
    "                        mapping[p] = \"Chickpea\"\n",
    "                    elif 'pea' in p_lower:\n",
    "                        mapping[p] = \"Field Pea\"\n",
    "                    elif 'carrots' in p_lower:\n",
    "                        mapping[p] = \"Carrots\"\n",
    "                    else:\n",
    "                        mapping[p] = \"Unrecognized\"\n",
    "            return mapping\n",
    "        product_mapping = _create_hp_product_mapping(df.ProductRaw.unique())\n",
    "        df[\"Product\"] = df[\"ProductRaw\"].map(product_mapping)\n",
    "        \n",
    "        # determine transfer mode\n",
    "        \n",
    "        ## use Location + From/To name to match fields_df \n",
    "        df[\"FromExtended\"] = df[\"Location\"] + \"-\" + df[\"from\"].str.strip()\n",
    "        df[\"FromExtended\"] = df[\"FromExtended\"].str.split(\",\").str[0]   # only look at first portion of multiple inputs to determine whether it's harvest records\n",
    "        df[\"ToExtended\"] = df[\"Location\"] + \"-\" + df[\"to\"].str.strip()\n",
    "        \n",
    "        ## create fields df\n",
    "        files = os.listdir(folder_fields)\n",
    "        fields_df = pd.DataFrame()\n",
    "        for f in files:\n",
    "            location = f.split(\".\")[0].split(\"_\")[-1]   # extract the last part (location name) after _ separater before .xlsx suffix\n",
    "            temp = pd.read_excel(folder_fields/f,dtype={\"Field\": str, \"Acres\":float})\n",
    "            temp[\"Location\"] = location\n",
    "            fields_df = pd.concat([fields_df, temp],ignore_index=True)\n",
    "        ### Location + Field to match with HP data\n",
    "        fields_df[\"FieldRaw\"] = fields_df[\"Field\"]\n",
    "        fields_df[\"Field\"] = fields_df[\"Location\"] + \"-\" + fields_df[\"FieldRaw\"]\n",
    "        fields_df.to_csv(gold_HP / \"HPFields.csv\", index=False)\n",
    "        \n",
    "        ## determine whether a load is from field\n",
    "        ### determine if a load is harvest from a field\n",
    "        df[\"FromField\"] = df[\"FromExtended\"].isin(fields_df[\"Field\"].unique())\n",
    "        df[\"ToField\"] = df[\"ToExtended\"].isin(fields_df[\"Field\"].unique())\n",
    "        ### when the load is from field (harvest) and to is missing, flag those loads\n",
    "        df.loc[((df[\"FromField\"])&(df[\"to\"].isna())), \"Flag\"] = \"Harvest with Unknown Destination (Bins)\"\n",
    "        \n",
    "        ## determine whether a load is from/to bins and identify direct deliveries\n",
    "        ### read bins records\n",
    "        bins_df = pd.read_csv(gold_HP / \"HPBins.csv\", dtype={\"Bins\":str, \"Location\":str})\n",
    "        bins_df[\"IsDirect\"] = bins_df[\"Bins\"].str.contains(r\"(?i:direct)|FTC|D\\.C\\.|(?i:hardin)|(?i:huntley)\", regex=True)\n",
    "        bins_df[\"Bins\"] = bins_df[\"Location\"] + \"-\" + bins_df[\"Bins\"]\n",
    "        ### determine load from/to bins\n",
    "        df[\"FromBins\"] = df[\"FromExtended\"].isin(bins_df[~bins_df[\"IsDirect\"]][\"Bins\"].unique())\n",
    "        df[\"ToBins\"] = df[\"ToExtended\"].isin(bins_df[~bins_df[\"IsDirect\"]][\"Bins\"].unique())\n",
    "        ## transfer_mode - applicable for valid records only\n",
    "        ### transfer_mode = Harvest -> FromField==True & ToBins==True\n",
    "        df.loc[(df[\"FromField\"]&df[\"ToBins\"]), \"TransferMode\"] = \"Harvest\"\n",
    "        ### transfer_mode = Sales -> FromBins==True & ToBins==False & ToField==False\n",
    "        df.loc[((df[\"FromBins\"])&(~df[\"ToBins\"])&(~df[\"ToField\"])), \"TransferMode\"] = \"Sales\"\n",
    "        ### transfer_mode = BinTransfer -> FromBins==True & ToBins==True\n",
    "        df.loc[(df[\"FromBins\"]&df[\"ToBins\"]), \"TransferMode\"] = \"BinTransfer\"\n",
    "        ## identify direct deliveries\n",
    "        mask = (\n",
    "            df[\"FromExtended\"].isin(bins_df[bins_df[\"IsDirect\"]].Bins.unique()) | \n",
    "            df[\"ToExtended\"].isin(bins_df[bins_df[\"IsDirect\"]].Bins.unique())\n",
    "\n",
    "        )\n",
    "        df[\"IsDirect\"] = mask \n",
    "        ### in addition, if ToBins==False & FromField==True & to is not missing , this is also direct delivery\n",
    "        df.loc[((df[\"FromField\"])&(df[\"to\"].notna())&(~df[\"ToBins\"])), \"IsDirect\"] = True\n",
    "        ### transfer_mode = Sales -> Direct Delivery\n",
    "        df.loc[df[\"IsDirect\"], \"TransferMode\"] = \"Sales\"\n",
    "        \n",
    "        ## invalid loads\n",
    "        df = df.fillna(value={\"TransferMode\": \"Invalid\"})\n",
    "        df.loc[df[\"TransferMode\"]!=\"Invalid\", \"Flag\"] = \"Valid Loads\"\n",
    "        ### flag invalid loads\n",
    "        #### when both from & to is missing, flag those records\n",
    "        df.loc[((df[\"from\"].isna())&(df[\"to\"].isna())), \"Flag\"] = \"[from] and [to] Unassigned\"\n",
    "        #### when from is missing and to is not a field or a bin, assume those records are to a customer, without stating which inventory it is from\n",
    "        df.loc[((df[\"TransferMode\"]==\"Invalid\")&(df[\"from\"].isna())&(~df[\"ToBins\"])&(df[\"to\"].notna())), \"Flag\"] = \"Deliveries with Unknown Origin (Bins)\"\n",
    "        #### when to is a bin (most likely from harvest), and from is missing\n",
    "        df.loc[((df[\"TransferMode\"]==\"Invalid\")&(df[\"from\"].isna())&(df[\"ToBins\"])), \"Flag\"] = \"Harvest with Unknown Origin (Field)\"\n",
    "        exception = df[df[\"Flag\"].isna()]\n",
    "        if len(exception) != 0:\n",
    "            print(f\"\\nThere are {len(exception)} number of exceptions unaccounted for in \\n{exception.Location.value_counts()}\\n\")\n",
    "        \n",
    "        # create LoadType label to include invalid loads\n",
    "        df.loc[(df[\"IsDirect\"]), \"LoadType\"] = \"Direct Delivery\"\n",
    "        df.loc[(df[\"FromField\"] | df[\"ToBins\"]) & (~df[\"IsDirect\"]), \"LoadType\"] = \"Harvest\"\n",
    "        df.loc[((~(df[\"FromField\"] | df[\"ToBins\"])) & (~df[\"IsDirect\"])&(df[\"to\"].notna())), \"LoadType\"] = \"Delivery from Inventory\"\n",
    "        df.loc[((~(df[\"FromField\"] | df[\"ToBins\"])) & (~df[\"IsDirect\"])&(df[\"to\"].isna())), \"LoadType\"] = \"Undefined Loads\"\n",
    "        df.loc[((~df[\"FromBins\"])&(~df[\"FromField\"])&(df[\"from\"].notna())&(~df[\"IsDirect\"])), \"LoadType\"] = \\\n",
    "            df.loc[((~df[\"FromBins\"])&(~df[\"FromField\"])&(df[\"from\"].notna())&(~df[\"IsDirect\"])), \"TransferMode\"] = \"Not Load\"\n",
    "        df.loc[df[\"TransferMode\"]==\"BinTransfer\", \"LoadType\"] = \"BinTransfer\"\n",
    "\n",
    "        # bin inventory - create a column to store bin no matter if it is from or to a bin\n",
    "        direct_others = df[df[\"LoadType\"].isin([\"Direct Delivery\",\"Undefined Loads\",\"Not Load\",\"BinTransfer\"])].copy(deep=True)\n",
    "        harvest = df[df[\"LoadType\"]==\"Harvest\"].copy(deep=True)\n",
    "        harvest[\"Bin\"] = harvest.loc[harvest[\"ToBins\"], \"to\"]\n",
    "        others = df[df[\"LoadType\"]==\"Delivery from Inventory\"].copy(deep=True)\n",
    "        others[\"Bin\"] = others[\"from\"]\n",
    "        df = pd.concat([harvest, others, direct_others], ignore_index=True)\n",
    "\n",
    "        # create MT monitoring mechanism\n",
    "        ranges = [0, 10, 36, 48, 95, 10000]\n",
    "        ranges_indexer = pd.IntervalIndex.from_arrays(left=ranges[:-1], right=ranges[1:], closed=\"left\")\n",
    "        range_names = np.array([\"Invalid-Small:<10\", \"Unusual-Small:10-36\", \"Valid:36-48\", \"Invalid-Large:48-95\", \"Invalid-Large:>95\"], dtype=str)\n",
    "        amounts_category = ranges_indexer.get_indexer(df[\"AcceptedAmount\"])\n",
    "        assert -1 not in amounts_category, \"Amount MT monitoring detected <0 or >10,000 values\"\n",
    "        df[\"AmountCategory\"] = range_names[amounts_category]\n",
    "        ## for The Pas and Billings, 48 - 95 is valid\n",
    "        df.loc[(df[\"Location\"].isin([\"Billings\",\"ThePas\"])& (df[\"AmountCategory\"]==\"Invalid-Large:48-95\")), \"AmountCategory\"] = \"Valid:48-95\"\n",
    "\n",
    "\n",
    "        # saving\n",
    "        print(f\"Transformed {len(df)} loads, saving ...\")\n",
    "        df.to_csv(gold_HP / \"hp.csv\", index=False)\n",
    "        df.to_excel(gold_HP / \"hp.xlsx\", sheet_name=\"Loads\", index=False)\n",
    "\n",
    "\n",
    "    def run(self, force_run_time:bool=False, force_create_budget:bool=True, force_process_budget_input:bool=False) -> None:\n",
    "        start = perf_counter()\n",
    "\n",
    "        self._process_units()\n",
    "\n",
    "        # pure finance projects\n",
    "        self._weekly_banking()\n",
    "        self._APRporting_project()\n",
    "\n",
    "\n",
    "        # financial operational related projects\n",
    "        self._finance_operational()\n",
    "        self._budget_update(force_create=force_create_budget, force_process_input=force_process_budget_input)\n",
    "        self._finance_summary()\n",
    "\n",
    "        # payroll related\n",
    "        self._payroll_project()\n",
    "        if force_run_time or (self.today.weekday() in [0, 2, 6]): self._QBOTime_project()\n",
    "        self._hr_summary()\n",
    "\n",
    "        # inventory\n",
    "        self._raw_inventory()\n",
    "        self._HP_transformation()\n",
    "\n",
    "        end = perf_counter()\n",
    "        print(f\"\\nProjects Transformation Finished with {(end-start)/60:.3f} minutes\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "701ff93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "self = Projects()\n",
    "gold_HP = self.gold_path[\"inventory\"]/\"Grain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed6e08d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductRaw</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>AmountRaw</th>\n",
       "      <th>AcceptedAmountRaw</th>\n",
       "      <th>AmountRawUnit</th>\n",
       "      <th>details</th>\n",
       "      <th>harvest_profit_id</th>\n",
       "      <th>TransactionDate</th>\n",
       "      <th>truck</th>\n",
       "      <th>...</th>\n",
       "      <th>FromField</th>\n",
       "      <th>ToField</th>\n",
       "      <th>FromBins</th>\n",
       "      <th>ToBins</th>\n",
       "      <th>TransferMode</th>\n",
       "      <th>IsDirect</th>\n",
       "      <th>Flag</th>\n",
       "      <th>LoadType</th>\n",
       "      <th>Bin</th>\n",
       "      <th>AmountCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barley</td>\n",
       "      <td>Tamrack</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59208.90</td>\n",
       "      <td>59208.90</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>983835</td>\n",
       "      <td>2025-08-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>Harvest with Unknown Destination (Bins)</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unusual-Small:10-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barley</td>\n",
       "      <td>Tamrack</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2027.92</td>\n",
       "      <td>2027.92</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>983838</td>\n",
       "      <td>2025-08-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>Harvest with Unknown Destination (Bins)</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Invalid-Small:&lt;10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barley</td>\n",
       "      <td>Tamrack</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27594.41</td>\n",
       "      <td>27594.41</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>991930</td>\n",
       "      <td>2025-08-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>Harvest with Unknown Destination (Bins)</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unusual-Small:10-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Barley</td>\n",
       "      <td>Tamrack</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23603.71</td>\n",
       "      <td>23603.71</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>992098</td>\n",
       "      <td>2025-08-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>Harvest with Unknown Destination (Bins)</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unusual-Small:10-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barley</td>\n",
       "      <td>Tamrack</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50998.35</td>\n",
       "      <td>50998.35</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>992109</td>\n",
       "      <td>2025-08-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>Harvest with Unknown Destination (Bins)</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unusual-Small:10-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18665</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>115 - 3</td>\n",
       "      <td>170-N</td>\n",
       "      <td>-93110.23</td>\n",
       "      <td>-93110.23</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1017469</td>\n",
       "      <td>2025-08-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>BinTransfer</td>\n",
       "      <td>False</td>\n",
       "      <td>Valid Loads</td>\n",
       "      <td>BinTransfer</td>\n",
       "      <td>115 - 3</td>\n",
       "      <td>Valid:36-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18666</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>170-N</td>\n",
       "      <td>170-S</td>\n",
       "      <td>-295304.78</td>\n",
       "      <td>-295304.78</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1018131</td>\n",
       "      <td>2025-08-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>BinTransfer</td>\n",
       "      <td>False</td>\n",
       "      <td>Valid Loads</td>\n",
       "      <td>BinTransfer</td>\n",
       "      <td>170-N</td>\n",
       "      <td>Invalid-Large:&gt;95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18667</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>115 - 1</td>\n",
       "      <td>50 - 3</td>\n",
       "      <td>-99454.94</td>\n",
       "      <td>-99454.94</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1101091</td>\n",
       "      <td>2025-09-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>BinTransfer</td>\n",
       "      <td>False</td>\n",
       "      <td>Valid Loads</td>\n",
       "      <td>BinTransfer</td>\n",
       "      <td>115 - 1</td>\n",
       "      <td>Valid:36-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18668</th>\n",
       "      <td>Canola</td>\n",
       "      <td>Wymark - H 04</td>\n",
       "      <td>Wymark - A 07</td>\n",
       "      <td>-94262.00</td>\n",
       "      <td>-94262.00</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1133512</td>\n",
       "      <td>2025-10-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>BinTransfer</td>\n",
       "      <td>False</td>\n",
       "      <td>Valid Loads</td>\n",
       "      <td>BinTransfer</td>\n",
       "      <td>Wymark - H 04</td>\n",
       "      <td>Valid:36-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18669</th>\n",
       "      <td>Wheat (Hard Red Winter)</td>\n",
       "      <td>FC Bag 14</td>\n",
       "      <td>FC Wheat Seed Cleaned and planted fall 2025</td>\n",
       "      <td>-12000.00</td>\n",
       "      <td>-12000.00</td>\n",
       "      <td>Bu</td>\n",
       "      <td>Cleaned seed</td>\n",
       "      <td>1027883</td>\n",
       "      <td>2025-09-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>BinTransfer</td>\n",
       "      <td>False</td>\n",
       "      <td>Valid Loads</td>\n",
       "      <td>BinTransfer</td>\n",
       "      <td>FC Bag 14</td>\n",
       "      <td>Invalid-Large:&gt;95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18670 rows  41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ProductRaw           from  \\\n",
       "0                       Barley        Tamrack   \n",
       "1                       Barley        Tamrack   \n",
       "2                       Barley        Tamrack   \n",
       "3                       Barley        Tamrack   \n",
       "4                       Barley        Tamrack   \n",
       "...                        ...            ...   \n",
       "18665                    Wheat        115 - 3   \n",
       "18666                    Wheat          170-N   \n",
       "18667                    Wheat        115 - 1   \n",
       "18668                   Canola  Wymark - H 04   \n",
       "18669  Wheat (Hard Red Winter)      FC Bag 14   \n",
       "\n",
       "                                                to  AmountRaw  \\\n",
       "0                                              NaN   59208.90   \n",
       "1                                              NaN    2027.92   \n",
       "2                                              NaN   27594.41   \n",
       "3                                              NaN   23603.71   \n",
       "4                                              NaN   50998.35   \n",
       "...                                            ...        ...   \n",
       "18665                                        170-N  -93110.23   \n",
       "18666                                        170-S -295304.78   \n",
       "18667                                       50 - 3  -99454.94   \n",
       "18668                                Wymark - A 07  -94262.00   \n",
       "18669  FC Wheat Seed Cleaned and planted fall 2025  -12000.00   \n",
       "\n",
       "       AcceptedAmountRaw AmountRawUnit       details  harvest_profit_id  \\\n",
       "0               59208.90           Lbs           NaN             983835   \n",
       "1                2027.92           Lbs           NaN             983838   \n",
       "2               27594.41           Lbs           NaN             991930   \n",
       "3               23603.71           Lbs           NaN             992098   \n",
       "4               50998.35           Lbs           NaN             992109   \n",
       "...                  ...           ...           ...                ...   \n",
       "18665          -93110.23           Lbs           NaN            1017469   \n",
       "18666         -295304.78           Lbs           NaN            1018131   \n",
       "18667          -99454.94           Lbs           NaN            1101091   \n",
       "18668          -94262.00           Lbs           NaN            1133512   \n",
       "18669          -12000.00            Bu  Cleaned seed            1027883   \n",
       "\n",
       "      TransactionDate truck  ... FromField  ToField  FromBins  ToBins  \\\n",
       "0          2025-08-07   NaN  ...      True    False     False   False   \n",
       "1          2025-08-07   NaN  ...      True    False     False   False   \n",
       "2          2025-08-16   NaN  ...      True    False     False   False   \n",
       "3          2025-08-16   NaN  ...      True    False     False   False   \n",
       "4          2025-08-16   NaN  ...      True    False     False   False   \n",
       "...               ...   ...  ...       ...      ...       ...     ...   \n",
       "18665      2025-08-30   NaN  ...     False    False      True    True   \n",
       "18666      2025-08-31   NaN  ...     False    False      True    True   \n",
       "18667      2025-09-08   NaN  ...     False    False      True    True   \n",
       "18668      2025-10-10   NaN  ...     False    False      True    True   \n",
       "18669      2025-09-05   NaN  ...     False    False      True    True   \n",
       "\n",
       "       TransferMode  IsDirect                                     Flag  \\\n",
       "0           Invalid     False  Harvest with Unknown Destination (Bins)   \n",
       "1           Invalid     False  Harvest with Unknown Destination (Bins)   \n",
       "2           Invalid     False  Harvest with Unknown Destination (Bins)   \n",
       "3           Invalid     False  Harvest with Unknown Destination (Bins)   \n",
       "4           Invalid     False  Harvest with Unknown Destination (Bins)   \n",
       "...             ...       ...                                      ...   \n",
       "18665   BinTransfer     False                              Valid Loads   \n",
       "18666   BinTransfer     False                              Valid Loads   \n",
       "18667   BinTransfer     False                              Valid Loads   \n",
       "18668   BinTransfer     False                              Valid Loads   \n",
       "18669   BinTransfer     False                              Valid Loads   \n",
       "\n",
       "          LoadType            Bin       AmountCategory  \n",
       "0          Harvest            NaN  Unusual-Small:10-36  \n",
       "1          Harvest            NaN    Invalid-Small:<10  \n",
       "2          Harvest            NaN  Unusual-Small:10-36  \n",
       "3          Harvest            NaN  Unusual-Small:10-36  \n",
       "4          Harvest            NaN  Unusual-Small:10-36  \n",
       "...            ...            ...                  ...  \n",
       "18665  BinTransfer        115 - 3          Valid:36-48  \n",
       "18666  BinTransfer          170-N    Invalid-Large:>95  \n",
       "18667  BinTransfer        115 - 1          Valid:36-48  \n",
       "18668  BinTransfer  Wymark - H 04          Valid:36-48  \n",
       "18669  BinTransfer      FC Bag 14    Invalid-Large:>95  \n",
       "\n",
       "[18670 rows x 41 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(gold_HP / \"hp.csv\", dtype={\"Bin\":str})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "744ff8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductRaw</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>AmountRaw</th>\n",
       "      <th>AcceptedAmountRaw</th>\n",
       "      <th>AmountRawUnit</th>\n",
       "      <th>details</th>\n",
       "      <th>harvest_profit_id</th>\n",
       "      <th>TransactionDate</th>\n",
       "      <th>truck</th>\n",
       "      <th>...</th>\n",
       "      <th>FromField</th>\n",
       "      <th>ToField</th>\n",
       "      <th>FromBins</th>\n",
       "      <th>ToBins</th>\n",
       "      <th>TransferMode</th>\n",
       "      <th>IsDirect</th>\n",
       "      <th>Flag</th>\n",
       "      <th>LoadType</th>\n",
       "      <th>Bin</th>\n",
       "      <th>AmountCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4533</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>A3</td>\n",
       "      <td>Bag 001 (A3 Bag 1)</td>\n",
       "      <td>8462.12</td>\n",
       "      <td>8462.12</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1012591</td>\n",
       "      <td>2025-08-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Invalid-Small:&lt;10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4534</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>A3</td>\n",
       "      <td>Bag 001 (A3 Bag 1)</td>\n",
       "      <td>39406.37</td>\n",
       "      <td>39406.37</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1012602</td>\n",
       "      <td>2025-08-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unusual-Small:10-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4536</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>A3</td>\n",
       "      <td>Bag 001 (A3 Bag 1)</td>\n",
       "      <td>89500.34</td>\n",
       "      <td>89500.34</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1012675</td>\n",
       "      <td>2025-08-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valid:36-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4541</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>A3</td>\n",
       "      <td>Bag 001 (A3 Bag 1)</td>\n",
       "      <td>2979.64</td>\n",
       "      <td>2979.64</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1012835</td>\n",
       "      <td>2025-08-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Invalid-Small:&lt;10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4542</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>A3</td>\n",
       "      <td>Bag 001 (A3 Bag 1)</td>\n",
       "      <td>58392.73</td>\n",
       "      <td>58392.73</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1012845</td>\n",
       "      <td>2025-08-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unusual-Small:10-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4552</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>A3</td>\n",
       "      <td>Bag 001 (A3 Bag 1)</td>\n",
       "      <td>49975.59</td>\n",
       "      <td>49975.59</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1013197</td>\n",
       "      <td>2025-08-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unusual-Small:10-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4554</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>A3</td>\n",
       "      <td>Bag 001 (A3 Bag 1)</td>\n",
       "      <td>43149.31</td>\n",
       "      <td>43149.31</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1013239</td>\n",
       "      <td>2025-08-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unusual-Small:10-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4557</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>A3</td>\n",
       "      <td>Bag 001 (A3 Bag 1)</td>\n",
       "      <td>61919.65</td>\n",
       "      <td>61919.65</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1013381</td>\n",
       "      <td>2025-08-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unusual-Small:10-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4564</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>A3</td>\n",
       "      <td>Bag 001 (A3 Bag 1)</td>\n",
       "      <td>49295.64</td>\n",
       "      <td>49295.64</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1013557</td>\n",
       "      <td>2025-08-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unusual-Small:10-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4574</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>A1</td>\n",
       "      <td>Bag 002 (A1 Bag 1)</td>\n",
       "      <td>74147.84</td>\n",
       "      <td>74147.84</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1013941</td>\n",
       "      <td>2025-08-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unusual-Small:10-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4588</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>A1</td>\n",
       "      <td>Bag 002 (A1 Bag 1)</td>\n",
       "      <td>101059.60</td>\n",
       "      <td>101059.60</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1014541</td>\n",
       "      <td>2025-08-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valid:36-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4589</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>A1</td>\n",
       "      <td>Bag 002 (A1 Bag 1)</td>\n",
       "      <td>61126.77</td>\n",
       "      <td>61126.77</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1014600</td>\n",
       "      <td>2025-08-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unusual-Small:10-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4592</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>A1</td>\n",
       "      <td>Bag 002 (A1 Bag 1)</td>\n",
       "      <td>96931.51</td>\n",
       "      <td>96931.51</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1014740</td>\n",
       "      <td>2025-08-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valid:36-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>A1</td>\n",
       "      <td>Bag 003 (A1 Bag 2)</td>\n",
       "      <td>44114.37</td>\n",
       "      <td>44114.37</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1014936</td>\n",
       "      <td>2025-08-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unusual-Small:10-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4601</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>A1</td>\n",
       "      <td>Bag 003 (A1 Bag 2)</td>\n",
       "      <td>68915.48</td>\n",
       "      <td>68915.48</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1015055</td>\n",
       "      <td>2025-08-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unusual-Small:10-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4608</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>A1</td>\n",
       "      <td>Bag 003 (A1 Bag 2)</td>\n",
       "      <td>59244.18</td>\n",
       "      <td>59244.18</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1015266</td>\n",
       "      <td>2025-08-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unusual-Small:10-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4610</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>A1</td>\n",
       "      <td>Bag 003 (A1 Bag 2)</td>\n",
       "      <td>26459.93</td>\n",
       "      <td>26459.93</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1015288</td>\n",
       "      <td>2025-08-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unusual-Small:10-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4624</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>A4</td>\n",
       "      <td>Bag 005 (A4 Bag 1)</td>\n",
       "      <td>90289.82</td>\n",
       "      <td>90289.82</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1015732</td>\n",
       "      <td>2025-08-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valid:36-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4805</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>H8</td>\n",
       "      <td>Grains Connect Hafford</td>\n",
       "      <td>98009.63</td>\n",
       "      <td>98009.63</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>Contract: 59720</td>\n",
       "      <td>1025334</td>\n",
       "      <td>2025-09-04</td>\n",
       "      <td>49 Black mack Charlie</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valid:36-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4822</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>H4, H8</td>\n",
       "      <td>Grains Connect Hafford</td>\n",
       "      <td>197594.53</td>\n",
       "      <td>197594.53</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>Contract: 59720</td>\n",
       "      <td>1025649</td>\n",
       "      <td>2025-09-04</td>\n",
       "      <td>86 Jeff</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Invalid-Large:48-95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4824</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>H4</td>\n",
       "      <td>Grains Connect Hafford</td>\n",
       "      <td>95967.55</td>\n",
       "      <td>95967.55</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>Contract: 59720</td>\n",
       "      <td>1025750</td>\n",
       "      <td>2025-09-04</td>\n",
       "      <td>54 Blue Kenworth</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valid:36-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4835</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>H14, H15</td>\n",
       "      <td>Grains Connect Hafford</td>\n",
       "      <td>94443.19</td>\n",
       "      <td>94443.19</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>Contract: 59720</td>\n",
       "      <td>1026054</td>\n",
       "      <td>2025-09-04</td>\n",
       "      <td>86 Jeff</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valid:36-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4840</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>H14, H15</td>\n",
       "      <td>Grains Connect Hafford</td>\n",
       "      <td>96913.44</td>\n",
       "      <td>96913.44</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>Contract: 59720</td>\n",
       "      <td>1026111</td>\n",
       "      <td>2025-09-04</td>\n",
       "      <td>54 Blue Kenworth</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valid:36-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13249</th>\n",
       "      <td>Barley</td>\n",
       "      <td>Heinrichs</td>\n",
       "      <td>NEXGEN-B4</td>\n",
       "      <td>93626.11</td>\n",
       "      <td>93626.11</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1002303</td>\n",
       "      <td>2025-08-23</td>\n",
       "      <td>Truck C 088</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valid:36-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13252</th>\n",
       "      <td>Barley</td>\n",
       "      <td>Heinrichs</td>\n",
       "      <td>NEXGEN-B4</td>\n",
       "      <td>93959.02</td>\n",
       "      <td>93959.02</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1002401</td>\n",
       "      <td>2025-08-23</td>\n",
       "      <td>Truck C 033</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valid:36-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13258</th>\n",
       "      <td>Barley</td>\n",
       "      <td>Heinrichs</td>\n",
       "      <td>NEXGEN-B4</td>\n",
       "      <td>85309.45</td>\n",
       "      <td>85309.45</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1002578</td>\n",
       "      <td>2025-08-23</td>\n",
       "      <td>Truck C 033</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valid:36-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13261</th>\n",
       "      <td>Barley</td>\n",
       "      <td>Heinrichs</td>\n",
       "      <td>NEXGEN-B4</td>\n",
       "      <td>91915.80</td>\n",
       "      <td>91915.80</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1002662</td>\n",
       "      <td>2025-08-23</td>\n",
       "      <td>Truck C 032</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valid:36-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13263</th>\n",
       "      <td>Barley</td>\n",
       "      <td>Heinrichs</td>\n",
       "      <td>NEXGEN-B4</td>\n",
       "      <td>89937.77</td>\n",
       "      <td>89937.77</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1002716</td>\n",
       "      <td>2025-08-23</td>\n",
       "      <td>Truck C 088</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valid:36-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13265</th>\n",
       "      <td>Barley</td>\n",
       "      <td>Heinrichs</td>\n",
       "      <td>NEXGEN-B4</td>\n",
       "      <td>80697.91</td>\n",
       "      <td>80697.91</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1002747</td>\n",
       "      <td>2025-08-23</td>\n",
       "      <td>Truck C 033</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valid:36-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13268</th>\n",
       "      <td>Barley</td>\n",
       "      <td>Heinrichs</td>\n",
       "      <td>NEXGEN-B4</td>\n",
       "      <td>92071.02</td>\n",
       "      <td>92071.02</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1002871</td>\n",
       "      <td>2025-08-23</td>\n",
       "      <td>Truck C 032</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valid:36-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13271</th>\n",
       "      <td>Barley</td>\n",
       "      <td>Heinrichs</td>\n",
       "      <td>NEXGEN-B4</td>\n",
       "      <td>95208.04</td>\n",
       "      <td>95208.04</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1002974</td>\n",
       "      <td>2025-08-23</td>\n",
       "      <td>Truck C 088</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valid:36-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13274</th>\n",
       "      <td>Barley</td>\n",
       "      <td>Heinrichs</td>\n",
       "      <td>NEXGEN-B4</td>\n",
       "      <td>86872.59</td>\n",
       "      <td>86872.59</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1003022</td>\n",
       "      <td>2025-08-23</td>\n",
       "      <td>Truck C 033</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valid:36-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13278</th>\n",
       "      <td>Barley</td>\n",
       "      <td>Heinrichs</td>\n",
       "      <td>NEXGEN-B4</td>\n",
       "      <td>94052.68</td>\n",
       "      <td>94052.68</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1003128</td>\n",
       "      <td>2025-08-23</td>\n",
       "      <td>Truck C 032</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valid:36-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13280</th>\n",
       "      <td>Barley</td>\n",
       "      <td>Heinrichs</td>\n",
       "      <td>NEXGEN-B4</td>\n",
       "      <td>94805.38</td>\n",
       "      <td>94805.38</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1003161</td>\n",
       "      <td>2025-08-23</td>\n",
       "      <td>Truck C 088</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valid:36-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13316</th>\n",
       "      <td>Barley</td>\n",
       "      <td>Peters</td>\n",
       "      <td>NEXGEN-B1</td>\n",
       "      <td>88416.37</td>\n",
       "      <td>88416.37</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1004589</td>\n",
       "      <td>2025-08-24</td>\n",
       "      <td>Truck C 013</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valid:36-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13317</th>\n",
       "      <td>Barley</td>\n",
       "      <td>Peters</td>\n",
       "      <td>NEXGEN-B1</td>\n",
       "      <td>88700.72</td>\n",
       "      <td>88700.72</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1004679</td>\n",
       "      <td>2025-08-24</td>\n",
       "      <td>Truck C 009</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valid:36-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13318</th>\n",
       "      <td>Barley</td>\n",
       "      <td>Peters</td>\n",
       "      <td>NEXGEN-B1</td>\n",
       "      <td>92578.98</td>\n",
       "      <td>92578.98</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1004718</td>\n",
       "      <td>2025-08-24</td>\n",
       "      <td>Truck C 013</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valid:36-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13319</th>\n",
       "      <td>Barley</td>\n",
       "      <td>Peters</td>\n",
       "      <td>NEXGEN-B1</td>\n",
       "      <td>92471.22</td>\n",
       "      <td>92471.22</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1004720</td>\n",
       "      <td>2025-08-24</td>\n",
       "      <td>Truck C 007</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valid:36-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13320</th>\n",
       "      <td>Barley</td>\n",
       "      <td>Peters</td>\n",
       "      <td>NEXGEN-B1</td>\n",
       "      <td>12277.58</td>\n",
       "      <td>12277.58</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1004721</td>\n",
       "      <td>2025-08-24</td>\n",
       "      <td>Truck C 009</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Invalid-Small:&lt;10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14019</th>\n",
       "      <td>Wheat (Durum)</td>\n",
       "      <td>W.Villlage</td>\n",
       "      <td>NEXGEN-B2</td>\n",
       "      <td>98724.05</td>\n",
       "      <td>98724.05</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1034723</td>\n",
       "      <td>2025-09-09</td>\n",
       "      <td>Truck C 013</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valid:36-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14020</th>\n",
       "      <td>Wheat (Durum)</td>\n",
       "      <td>E.Village</td>\n",
       "      <td>NEXGEN-B2</td>\n",
       "      <td>93866.78</td>\n",
       "      <td>93866.78</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1034728</td>\n",
       "      <td>2025-09-09</td>\n",
       "      <td>Truck C 009</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valid:36-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14021</th>\n",
       "      <td>Wheat (Durum)</td>\n",
       "      <td>E.Village</td>\n",
       "      <td>NEXGEN-B2</td>\n",
       "      <td>13518.36</td>\n",
       "      <td>13518.36</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1034730</td>\n",
       "      <td>2025-09-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Invalid-Small:&lt;10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14022</th>\n",
       "      <td>Wheat (Durum)</td>\n",
       "      <td>W.Villlage</td>\n",
       "      <td>NEXGEN-B2</td>\n",
       "      <td>33011.63</td>\n",
       "      <td>33011.63</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1034743</td>\n",
       "      <td>2025-09-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unusual-Small:10-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14023</th>\n",
       "      <td>Wheat (Durum)</td>\n",
       "      <td>W.Villlage</td>\n",
       "      <td>NEXGEN-B2</td>\n",
       "      <td>45812.60</td>\n",
       "      <td>45812.60</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1034754</td>\n",
       "      <td>2025-09-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unusual-Small:10-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14026</th>\n",
       "      <td>Wheat (Durum)</td>\n",
       "      <td>E.Village, W.Villlage</td>\n",
       "      <td>NEXGEN-B2</td>\n",
       "      <td>29896.19</td>\n",
       "      <td>29896.19</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1034908</td>\n",
       "      <td>2025-09-09</td>\n",
       "      <td>Truck C 009</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unusual-Small:10-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14029</th>\n",
       "      <td>Wheat (Durum)</td>\n",
       "      <td>W.Villlage</td>\n",
       "      <td>NEXGEN-B2</td>\n",
       "      <td>94257.37</td>\n",
       "      <td>94257.37</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1035083</td>\n",
       "      <td>2025-09-09</td>\n",
       "      <td>Truck C 033</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valid:36-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14034</th>\n",
       "      <td>Wheat (Durum)</td>\n",
       "      <td>E.Village, W.Villlage</td>\n",
       "      <td>NEXGEN-B2</td>\n",
       "      <td>93951.58</td>\n",
       "      <td>93951.58</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1035272</td>\n",
       "      <td>2025-09-09</td>\n",
       "      <td>Truck C 015</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valid:36-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14044</th>\n",
       "      <td>Wheat (Durum)</td>\n",
       "      <td>E.Village</td>\n",
       "      <td>NEXGEN-B2</td>\n",
       "      <td>94761.21</td>\n",
       "      <td>94761.21</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1035528</td>\n",
       "      <td>2025-09-09</td>\n",
       "      <td>Truck C 007</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valid:36-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14045</th>\n",
       "      <td>Wheat (Durum)</td>\n",
       "      <td>W.Villlage</td>\n",
       "      <td>NEXGEN-B2</td>\n",
       "      <td>78475.11</td>\n",
       "      <td>78475.11</td>\n",
       "      <td>Lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1035529</td>\n",
       "      <td>2025-09-09</td>\n",
       "      <td>Truck C 088</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unusual-Small:10-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18029</th>\n",
       "      <td>Canola</td>\n",
       "      <td>C1</td>\n",
       "      <td>Cargill Crush Clavet</td>\n",
       "      <td>41645.00</td>\n",
       "      <td>41103.62</td>\n",
       "      <td>Kg</td>\n",
       "      <td>Ticket 1195846</td>\n",
       "      <td>1163963</td>\n",
       "      <td>2025-10-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Not Load</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Load</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valid:36-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18625</th>\n",
       "      <td>Large Green Lentils</td>\n",
       "      <td>South - A 1</td>\n",
       "      <td>DG Global</td>\n",
       "      <td>44000.00</td>\n",
       "      <td>44000.00</td>\n",
       "      <td>Kg</td>\n",
       "      <td>Ticket 07-1-030372</td>\n",
       "      <td>1159991</td>\n",
       "      <td>2025-10-14</td>\n",
       "      <td>Bickner</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Not Load</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Load</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valid:36-48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51 rows  41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ProductRaw                   from                      to  \\\n",
       "4533                 Wheat                     A3      Bag 001 (A3 Bag 1)   \n",
       "4534                 Wheat                     A3      Bag 001 (A3 Bag 1)   \n",
       "4536                 Wheat                     A3      Bag 001 (A3 Bag 1)   \n",
       "4541                 Wheat                     A3      Bag 001 (A3 Bag 1)   \n",
       "4542                 Wheat                     A3      Bag 001 (A3 Bag 1)   \n",
       "4552                 Wheat                     A3      Bag 001 (A3 Bag 1)   \n",
       "4554                 Wheat                     A3      Bag 001 (A3 Bag 1)   \n",
       "4557                 Wheat                     A3      Bag 001 (A3 Bag 1)   \n",
       "4564                 Wheat                     A3      Bag 001 (A3 Bag 1)   \n",
       "4574                 Wheat                     A1      Bag 002 (A1 Bag 1)   \n",
       "4588                 Wheat                     A1      Bag 002 (A1 Bag 1)   \n",
       "4589                 Wheat                     A1      Bag 002 (A1 Bag 1)   \n",
       "4592                 Wheat                     A1      Bag 002 (A1 Bag 1)   \n",
       "4598                 Wheat                     A1      Bag 003 (A1 Bag 2)   \n",
       "4601                 Wheat                     A1      Bag 003 (A1 Bag 2)   \n",
       "4608                 Wheat                     A1      Bag 003 (A1 Bag 2)   \n",
       "4610                 Wheat                     A1      Bag 003 (A1 Bag 2)   \n",
       "4624                 Wheat                     A4      Bag 005 (A4 Bag 1)   \n",
       "4805                 Wheat                     H8  Grains Connect Hafford   \n",
       "4822                 Wheat                 H4, H8  Grains Connect Hafford   \n",
       "4824                 Wheat                     H4  Grains Connect Hafford   \n",
       "4835                 Wheat               H14, H15  Grains Connect Hafford   \n",
       "4840                 Wheat               H14, H15  Grains Connect Hafford   \n",
       "13249               Barley              Heinrichs               NEXGEN-B4   \n",
       "13252               Barley              Heinrichs               NEXGEN-B4   \n",
       "13258               Barley              Heinrichs               NEXGEN-B4   \n",
       "13261               Barley              Heinrichs               NEXGEN-B4   \n",
       "13263               Barley              Heinrichs               NEXGEN-B4   \n",
       "13265               Barley              Heinrichs               NEXGEN-B4   \n",
       "13268               Barley              Heinrichs               NEXGEN-B4   \n",
       "13271               Barley              Heinrichs               NEXGEN-B4   \n",
       "13274               Barley              Heinrichs               NEXGEN-B4   \n",
       "13278               Barley              Heinrichs               NEXGEN-B4   \n",
       "13280               Barley              Heinrichs               NEXGEN-B4   \n",
       "13316               Barley                 Peters               NEXGEN-B1   \n",
       "13317               Barley                 Peters               NEXGEN-B1   \n",
       "13318               Barley                 Peters               NEXGEN-B1   \n",
       "13319               Barley                 Peters               NEXGEN-B1   \n",
       "13320               Barley                 Peters               NEXGEN-B1   \n",
       "14019        Wheat (Durum)             W.Villlage               NEXGEN-B2   \n",
       "14020        Wheat (Durum)              E.Village               NEXGEN-B2   \n",
       "14021        Wheat (Durum)              E.Village               NEXGEN-B2   \n",
       "14022        Wheat (Durum)             W.Villlage               NEXGEN-B2   \n",
       "14023        Wheat (Durum)             W.Villlage               NEXGEN-B2   \n",
       "14026        Wheat (Durum)  E.Village, W.Villlage               NEXGEN-B2   \n",
       "14029        Wheat (Durum)             W.Villlage               NEXGEN-B2   \n",
       "14034        Wheat (Durum)  E.Village, W.Villlage               NEXGEN-B2   \n",
       "14044        Wheat (Durum)              E.Village               NEXGEN-B2   \n",
       "14045        Wheat (Durum)             W.Villlage               NEXGEN-B2   \n",
       "18029               Canola                     C1    Cargill Crush Clavet   \n",
       "18625  Large Green Lentils            South - A 1               DG Global   \n",
       "\n",
       "       AmountRaw  AcceptedAmountRaw AmountRawUnit             details  \\\n",
       "4533     8462.12            8462.12           Lbs                 NaN   \n",
       "4534    39406.37           39406.37           Lbs                 NaN   \n",
       "4536    89500.34           89500.34           Lbs                 NaN   \n",
       "4541     2979.64            2979.64           Lbs                 NaN   \n",
       "4542    58392.73           58392.73           Lbs                 NaN   \n",
       "4552    49975.59           49975.59           Lbs                 NaN   \n",
       "4554    43149.31           43149.31           Lbs                 NaN   \n",
       "4557    61919.65           61919.65           Lbs                 NaN   \n",
       "4564    49295.64           49295.64           Lbs                 NaN   \n",
       "4574    74147.84           74147.84           Lbs                 NaN   \n",
       "4588   101059.60          101059.60           Lbs                 NaN   \n",
       "4589    61126.77           61126.77           Lbs                 NaN   \n",
       "4592    96931.51           96931.51           Lbs                 NaN   \n",
       "4598    44114.37           44114.37           Lbs                 NaN   \n",
       "4601    68915.48           68915.48           Lbs                 NaN   \n",
       "4608    59244.18           59244.18           Lbs                 NaN   \n",
       "4610    26459.93           26459.93           Lbs                 NaN   \n",
       "4624    90289.82           90289.82           Lbs                 NaN   \n",
       "4805    98009.63           98009.63           Lbs     Contract: 59720   \n",
       "4822   197594.53          197594.53           Lbs     Contract: 59720   \n",
       "4824    95967.55           95967.55           Lbs     Contract: 59720   \n",
       "4835    94443.19           94443.19           Lbs     Contract: 59720   \n",
       "4840    96913.44           96913.44           Lbs     Contract: 59720   \n",
       "13249   93626.11           93626.11           Lbs                 NaN   \n",
       "13252   93959.02           93959.02           Lbs                 NaN   \n",
       "13258   85309.45           85309.45           Lbs                 NaN   \n",
       "13261   91915.80           91915.80           Lbs                 NaN   \n",
       "13263   89937.77           89937.77           Lbs                 NaN   \n",
       "13265   80697.91           80697.91           Lbs                 NaN   \n",
       "13268   92071.02           92071.02           Lbs                 NaN   \n",
       "13271   95208.04           95208.04           Lbs                 NaN   \n",
       "13274   86872.59           86872.59           Lbs                 NaN   \n",
       "13278   94052.68           94052.68           Lbs                 NaN   \n",
       "13280   94805.38           94805.38           Lbs                 NaN   \n",
       "13316   88416.37           88416.37           Lbs                 NaN   \n",
       "13317   88700.72           88700.72           Lbs                 NaN   \n",
       "13318   92578.98           92578.98           Lbs                 NaN   \n",
       "13319   92471.22           92471.22           Lbs                 NaN   \n",
       "13320   12277.58           12277.58           Lbs                 NaN   \n",
       "14019   98724.05           98724.05           Lbs                 NaN   \n",
       "14020   93866.78           93866.78           Lbs                 NaN   \n",
       "14021   13518.36           13518.36           Lbs                 NaN   \n",
       "14022   33011.63           33011.63           Lbs                 NaN   \n",
       "14023   45812.60           45812.60           Lbs                 NaN   \n",
       "14026   29896.19           29896.19           Lbs                 NaN   \n",
       "14029   94257.37           94257.37           Lbs                 NaN   \n",
       "14034   93951.58           93951.58           Lbs                 NaN   \n",
       "14044   94761.21           94761.21           Lbs                 NaN   \n",
       "14045   78475.11           78475.11           Lbs                 NaN   \n",
       "18029   41645.00           41103.62            Kg      Ticket 1195846   \n",
       "18625   44000.00           44000.00            Kg  Ticket 07-1-030372   \n",
       "\n",
       "       harvest_profit_id TransactionDate                  truck  ...  \\\n",
       "4533             1012591      2025-08-28                    NaN  ...   \n",
       "4534             1012602      2025-08-28                    NaN  ...   \n",
       "4536             1012675      2025-08-28                    NaN  ...   \n",
       "4541             1012835      2025-08-28                    NaN  ...   \n",
       "4542             1012845      2025-08-28                    NaN  ...   \n",
       "4552             1013197      2025-08-28                    NaN  ...   \n",
       "4554             1013239      2025-08-28                    NaN  ...   \n",
       "4557             1013381      2025-08-28                    NaN  ...   \n",
       "4564             1013557      2025-08-28                    NaN  ...   \n",
       "4574             1013941      2025-08-28                    NaN  ...   \n",
       "4588             1014541      2025-08-29                    NaN  ...   \n",
       "4589             1014600      2025-08-29                    NaN  ...   \n",
       "4592             1014740      2025-08-29                    NaN  ...   \n",
       "4598             1014936      2025-08-29                    NaN  ...   \n",
       "4601             1015055      2025-08-29                    NaN  ...   \n",
       "4608             1015266      2025-08-29                    NaN  ...   \n",
       "4610             1015288      2025-08-29                    NaN  ...   \n",
       "4624             1015732      2025-08-29                    NaN  ...   \n",
       "4805             1025334      2025-09-04  49 Black mack Charlie  ...   \n",
       "4822             1025649      2025-09-04                86 Jeff  ...   \n",
       "4824             1025750      2025-09-04       54 Blue Kenworth  ...   \n",
       "4835             1026054      2025-09-04                86 Jeff  ...   \n",
       "4840             1026111      2025-09-04       54 Blue Kenworth  ...   \n",
       "13249            1002303      2025-08-23            Truck C 088  ...   \n",
       "13252            1002401      2025-08-23            Truck C 033  ...   \n",
       "13258            1002578      2025-08-23            Truck C 033  ...   \n",
       "13261            1002662      2025-08-23            Truck C 032  ...   \n",
       "13263            1002716      2025-08-23            Truck C 088  ...   \n",
       "13265            1002747      2025-08-23            Truck C 033  ...   \n",
       "13268            1002871      2025-08-23            Truck C 032  ...   \n",
       "13271            1002974      2025-08-23            Truck C 088  ...   \n",
       "13274            1003022      2025-08-23            Truck C 033  ...   \n",
       "13278            1003128      2025-08-23            Truck C 032  ...   \n",
       "13280            1003161      2025-08-23            Truck C 088  ...   \n",
       "13316            1004589      2025-08-24            Truck C 013  ...   \n",
       "13317            1004679      2025-08-24            Truck C 009  ...   \n",
       "13318            1004718      2025-08-24            Truck C 013  ...   \n",
       "13319            1004720      2025-08-24            Truck C 007  ...   \n",
       "13320            1004721      2025-08-24            Truck C 009  ...   \n",
       "14019            1034723      2025-09-09            Truck C 013  ...   \n",
       "14020            1034728      2025-09-09            Truck C 009  ...   \n",
       "14021            1034730      2025-09-09                    NaN  ...   \n",
       "14022            1034743      2025-09-09                    NaN  ...   \n",
       "14023            1034754      2025-09-09                    NaN  ...   \n",
       "14026            1034908      2025-09-09            Truck C 009  ...   \n",
       "14029            1035083      2025-09-09            Truck C 033  ...   \n",
       "14034            1035272      2025-09-09            Truck C 015  ...   \n",
       "14044            1035528      2025-09-09            Truck C 007  ...   \n",
       "14045            1035529      2025-09-09            Truck C 088  ...   \n",
       "18029            1163963      2025-10-06                    NaN  ...   \n",
       "18625            1159991      2025-10-14                Bickner  ...   \n",
       "\n",
       "      FromField  ToField  FromBins  ToBins  TransferMode  IsDirect  Flag  \\\n",
       "4533       True    False     False   False       Invalid     False   NaN   \n",
       "4534       True    False     False   False       Invalid     False   NaN   \n",
       "4536       True    False     False   False       Invalid     False   NaN   \n",
       "4541       True    False     False   False       Invalid     False   NaN   \n",
       "4542       True    False     False   False       Invalid     False   NaN   \n",
       "4552       True    False     False   False       Invalid     False   NaN   \n",
       "4554       True    False     False   False       Invalid     False   NaN   \n",
       "4557       True    False     False   False       Invalid     False   NaN   \n",
       "4564       True    False     False   False       Invalid     False   NaN   \n",
       "4574       True    False     False   False       Invalid     False   NaN   \n",
       "4588       True    False     False   False       Invalid     False   NaN   \n",
       "4589       True    False     False   False       Invalid     False   NaN   \n",
       "4592       True    False     False   False       Invalid     False   NaN   \n",
       "4598       True    False     False   False       Invalid     False   NaN   \n",
       "4601       True    False     False   False       Invalid     False   NaN   \n",
       "4608       True    False     False   False       Invalid     False   NaN   \n",
       "4610       True    False     False   False       Invalid     False   NaN   \n",
       "4624       True    False     False   False       Invalid     False   NaN   \n",
       "4805       True    False     False   False       Invalid     False   NaN   \n",
       "4822       True    False     False   False       Invalid     False   NaN   \n",
       "4824       True    False     False   False       Invalid     False   NaN   \n",
       "4835       True    False     False   False       Invalid     False   NaN   \n",
       "4840       True    False     False   False       Invalid     False   NaN   \n",
       "13249      True    False     False   False       Invalid     False   NaN   \n",
       "13252      True    False     False   False       Invalid     False   NaN   \n",
       "13258      True    False     False   False       Invalid     False   NaN   \n",
       "13261      True    False     False   False       Invalid     False   NaN   \n",
       "13263      True    False     False   False       Invalid     False   NaN   \n",
       "13265      True    False     False   False       Invalid     False   NaN   \n",
       "13268      True    False     False   False       Invalid     False   NaN   \n",
       "13271      True    False     False   False       Invalid     False   NaN   \n",
       "13274      True    False     False   False       Invalid     False   NaN   \n",
       "13278      True    False     False   False       Invalid     False   NaN   \n",
       "13280      True    False     False   False       Invalid     False   NaN   \n",
       "13316      True    False     False   False       Invalid     False   NaN   \n",
       "13317      True    False     False   False       Invalid     False   NaN   \n",
       "13318      True    False     False   False       Invalid     False   NaN   \n",
       "13319      True    False     False   False       Invalid     False   NaN   \n",
       "13320      True    False     False   False       Invalid     False   NaN   \n",
       "14019      True    False     False   False       Invalid     False   NaN   \n",
       "14020      True    False     False   False       Invalid     False   NaN   \n",
       "14021      True    False     False   False       Invalid     False   NaN   \n",
       "14022      True    False     False   False       Invalid     False   NaN   \n",
       "14023      True    False     False   False       Invalid     False   NaN   \n",
       "14026      True    False     False   False       Invalid     False   NaN   \n",
       "14029      True    False     False   False       Invalid     False   NaN   \n",
       "14034      True    False     False   False       Invalid     False   NaN   \n",
       "14044      True    False     False   False       Invalid     False   NaN   \n",
       "14045      True    False     False   False       Invalid     False   NaN   \n",
       "18029     False    False     False   False      Not Load     False   NaN   \n",
       "18625     False    False     False   False      Not Load     False   NaN   \n",
       "\n",
       "       LoadType  Bin       AmountCategory  \n",
       "4533    Harvest  NaN    Invalid-Small:<10  \n",
       "4534    Harvest  NaN  Unusual-Small:10-36  \n",
       "4536    Harvest  NaN          Valid:36-48  \n",
       "4541    Harvest  NaN    Invalid-Small:<10  \n",
       "4542    Harvest  NaN  Unusual-Small:10-36  \n",
       "4552    Harvest  NaN  Unusual-Small:10-36  \n",
       "4554    Harvest  NaN  Unusual-Small:10-36  \n",
       "4557    Harvest  NaN  Unusual-Small:10-36  \n",
       "4564    Harvest  NaN  Unusual-Small:10-36  \n",
       "4574    Harvest  NaN  Unusual-Small:10-36  \n",
       "4588    Harvest  NaN          Valid:36-48  \n",
       "4589    Harvest  NaN  Unusual-Small:10-36  \n",
       "4592    Harvest  NaN          Valid:36-48  \n",
       "4598    Harvest  NaN  Unusual-Small:10-36  \n",
       "4601    Harvest  NaN  Unusual-Small:10-36  \n",
       "4608    Harvest  NaN  Unusual-Small:10-36  \n",
       "4610    Harvest  NaN  Unusual-Small:10-36  \n",
       "4624    Harvest  NaN          Valid:36-48  \n",
       "4805    Harvest  NaN          Valid:36-48  \n",
       "4822    Harvest  NaN  Invalid-Large:48-95  \n",
       "4824    Harvest  NaN          Valid:36-48  \n",
       "4835    Harvest  NaN          Valid:36-48  \n",
       "4840    Harvest  NaN          Valid:36-48  \n",
       "13249   Harvest  NaN          Valid:36-48  \n",
       "13252   Harvest  NaN          Valid:36-48  \n",
       "13258   Harvest  NaN          Valid:36-48  \n",
       "13261   Harvest  NaN          Valid:36-48  \n",
       "13263   Harvest  NaN          Valid:36-48  \n",
       "13265   Harvest  NaN          Valid:36-48  \n",
       "13268   Harvest  NaN          Valid:36-48  \n",
       "13271   Harvest  NaN          Valid:36-48  \n",
       "13274   Harvest  NaN          Valid:36-48  \n",
       "13278   Harvest  NaN          Valid:36-48  \n",
       "13280   Harvest  NaN          Valid:36-48  \n",
       "13316   Harvest  NaN          Valid:36-48  \n",
       "13317   Harvest  NaN          Valid:36-48  \n",
       "13318   Harvest  NaN          Valid:36-48  \n",
       "13319   Harvest  NaN          Valid:36-48  \n",
       "13320   Harvest  NaN    Invalid-Small:<10  \n",
       "14019   Harvest  NaN          Valid:36-48  \n",
       "14020   Harvest  NaN          Valid:36-48  \n",
       "14021   Harvest  NaN    Invalid-Small:<10  \n",
       "14022   Harvest  NaN  Unusual-Small:10-36  \n",
       "14023   Harvest  NaN  Unusual-Small:10-36  \n",
       "14026   Harvest  NaN  Unusual-Small:10-36  \n",
       "14029   Harvest  NaN          Valid:36-48  \n",
       "14034   Harvest  NaN          Valid:36-48  \n",
       "14044   Harvest  NaN          Valid:36-48  \n",
       "14045   Harvest  NaN  Unusual-Small:10-36  \n",
       "18029  Not Load  NaN          Valid:36-48  \n",
       "18625  Not Load  NaN          Valid:36-48  \n",
       "\n",
       "[51 rows x 41 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = df[((df[\"Flag\"].isna()))]\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a7c73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e68cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33df4ded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bf39f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92a2123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668388d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a87d77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1efea71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfb0548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d595208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77111ede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa9ecc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912b61dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1fc61c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45a14af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a11d97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3dbdbe48",
   "metadata": {},
   "source": [
    "# QBOETL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8b58f2",
   "metadata": {},
   "source": [
    "## New Cube Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eafe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_names = [\"MFUSA\", \"MFAZ\", \"MSUSA\", \"MPUSA\"] + [\"MSL\", \"NexGen\", \"MFBC\", \"MPL\", \"MFL\"]\n",
    "def _raw_split_name(accname: str):\n",
    "    \"\"\" \n",
    "        helper function for formatting cube file, split a full account name into corp + accnum + accname if the name is a legit accname\n",
    "            the return list is formatted as [is_acc, corp, accnum, accname], -1 is used when it is not an actual account\n",
    "            expected actual accname to have this format: 'MFL 000000 Sales'\n",
    "    \"\"\"\n",
    "    name_list = accname.split(\" \")\n",
    "    if len(name_list) < 3:\n",
    "        return False, -1, -1, -1\n",
    "    if (name_list[0] in company_names) and (len(name_list[1]) == 6) and (name_list[1].isnumeric()):\n",
    "        return True, name_list[0], name_list[1], accname[len((\" \".join(name_list[:2])))+1:]\n",
    "    return False, -1, -1, -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a39bec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 'MSL', '401423', 'Raw Small Chickpeas - No. 3')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_raw_split_name(\"MSL 401423 Raw Small Chickpeas - No. 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb85b7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monette Farms Dimensions Sep 15, 2025.xlsx'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cube_file = [name for name in os.listdir(\".\") if \".xlsx\" in name]\n",
    "assert len(cube_file) == 1, \"multiple cube files detected\"\n",
    "cube_file = cube_file[0]\n",
    "cube_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51e952f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>child</th>\n",
       "      <th>parent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Account</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Income Statement</td>\n",
       "      <td>Account</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sales Revenue</td>\n",
       "      <td>Income Statement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Grain Revenue</td>\n",
       "      <td>Sales Revenue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Grain - cash settlements</td>\n",
       "      <td>Grain Revenue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4365</th>\n",
       "      <td>MFL - Bank Indebtedness</td>\n",
       "      <td>Cube Staff - DNU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4366</th>\n",
       "      <td>MFL 110000 ICU Business Account</td>\n",
       "      <td>MFL - Bank Indebtedness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4367</th>\n",
       "      <td>MFL 110200 Scotiabank Business Account</td>\n",
       "      <td>MFL - Bank Indebtedness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4368</th>\n",
       "      <td>MFL 121900 Undeposited Funds</td>\n",
       "      <td>MFL - Bank Indebtedness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4369</th>\n",
       "      <td>Retained Earnings Adjustment</td>\n",
       "      <td>Account</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4370 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       child                   parent\n",
       "0                                    Account                      NaN\n",
       "1                           Income Statement                  Account\n",
       "2                              Sales Revenue         Income Statement\n",
       "3                              Grain Revenue            Sales Revenue\n",
       "4                   Grain - cash settlements            Grain Revenue\n",
       "...                                      ...                      ...\n",
       "4365                 MFL - Bank Indebtedness         Cube Staff - DNU\n",
       "4366         MFL 110000 ICU Business Account  MFL - Bank Indebtedness\n",
       "4367  MFL 110200 Scotiabank Business Account  MFL - Bank Indebtedness\n",
       "4368            MFL 121900 Undeposited Funds  MFL - Bank Indebtedness\n",
       "4369            Retained Earnings Adjustment                  Account\n",
       "\n",
       "[4370 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mixed child - parent relationships, includes: account -> subcategory; account -> category; subcategory -> category; category -> profittype; .... \n",
    "maps = pd.read_excel(cube_file,sheet_name=\"Account\",usecols=[\"Current Name\", \"Parent Dimension Member\"])\n",
    "maps = maps.rename(columns={\"Current Name\":\"child\", \"Parent Dimension Member\":\"parent\"})\n",
    "maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7402f8cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>child</th>\n",
       "      <th>parent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seed Processing</td>\n",
       "      <td>Sales Revenue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSL Grain Sales</td>\n",
       "      <td>Seed Processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSL Grain Sales - Raw Grain</td>\n",
       "      <td>MSL Grain Sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MSL 401000 Raw Grain</td>\n",
       "      <td>MSL Grain Sales - Raw Grain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MSL Grain Sales - Raw Grain - Large Green Lentils</td>\n",
       "      <td>MSL Grain Sales - Raw Grain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MSL 401110 Grain Sales - Raw Grain - Green Len...</td>\n",
       "      <td>MSL Grain Sales - Raw Grain - Large Green Lentils</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MSL 401111 Raw Green Lentils - Large Green - N...</td>\n",
       "      <td>MSL 401110 Grain Sales - Raw Grain - Green Len...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MSL 401112 Raw Green Lentils - Large Green - N...</td>\n",
       "      <td>MSL 401110 Grain Sales - Raw Grain - Green Len...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MSL 401113 Raw Green Lentils - Large Green - N...</td>\n",
       "      <td>MSL 401110 Grain Sales - Raw Grain - Green Len...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MSL 401114 Raw Green Lentils - Large Green - E...</td>\n",
       "      <td>MSL 401110 Grain Sales - Raw Grain - Green Len...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MSL 401120 Grain Sales - Raw Grain - Green Len...</td>\n",
       "      <td>MSL Grain Sales - Raw Grain - Large Green Lentils</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MSL 401121 Raw Green Lentils - Small Green - N...</td>\n",
       "      <td>MSL 401120 Grain Sales - Raw Grain - Green Len...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MSL 401122 Raw Green Lentils - Small Green - N...</td>\n",
       "      <td>MSL 401120 Grain Sales - Raw Grain - Green Len...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MSL 401123 Raw Green Lentils - Small Green - N...</td>\n",
       "      <td>MSL 401120 Grain Sales - Raw Grain - Green Len...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MSL 401124 Raw Green Lentils - Small Green - E...</td>\n",
       "      <td>MSL 401120 Grain Sales - Raw Grain - Green Len...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MSL Grain Sales - Raw Grain - Red Lentils</td>\n",
       "      <td>MSL Grain Sales - Raw Grain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MSL 401201 Raw Red Lentils - No. 1</td>\n",
       "      <td>MSL Grain Sales - Raw Grain - Red Lentils</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MSL 401202 Raw Red Lentils - No. 2</td>\n",
       "      <td>MSL Grain Sales - Raw Grain - Red Lentils</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MSL 401203 Raw Red Lentils - No. 3</td>\n",
       "      <td>MSL Grain Sales - Raw Grain - Red Lentils</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MSL 401204 Raw Red Lentils - Extra No. 3</td>\n",
       "      <td>MSL Grain Sales - Raw Grain - Red Lentils</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MSL Grain Sales - Raw Grain - Mixed Lentils</td>\n",
       "      <td>MSL Grain Sales - Raw Grain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MSL Grain Sales - Raw Grain - Chickpeas</td>\n",
       "      <td>MSL Grain Sales - Raw Grain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                child  \\\n",
       "0                                     Seed Processing   \n",
       "1                                     MSL Grain Sales   \n",
       "2                         MSL Grain Sales - Raw Grain   \n",
       "3                                MSL 401000 Raw Grain   \n",
       "4   MSL Grain Sales - Raw Grain - Large Green Lentils   \n",
       "5   MSL 401110 Grain Sales - Raw Grain - Green Len...   \n",
       "6   MSL 401111 Raw Green Lentils - Large Green - N...   \n",
       "7   MSL 401112 Raw Green Lentils - Large Green - N...   \n",
       "8   MSL 401113 Raw Green Lentils - Large Green - N...   \n",
       "9   MSL 401114 Raw Green Lentils - Large Green - E...   \n",
       "10  MSL 401120 Grain Sales - Raw Grain - Green Len...   \n",
       "11  MSL 401121 Raw Green Lentils - Small Green - N...   \n",
       "12  MSL 401122 Raw Green Lentils - Small Green - N...   \n",
       "13  MSL 401123 Raw Green Lentils - Small Green - N...   \n",
       "14  MSL 401124 Raw Green Lentils - Small Green - E...   \n",
       "15          MSL Grain Sales - Raw Grain - Red Lentils   \n",
       "16                 MSL 401201 Raw Red Lentils - No. 1   \n",
       "17                 MSL 401202 Raw Red Lentils - No. 2   \n",
       "18                 MSL 401203 Raw Red Lentils - No. 3   \n",
       "19           MSL 401204 Raw Red Lentils - Extra No. 3   \n",
       "20        MSL Grain Sales - Raw Grain - Mixed Lentils   \n",
       "21            MSL Grain Sales - Raw Grain - Chickpeas   \n",
       "\n",
       "                                               parent  \n",
       "0                                       Sales Revenue  \n",
       "1                                     Seed Processing  \n",
       "2                                     MSL Grain Sales  \n",
       "3                         MSL Grain Sales - Raw Grain  \n",
       "4                         MSL Grain Sales - Raw Grain  \n",
       "5   MSL Grain Sales - Raw Grain - Large Green Lentils  \n",
       "6   MSL 401110 Grain Sales - Raw Grain - Green Len...  \n",
       "7   MSL 401110 Grain Sales - Raw Grain - Green Len...  \n",
       "8   MSL 401110 Grain Sales - Raw Grain - Green Len...  \n",
       "9   MSL 401110 Grain Sales - Raw Grain - Green Len...  \n",
       "10  MSL Grain Sales - Raw Grain - Large Green Lentils  \n",
       "11  MSL 401120 Grain Sales - Raw Grain - Green Len...  \n",
       "12  MSL 401120 Grain Sales - Raw Grain - Green Len...  \n",
       "13  MSL 401120 Grain Sales - Raw Grain - Green Len...  \n",
       "14  MSL 401120 Grain Sales - Raw Grain - Green Len...  \n",
       "15                        MSL Grain Sales - Raw Grain  \n",
       "16          MSL Grain Sales - Raw Grain - Red Lentils  \n",
       "17          MSL Grain Sales - Raw Grain - Red Lentils  \n",
       "18          MSL Grain Sales - Raw Grain - Red Lentils  \n",
       "19          MSL Grain Sales - Raw Grain - Red Lentils  \n",
       "20                        MSL Grain Sales - Raw Grain  \n",
       "21                        MSL Grain Sales - Raw Grain  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subset = maps.loc[406:427].copy(deep=True).reset_index(drop=True)\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8999f8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "structure = [\"Account\"]\n",
    "for i in range(1, len(maps)):\n",
    "    # print()\n",
    "    # print(i)\n",
    "    # print(f\"structure {structure}\")\n",
    "    # print(f\"records {records}\")\n",
    "    child, parent = maps.loc[i, :]\n",
    "    idx = structure.index(parent)\n",
    "    structure = structure[:idx+1]\n",
    "    structure.append(child)\n",
    "    if _raw_split_name(child)[0]:\n",
    "        records.append(\":\".join(structure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d7bae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "self = QBOETL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ecfd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"Account\":records}).to_csv(self.raw_path[\"QBO\"][\"Raw\"].parent/\"Cube Dimensions - Monette Farms.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a37e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2c2f13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c925c279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fbcfe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b01aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54028f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1147ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce798fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b3f437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e2925e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359d7019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45386b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267f7766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e990f97d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
